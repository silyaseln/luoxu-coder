{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c270a896-d803-4082-a369-04a9985f1aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the code for diesease pre-diagnosis using the Ensemble learning-DNN approach.\n",
    "#This code is only avaliable for Ensemble learning-C(num_labels,K<num_labels-1)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import itertools\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import warnings\n",
    "matplotlib.rcParams['font.sans-serif']=['SimHei']\n",
    "matplotlib.rcParams['axes.unicode_minus']= False\n",
    "matplotlib.rcParams['font.size']= 11\n",
    "from pandas import DataFrame\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import RocCurveDisplay, roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import hamming_loss, f1_score, precision_score, precision_recall_curve, recall_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.utils import resample\n",
    "\n",
    "#Ensemble learning-C(num_labels,K<num_labels-1)\n",
    "K = 3 #K=2,3,4,...,num_labels-2\n",
    "# This section imports the data. \n",
    "filepath = \"C:\\\\Users\\\\PS\\\\Desktop\\\\Open code\\\\Demo.csv\" #Set the user's own path\n",
    "df = pd.read_csv(filepath, header=0, encoding=\"gbk\")\n",
    "X1 = df.drop([\"Pancreas disease\", \"Biliary tract disease\", \"Gastroduodenal disease\", \"Intestinal tract disease\", \"liver disease\", \"others\"], axis=1)\n",
    "y = df[[\"Pancreas disease\", \"Intestinal tract disease\", \"liver disease\", \"Biliary tract disease\", \"Gastroduodenal disease\", \"others\"]]\n",
    "\n",
    "# This section generates all possible C(num_labels,K) combinations. \n",
    "labels = y.columns.tolist()\n",
    "num_labels = y.shape[1]\n",
    "#Use itertools.combinations to generate all possible combinations of K subclasses.\n",
    "combinations = list(itertools.combinations(labels, K))\n",
    "#N-fold cross-validation\n",
    "N = 5\n",
    "kf = KFold(n_splits=N, shuffle=True, random_state=3)\n",
    "\n",
    "#逻辑回归\n",
    "classifier1= LogisticRegression(solver='lbfgs', penalty='l2', dual=False, tol=1e-3, C=1.0, fit_intercept=True,\n",
    "                                intercept_scaling=1, class_weight='balanced', random_state=None,\n",
    "                                max_iter=100, verbose=0, warm_start=False, n_jobs=-1)\n",
    "\n",
    "#weight_Class reflects the class weights.\n",
    "def weight_Class (y):\n",
    "    # Calculate weight of each subclass.\n",
    "    # Initialize weight dictionary.\n",
    "    class_weights = {}\n",
    "    # Iterate through each column (label)\n",
    "    for i, column in enumerate(y.columns):\n",
    "        # Calculate the frequency of each class\n",
    "        counts = np.bincount(y[column].astype(int), minlength=2)\n",
    "        # Calculate the weights, avoiding division by zero.\n",
    "        total_samples = len(y)\n",
    "        weights = total_samples / counts\n",
    "        weights[counts == 0] = 0  # avoiding division by zero\n",
    "        #Store the weights in a dictionary with class labels as keys and weights as values.\n",
    "        class_weights[column] = dict({0: weights[0], 1: weights[1]})\n",
    "        #Create a weight array for each sample in the training set.\n",
    "    pos_weights = [class_weights[category][1] for category in class_weights]\n",
    "\n",
    "    return pos_weights\n",
    "\n",
    "\n",
    "#Label Co-occurrence Adjustment Layer\n",
    "class FeatureAdjustmentLayer(nn.Module):\n",
    "    def __init__(self, hidden_size, num_labels, co_occurrence_matrix):\n",
    "        super(FeatureAdjustmentLayer, self).__init__()\n",
    "        self.co_occurrence_matrix = nn.Parameter(torch.from_numpy(co_occurrence_matrix).float(), requires_grad=False)\n",
    "        #Define a linear layer to map from hidden_size to num_labels.\n",
    "        self.map_to_labels = nn.Linear(hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Map the hidden layer features to a dimension equal to the number of labels.\n",
    "        mapped_features = self.map_to_labels(x)  # [batch_size, num_labels]\n",
    "        # Adjust the features using the co-occurrence matrix.\n",
    "        # Note: Ensure that the dimensions of mapped_features and co_occurrence_matrix are compatible.\n",
    "        adjusted_with_cooccurrence = torch.matmul(mapped_features, self.co_occurrence_matrix)  # [batch_size, num_labels]\n",
    "        return adjusted_with_cooccurrence\n",
    "\n",
    "#DNN for MultiLabelClassification。\n",
    "class MultiLabelClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_labels, co_occurrence_matrix):\n",
    "        super(MultiLabelClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.adjustment_layer = FeatureAdjustmentLayer(hidden_size, num_labels, co_occurrence_matrix)\n",
    "        self.fc3 = nn.Linear(num_labels, num_labels)  #Ensure the input dimension here is num_labels.\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.adjustment_layer(x)\n",
    "        output = torch.sigmoid(self.fc3(x))  #Ensure that the input dimension of self.fc3 matches the dimension of x.\n",
    "        return output\n",
    "\n",
    "#This function defines the basic method of model training。\n",
    "def Fit_MLP(X, y, pos_weights, co_occurrence_matrix, num_epochs, hidden_size=64, learning_rate=0.01):\n",
    "    #device set\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    pos_weights_tensor = torch.tensor(pos_weights, device=device)\n",
    "    X_Ten = torch.tensor(X.values, dtype=torch.float32).to(device)\n",
    "    y_Ten = torch.tensor(y.values, dtype=torch.float32).to(device)\n",
    "    dataset = TensorDataset(X_Ten, y_Ten)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    #Initialize the model, ensuring that the co_occurrence_matrix has been converted to a format suitable for the model.\n",
    "    model = MultiLabelClassifier(X.shape[1], hidden_size, y.shape[1], co_occurrence_matrix).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights_tensor)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "   \n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "#This is a self-defined GRIDSEARCH function\n",
    "def GRIDSEARCH (X_train, y_train, pos_weights, co_occurrence_matrix):\n",
    "    #Define the parameter grid.\n",
    "    param_grid = { 'hidden_size': [8, 16, 32], 'learning_rate': [0.01, 0.05], 'num_epochs': [10, 20, 30]}\n",
    "    best_clf = None\n",
    "    best_score = np.inf\n",
    "    best_params = {}\n",
    "    for hidden_size in param_grid['hidden_size']:\n",
    "        for lr in param_grid['learning_rate']:\n",
    "            for epochs in param_grid['num_epochs']:\n",
    "                model = Fit_MLP(X_train, y_train, pos_weights, co_occurrence_matrix, epochs, hidden_size, lr)\n",
    "                y_pred_proba, y_pred = predict_Multilabel(model, X_train)\n",
    "                y_true = y_train.values\n",
    "                score = np.sum(y_true != y_pred) #Calculate the unnormalized Hamming distance, which is the measure metric here.\n",
    "                if score < best_score:\n",
    "                    best_score = score\n",
    "                    best_params = {'hidden_size': hidden_size, 'learning_rate': lr, 'num_epochs': epochs}\n",
    "                    best_clf = model\n",
    "                    \n",
    "    return best_clf\n",
    "\n",
    "#This function defines the basic method for multi-label prediction.\n",
    "def predict_Multilabel(classifier, X):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    classifier = classifier.to(device)\n",
    "    X_Ten = torch.tensor(X.values, dtype=torch.float32).to(device)\n",
    "    dataset = TensorDataset(X_Ten)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "    classifier.eval()\n",
    "    y_pred_proba_combined = []\n",
    "    with torch.no_grad():\n",
    "         for batch in dataloader:\n",
    "                inputs = batch[0].to(device)\n",
    "                probabilities = classifier(inputs)\n",
    "                y_pred_proba_combined.append(probabilities.cpu().numpy())\n",
    "    \n",
    "    y_pred_proba_combined = np.concatenate(y_pred_proba_combined)\n",
    "    binary_vector = (y_pred_proba_combined > 0.5).astype(int)\n",
    "    return y_pred_proba_combined, binary_vector\n",
    "\n",
    "#This function defines the basic method for multi-label prediction with voting.\n",
    "def predict_with_rfecv(K, classifiers, df, num_labels):\n",
    "    #C(num_labels,K)\n",
    "    base_labels=K\n",
    "    residule_labels = num_labels - base_labels \n",
    "    num_rows = len(df) \n",
    "    vote_results_list = []  # Store the voting results for each row.\n",
    "\n",
    "    for index, row in df.iterrows():  #Iterate through each row of df.\n",
    "        predictions = np.zeros((len(classifiers), base_labels), dtype=int)\n",
    "        predictions_R = np.zeros((len(classifiers), base_labels + residule_labels), dtype=int)\n",
    "        #Store the voting results for each label.\n",
    "        vote_results = np.zeros((base_labels + residule_labels), dtype=int)\n",
    "        \n",
    "        for i, (clf, support, remaining_label_index) in enumerate(classifiers):\n",
    "            #Apply the features selected by the RFECV operators.\n",
    "            X_selected = row[support].values.reshape(1, -1)  #Select the features in the row.\n",
    "            X_selected_d = pd.DataFrame (X_selected)\n",
    "            # Use the corresponding binary classifier to make predictions.\n",
    "            clf_predictions_proba, clf_predictions = predict_Multilabel(clf, X_selected_d)\n",
    "            # The predict_Multilabel function returns a one - dimensional array that contains all the label predictions from the current classifier.\n",
    "            predictions[i, :] = clf_predictions\n",
    "            m=0\n",
    "            for idx in remaining_label_index:\n",
    "                predictions_R[i, idx] = clf_predictions[0, m]\n",
    "                m=m+1\n",
    "                \n",
    "        # Conduct voting to obtain the final results.\n",
    "        for j in range(base_labels + residule_labels):\n",
    "            votes = np.sum(predictions_R[:, j])\n",
    "            vote_results[j] = 1 if votes > (len(classifiers1)-4) / 2 else 0 #Slightly lower the voting threshold to suit multi-label classification.\n",
    "            \n",
    "        vote_results_list.append(vote_results)  # Add the voting results of the current row to the list.\n",
    "        predictions = []\n",
    "        predictions_R =[]\n",
    "        \n",
    "    return np.array(vote_results_list)  # Return the voting results for all rows.\n",
    "\n",
    "#Validation funciton with bootstrap - for recall, specificity, accuracy, precision, and F1\n",
    "def predict_with_rfecv_bootstrap(K, classifiers, df, y_test, n_bootstrap):\n",
    "    #Storage space for results\n",
    "    bootstrap_stats= {\n",
    "        'recall': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],  \n",
    "        'F1': [],\n",
    "        'han':[]   \n",
    "    }\n",
    "    bootstrap_stats_class1= {\n",
    "        'recall': [],\n",
    "        'specificity': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],  \n",
    "        'F1': [] \n",
    "    }\n",
    "    bootstrap_stats_class2={\n",
    "        'recall': [],\n",
    "        'specificity': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],  \n",
    "        'F1': [] \n",
    "    }\n",
    "    bootstrap_stats_class3= {\n",
    "        'recall': [],\n",
    "        'specificity': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],  \n",
    "        'F1': [] \n",
    "    }\n",
    "    bootstrap_stats_class4= {\n",
    "        'recall': [],\n",
    "        'specificity': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],  \n",
    "        'F1': [] \n",
    "    }\n",
    "    bootstrap_stats_class5= {\n",
    "        'recall': [],\n",
    "        'specificity': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],  \n",
    "        'F1': [] \n",
    "    }\n",
    "    bootstrap_stats_class6= {\n",
    "        'recall': [],\n",
    "        'specificity': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],  \n",
    "        'F1': [] \n",
    "    }\n",
    "    num_rows = len(df)  \n",
    "    num_labels = y.shape[1]\n",
    "    f1_vals = np.zeros(n_bootstrap, dtype=float)\n",
    "    precision_vals = np.zeros(n_bootstrap, dtype=float)\n",
    "    accuracy_vals = np.zeros(n_bootstrap, dtype=float)\n",
    "    recall_vals = np.zeros(n_bootstrap, dtype=float)\n",
    "    n_classes = y_test.shape[1]\n",
    "    \n",
    "    for b in range(n_bootstrap):\n",
    "        indices = resample(df.index, n_samples=num_rows, replace=True, random_state=b)\n",
    "        df_bootstrap = df.loc[indices]\n",
    "        y_test_bootstrap = y_test.loc[indices]\n",
    "        predictions = predict_with_rfecv(K, classifiers, df_bootstrap, num_labels)  \n",
    "        warnings.filterwarnings('ignore', category=UserWarning)\n",
    "        \n",
    "        hamming_loss_val = hamming_loss(y_test_bootstrap, predictions)\n",
    "        f1_val = f1_score(y_test_bootstrap, predictions, average='micro')\n",
    "        precision_val = precision_score(y_test_bootstrap, predictions, average='micro')\n",
    "        accuracy_val = accuracy_score(y_test_bootstrap, predictions)\n",
    "        recall_val = recall_score(y_test_bootstrap, predictions, average='micro')\n",
    "        bootstrap_stats['recall'].append(recall_val)\n",
    "        bootstrap_stats['precision'].append(precision_val)\n",
    "        bootstrap_stats['accuracy'].append(accuracy_val)\n",
    "        bootstrap_stats['F1'].append(f1_val)\n",
    "        bootstrap_stats['han'].append(hamming_loss_val)\n",
    "        \n",
    "        # Calculate the multi - label confusion matrix.\n",
    "        mcm = multilabel_confusion_matrix(y_test_bootstrap, predictions)\n",
    "        #  Compute and store the precision, recall, and F1 score for each subclass.\n",
    "        precision = precision_score(y_test_bootstrap, predictions, average=None)\n",
    "        recall = recall_score(y_test_bootstrap, predictions, average=None)\n",
    "        f1 = f1_score(y_test_bootstrap, predictions, average=None)\n",
    "\n",
    "        bootstrap_stats_class1['precision'].append(precision[0])\n",
    "        bootstrap_stats_class2['precision'].append(precision[1])\n",
    "        bootstrap_stats_class3['precision'].append(precision[2])\n",
    "        bootstrap_stats_class4['precision'].append(precision[3])\n",
    "        bootstrap_stats_class5['precision'].append(precision[4])\n",
    "        bootstrap_stats_class6['precision'].append(precision[5])\n",
    "        bootstrap_stats_class1['recall'].append(recall[0])\n",
    "        bootstrap_stats_class2['recall'].append(recall[1])\n",
    "        bootstrap_stats_class3['recall'].append(recall[2])\n",
    "        bootstrap_stats_class4['recall'].append(recall[3])\n",
    "        bootstrap_stats_class5['recall'].append(recall[4])\n",
    "        bootstrap_stats_class6['recall'].append(recall[5])\n",
    "        bootstrap_stats_class1['F1'].append(f1[0])\n",
    "        bootstrap_stats_class2['F1'].append(f1[1])\n",
    "        bootstrap_stats_class3['F1'].append(f1[2])\n",
    "        bootstrap_stats_class4['F1'].append(f1[3])\n",
    "        bootstrap_stats_class5['F1'].append(f1[4])\n",
    "        bootstrap_stats_class6['F1'].append(f1[5])\n",
    "\n",
    "        #Calculate and store the accuracy for each subclass.\n",
    "        accuracies = []\n",
    "        for i in range(n_classes):\n",
    "            # Extract the true and predicted labels for the i-th class.\n",
    "            y_true_class = y_test_bootstrap.values[:, i]\n",
    "            y_pred_class = predictions[:, i]  # Use binary labels for the i-th class.\n",
    "            # Calculate the accuracy for the i-th class.\n",
    "            accuracy_class = accuracy_score(y_true_class, y_pred_class)\n",
    "            if i==0:\n",
    "                bootstrap_stats_class1['accuracy'].append(accuracy_class)\n",
    "            elif i==1:\n",
    "                bootstrap_stats_class2['accuracy'].append(accuracy_class)\n",
    "            elif i==2:\n",
    "                bootstrap_stats_class3['accuracy'].append(accuracy_class)\n",
    "            elif i==3:\n",
    "                bootstrap_stats_class4['accuracy'].append(accuracy_class)\n",
    "            elif i==4:\n",
    "                bootstrap_stats_class5['accuracy'].append(accuracy_class)\n",
    "            elif i==5:\n",
    "                bootstrap_stats_class6['accuracy'].append(accuracy_class)\n",
    "       \n",
    "        # Calculate and store the specificity for each class\n",
    "        specificities = []\n",
    "        for i in range(n_classes):\n",
    "            #True Negatives = Sum of diagonal elements - True Positives of the current class.\n",
    "            true_negatives = np.sum(mcm[:, 0, 0]) - mcm[i, 0, 0]\n",
    "            # False Positives = Sum of the elements in current row - True Positives.\n",
    "            false_positives = np.sum(mcm[i, 0, 1])\n",
    "            # Calculate specificities\n",
    "            specificity = true_negatives / (true_negatives + false_positives) if (true_negatives + false_positives) > 0 else 0\n",
    "            if i==0:\n",
    "                bootstrap_stats_class1['specificity'].append(specificity)\n",
    "            elif i==1:\n",
    "                bootstrap_stats_class2['specificity'].append(specificity)\n",
    "            elif i==2:\n",
    "                bootstrap_stats_class3['specificity'].append(specificity)\n",
    "            elif i==3:\n",
    "                bootstrap_stats_class4['specificity'].append(specificity)\n",
    "            elif i==4:\n",
    "                bootstrap_stats_class5['specificity'].append(specificity)\n",
    "            elif i==5:\n",
    "                bootstrap_stats_class6['specificity'].append(specificity)\n",
    "    \n",
    "    return bootstrap_stats, bootstrap_stats_class1, bootstrap_stats_class2, bootstrap_stats_class3, bootstrap_stats_class4, bootstrap_stats_class5, bootstrap_stats_class6\n",
    "\n",
    "\n",
    "#Validation funciton with bootstrap - only for AUROC and AUPRC\n",
    "def predict_with_rfecv_bootstrap_RPC(K, classifiers, df, y, n_bootstrap):\n",
    "    #Storage space for results\n",
    "    bootstrap_stats = {\n",
    "        'auc': [],\n",
    "        'prc': [],\n",
    "    }\n",
    "    bootstrap_stats_class1= {\n",
    "        'auc': [],\n",
    "        'prc': [],\n",
    "    }\n",
    "    bootstrap_stats_class2={\n",
    "        'auc': [],\n",
    "        'prc': [],\n",
    "    }\n",
    "    bootstrap_stats_class3= {\n",
    "        'auc': [],\n",
    "        'prc': [],\n",
    "    }\n",
    "    bootstrap_stats_class4={\n",
    "        'auc': [],\n",
    "        'prc': [],\n",
    "    }\n",
    "    bootstrap_stats_class5= {\n",
    "        'auc': [],\n",
    "        'prc': [],\n",
    "    }\n",
    "    bootstrap_stats_class6= {\n",
    "        'auc': [],\n",
    "        'prc': [],\n",
    "    }\n",
    "\n",
    "    num_labels = K \n",
    "    n_classes = y.shape[1]\n",
    "    num_rows = len(df) \n",
    "    # Store the prediction results for all Bootstrap samples.\n",
    "    all_predictions_proba = np.zeros((num_rows, n_classes))\n",
    "    for b in range(n_bootstrap):\n",
    "        #Bootstrap resampling allows for the selection of samples with replacement.\n",
    "        indices = resample(df.index, n_samples= num_rows, replace=True, random_state= b)\n",
    "        df_bootstrap = df.loc[indices].reset_index(drop=True)\n",
    "        y_test = y.loc[indices].reset_index(drop=True)\n",
    "        sample_labels_V =y_test.values\n",
    "\n",
    "        for index, row in df_bootstrap.iterrows():  # Iterate through each row of df_bootstrap.\n",
    "            predictions_R_prob = np.zeros((len(classifiers), n_classes), dtype=int)\n",
    "        \n",
    "            for i, (clf, support, remaining_label_index) in enumerate(classifiers):\n",
    "                # Apply the features selected by the RFECV operators.\n",
    "                X_selected = row[support].values.reshape(1, -1) \n",
    "                X_selected_d = pd.DataFrame (X_selected)\n",
    "                # Use the corresponding binary classifier to make predictions.\n",
    "                clf_predictions_proba, clf_predictions = predict_Multilabel(clf, X_selected_d)\n",
    "                #The predict_Multilabel function returns a one-dimensional array containing all the label predictions from the current classifier.\n",
    "                m=0\n",
    "                for idx in remaining_label_index:\n",
    "                    predictions_R_prob[i, idx] = clf_predictions_proba[0, m]\n",
    "                    m=m+1\n",
    "            # or column_means = np.array([np.mean(predictions_R_prob[:, i][predictions_R_prob[:, i] != 0]) for i in range(predictions_R_prob.shape[1])])\n",
    "            # The combination number C(5,2) equals 10. In other cases it is the value of the combination numberC(num_labels-1,K-1)\n",
    "            column_means=np.sum(predictions_R_prob, axis=0)/10 \n",
    "            # Store the prediction probabilities for the current dataset.\n",
    "            all_predictions_proba[index, :] = column_means\n",
    "\n",
    "        # Calculate Micro-AUROC\n",
    "        micro_auc = roc_auc_score(sample_labels_V.ravel(), all_predictions_proba.ravel(), average='micro')\n",
    "        precisionq, recallq, _ = precision_recall_curve(sample_labels_V.ravel(), all_predictions_proba.ravel())\n",
    "        # Calculate Micro-AUPRC\n",
    "        micro_prc_auc = auc(recallq, precisionq)\n",
    "        bootstrap_stats['auc'].append(micro_auc)\n",
    "        bootstrap_stats['prc'].append(micro_prc_auc)\n",
    "        \n",
    "        fprs = dict()\n",
    "        tprs = dict()\n",
    "        roc_aucs = dict()\n",
    "        precisions = dict()\n",
    "        recalls = dict()\n",
    "        pr_aucs = dict()\n",
    "        # Calculate the AUROC for each class.\n",
    "        for i in range(n_classes):\n",
    "            fprs[i], tprs[i], _ = roc_curve(sample_labels_V[:, i], all_predictions_proba[:, i])\n",
    "            roc_aucs[i] = auc(fprs[i], tprs[i])\n",
    "            if i==0:\n",
    "                bootstrap_stats_class1['auc'].append(roc_aucs[0])\n",
    "            elif i==1:\n",
    "                bootstrap_stats_class2['auc'].append(roc_aucs[1])\n",
    "            elif i==2:\n",
    "                bootstrap_stats_class3['auc'].append(roc_aucs[2])\n",
    "            elif i==3:\n",
    "                bootstrap_stats_class4['auc'].append(roc_aucs[3])\n",
    "            elif i==4:\n",
    "                bootstrap_stats_class5['auc'].append(roc_aucs[4])\n",
    "            elif i==5:\n",
    "                bootstrap_stats_class6['auc'].append(roc_aucs[5])\n",
    "        # Calculate the AUPRC for each class.\n",
    "        for i in range(n_classes):\n",
    "            precisions[i], recalls[i], _ = precision_recall_curve(sample_labels_V[:, i], all_predictions_proba[:, i])\n",
    "            pr_aucs[i] = auc(recalls[i], precisions[i])\n",
    "            if i==0:\n",
    "                bootstrap_stats_class1['prc'].append(pr_aucs[i])\n",
    "            elif i==1:\n",
    "                bootstrap_stats_class2['prc'].append(pr_aucs[i])\n",
    "            elif i==2:\n",
    "                bootstrap_stats_class3['prc'].append(pr_aucs[i])\n",
    "            elif i==3:\n",
    "                bootstrap_stats_class4['prc'].append(pr_aucs[i])\n",
    "            elif i==4:\n",
    "                bootstrap_stats_class5['prc'].append(pr_aucs[i])\n",
    "            elif i==5:\n",
    "                bootstrap_stats_class6['prc'].append(pr_aucs[i])\n",
    "\n",
    "    return bootstrap_stats, bootstrap_stats_class1, bootstrap_stats_class2, bootstrap_stats_class3, bootstrap_stats_class4, bootstrap_stats_class5, bootstrap_stats_class6\n",
    "\n",
    "#Automatically identify continuous and binary variables.\n",
    "continuous_vars = []\n",
    "binary_vars = []\n",
    "for col in X1.columns:\n",
    "# Automatically identify binary variables by iterating through each column in the dataset. \n",
    "#If a column is numeric, has exactly two unique values, and those values are 0 and 1, it is considered a binary variable.\n",
    "    if X1[col].dtype.kind in 'biufc' and X1[col].nunique() == 2 and set(X1[col].unique()) == {0, 1}:\n",
    "       binary_vars.append(col)\n",
    "    # Otherwise, it is considered a continuous variable.\n",
    "    else:\n",
    "       continuous_vars.append(col)\n",
    "    # Define variable groups.\n",
    "    groups = {\n",
    "        'Continuous': continuous_vars,\n",
    "         'Binary': binary_vars\n",
    "    }\n",
    "\n",
    "# Apply logarithmic transformation and standardization to continuous variables.\n",
    "log_X1 = X1.copy()\n",
    "log_X1[continuous_vars] = np.log1p(X1[continuous_vars])  #Apply logarithmic transformation to continuous variables.\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = log_X1.copy()\n",
    "X_scaled[continuous_vars] = scaler.fit_transform(X_scaled[continuous_vars])  #Apply standardization to continuous variables.\n",
    "\n",
    "# Perform train - test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.20, random_state=5)\n",
    "\n",
    "# Initialize the lists for classifiers and supports for each label.\n",
    "classifiers1 = []\n",
    "label_supports = []\n",
    "\n",
    "#Perform RFECV feature selection separately for each category label.\n",
    "for j in range(y_train.shape[1]):\n",
    "    rfecv = RFECV(estimator=classifier1, step=1, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    rfecv.fit(X_train, y_train.iloc[:, j])\n",
    "    label_supports.append(rfecv.support_)\n",
    "\n",
    "# Iterate through all combinations of C(num_labels,K) categories.\n",
    "for combo in combinations:\n",
    "    remaining_label_index = [i for i, label in enumerate(labels) if label in combo]\n",
    "    subset = pd.concat([X_train, y_train.loc[:, combo]], axis=1)\n",
    "    filtered_subset = subset[y_train.loc[:, combo].sum(axis=1) > 0]\n",
    "    columns_to_drop = [col for col in combo if col in filtered_subset.columns]\n",
    "    X1_train = filtered_subset.drop(columns_to_drop, axis=1)\n",
    "    y1_train = filtered_subset.loc[:, combo]\n",
    "\n",
    "    #Combine the support features of all labels involved in the current combination.\n",
    "    combo_support = np.logical_or.reduce([label_supports[j] for j in range(y_train.shape[1]) if labels[j] in combo])\n",
    "\n",
    "    best_clf = None\n",
    "    best_accuracy = 1.0\n",
    "    for train_index, test_index in kf.split(filtered_subset):\n",
    "        X_T_train, X_T_test = X1_train.iloc[train_index], X1_train.iloc[test_index]\n",
    "        y_T_train, y_T_test = y1_train.iloc[train_index], y1_train.iloc[test_index]\n",
    "        # Use the combined support vector(Index vector) to select features.\n",
    "        X_T_train_selected = X_T_train.loc[:, X_T_train.columns[combo_support]]\n",
    "        X_T_test_selected = X_T_test.loc[:, X_T_test.columns[combo_support]]\n",
    "        # Train the classifiers.\n",
    "        pos_weights = weight_Class (y_T_train)\n",
    "        co_occurrence_matrix = np.dot(y_T_train.values.T, y_T_train.values) / y_T_train.values.shape[0]\n",
    "        model = GRIDSEARCH (X_T_train_selected, y_T_train, pos_weights, co_occurrence_matrix)\n",
    "        y_pred_proba, y_pred = predict_Multilabel(model, X_T_test_selected)\n",
    "        \n",
    "        hamming_loss_val = hamming_loss(y_T_test, y_pred)\n",
    "        #If the current model's Hamming Loss is smaller, then update the best model.\n",
    "        if hamming_loss_val < best_accuracy:\n",
    "            best_accuracy = hamming_loss_val\n",
    "            best_clf = (model, combo_support, remaining_label_index)\n",
    "    if best_clf:\n",
    "        classifiers1.append(best_clf)\n",
    "\n",
    "# Use the prediction function for validation with bootstrap\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "bootstrap_stats, bootstrap_stats_class1, bootstrap_stats_class2, bootstrap_stats_class3,bootstrap_stats_class4, bootstrap_stats_class5, bootstrap_stats_class6 = predict_with_rfecv_bootstrap(K, classifiers1, X_test, y_test, n_bootstrap=600)\n",
    "bootstrap_stat, bootstrap_stat_class1, bootstrap_stat_class2, bootstrap_stat_class3,bootstrap_stat_class4, bootstrap_stat_class5, bootstrap_stat_class6 = predict_with_rfecv_bootstrap(K, classifiers1, X_train, y_train, n_bootstrap=600)\n",
    "strap_stats, strap_stats_class1, strap_stats_class2, strap_stats_class3, strap_stats_class4, strap_stats_class5, strap_stats_class6 = predict_with_rfecv_bootstrap_RPC(K, classifiers1, X_test.reset_index(drop=True), y_test.reset_index(drop=True), n_bootstrap=600)\n",
    "strap_stat, strap_stat_class1, strap_stat_class2, strap_stat_class3, strap_stat_class4, strap_stat_class5, strap_stat_class6 = predict_with_rfecv_bootstrap_RPC(K, classifiers1, X_train.reset_index(drop=True), y_train.reset_index(drop=True), n_bootstrap=600)\n",
    "\n",
    "# Print the metric results\n",
    "print(f\"micro- Ave-hamming distance in external validation: {np.mean(bootstrap_stats['han']):.4f}\", f\"micro- Std-hamming distance in external validation: {np.std(bootstrap_stats['han']):.4f}\")\n",
    "print(f\"micro- Ave-sensitivity in external validation: {np.mean(bootstrap_stats['recall']):.4f}\", f\"micro- Std-sensitivity in external validation: {np.std(bootstrap_stats['recall']):.4f}\")\n",
    "print(f\"micro- Ave-AUROC in external validation: {np.mean(strap_stats['auc']):.4f}\", f\"micro- Std-AUROC in external validation: {np.std(strap_stats['auc']):.4f}\")\n",
    "print(f\"micro- Ave-precision in external validation: {np.mean(bootstrap_stats['precision']):.4f}\", f\"micro- Std-precision in external validation: {np.std(bootstrap_stats['precision']):.4f}\")\n",
    "print(f\"subset-Ave-accyracy in external validation: {np.mean(bootstrap_stats['accuracy']):.4f}\", f\"subset- Std-accuracy in external validation: {np.std(bootstrap_stats['accuracy']):.4f}\")\n",
    "print(f\"micro- Ave-F1 in external validation: {np.mean(bootstrap_stats['F1']):.4f}\", f\"micro- Std-F1 in external validation: {np.std(bootstrap_stats['F1']):.4f}\")\n",
    "print(f\"micro- Ave-AUPRC in external validation: {np.mean(strap_stats['prc']):.4f}\", f\"micro- Std-F1 in external validation: {np.std(strap_stats['prc']):.4f}\")\n",
    "\n",
    "print(f\"micro- Ave-hamming distance in internal validation: {np.mean(bootstrap_stat['han']):.4f}\", f\"micro- Std-hamming distance in internal validation: {np.std(bootstrap_stat['han']):.4f}\")\n",
    "print(f\"micro- Ave-sensitivity in internal validation: {np.mean(bootstrap_stat['recall']):.4f}\", f\"micro- Std-sensitivity in internal validation: {np.std(bootstrap_stat['recall']):.4f}\")\n",
    "print(f\"micro- Ave-AUROC in internal validation: {np.mean(strap_stat['auc']):.4f}\", f\"micro- Std-AUROC in internal cross-validation: {np.std(strap_stat['auc']):.4f}\")\n",
    "print(f\"micro- Ave-precision in internal validation: {np.mean(bootstrap_stat['precision']):.4f}\", f\"micro- Std-precision in internal validation:  {np.std(bootstrap_stat['precision']):.4f}\")\n",
    "print(f\"subset-Ave-accyracy in internal validation: {np.mean(bootstrap_stat['accuracy']):.4f}\", f\"subset- Std-accuracy in internal validation: {np.std(bootstrap_stat['accuracy']):.4f}\")\n",
    "print(f\"micro- Ave-F1 in internal validation: {np.mean(bootstrap_stat['F1']):.4f}\", f\"micro- Std-F1 in internal validation: {np.std(bootstrap_stat['F1']):.4f}\")\n",
    "print(f\"micro- Ave-AUPRC in internal validation: {np.mean(strap_stat['prc']):.4f}\", f\"micro- Std-F1 in internal validation: {np.std(strap_stat['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass1- Ave-specificity in external validation: {np.mean(bootstrap_stats_class1['specificity']):.4f}\", f\"subclass1- Std-specificity in external validation: {np.std(bootstrap_stats_class1['specificity']):.4f}\")\n",
    "print(f\"subclass1- Ave-sensitivity in external validation: {np.mean(bootstrap_stats_class1['recall']):.4f}\", f\"subclass1- Std-sensitivity in external validation: {np.std(bootstrap_stats_class1['recall']):.4f}\")\n",
    "print(f\"subclass1- Ave-AUROC in external validation: {np.mean(strap_stats_class1['auc']):.4f}\", f\"subclass1- Std-AUROC in external validation: {np.std(strap_stats_class1['auc']):.4f}\")\n",
    "print(f\"subclass1- Ave-precision in external validation: {np.mean(bootstrap_stats_class1['precision']):.4f}\", f\"subclass1- Std-precision in external validation: {np.std(bootstrap_stats_class1['precision']):.4f}\")\n",
    "print(f\"subclass1- Ave-accyracy in external validation: {np.mean(bootstrap_stats_class1['accuracy']):.4f}\", f\"subclass1- Std-accuracy in external validation: {np.std(bootstrap_stats_class1['accuracy']):.4f}\")\n",
    "print(f\"subclass1- Ave-F1 in external validation: {np.mean(bootstrap_stats_class1['F1']):.4f}\", f\"subclass1- Std-F1 in external validation: {np.std(bootstrap_stats_class1['F1']):.4f}\")\n",
    "print(f\"subclass1- Ave-AUPRC in external validation: {np.mean(strap_stats_class1['prc']):.4f}\", f\"subclass1- Std-AUPRC in external validation: {np.std(strap_stats_class1['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass2- Ave-specificity in external validation: {np.mean(bootstrap_stats_class2['specificity']):.4f}\", f\"subclass2- Std-specificity in external validation: {np.std(bootstrap_stats_class2['specificity']):.4f}\")\n",
    "print(f\"subclass2- Ave-sensitivity in external validation: {np.mean(bootstrap_stats_class2['recall']):.4f}\", f\"subclass2- Std-sensitivity in external validation: {np.std(bootstrap_stats_class2['recall']):.4f}\")\n",
    "print(f\"subclass2- Ave-AUROC in external validation: {np.mean(strap_stats_class2['auc']):.4f}\", f\"subclass2- Std-AUROC in external validation: {np.std(strap_stats_class2['auc']):.4f}\")\n",
    "print(f\"subclass2- Ave-precision in external validation: {np.mean(bootstrap_stats_class2['precision']):.4f}\", f\"subclass2- Std-precision in external validation: {np.std(bootstrap_stats_class2['precision']):.4f}\")\n",
    "print(f\"subclass2- Ave-accyracy in external validation: {np.mean(bootstrap_stats_class2['accuracy']):.4f}\", f\"subclass2- Std-accuracy in external validation: {np.std(bootstrap_stats_class2['accuracy']):.4f}\")\n",
    "print(f\"subclass2- Ave-F1 in external validation: {np.mean(bootstrap_stats_class2['F1']):.4f}\", f\"subclass2- Std-F1 in external validation: {np.std(bootstrap_stats_class2['F1']):.4f}\")\n",
    "print(f\"subclass2- Ave-AUPRC in external validation: {np.mean(strap_stats_class2['prc']):.4f}\", f\"subclass2- Std-AUPRC in external validation: {np.std(strap_stats_class2['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass3- Ave-specificity in external validation: {np.mean(bootstrap_stats_class3['specificity']):.4f}\", f\"subclass3- Std-specificity in external validation: {np.std(bootstrap_stats_class3['specificity']):.4f}\")\n",
    "print(f\"subclass3- Ave-sensitivity in external validation: {np.mean(bootstrap_stats_class3['recall']):.4f}\", f\"subclass3- Std-sensitivity in external validation: {np.std(bootstrap_stats_class3['recall']):.4f}\")\n",
    "print(f\"subclass3- Ave-AUROC in external validation: {np.mean(strap_stats_class3['auc']):.4f}\", f\"subclass3- Std-AUROC in external validation: {np.std(strap_stats_class3['auc']):.4f}\")\n",
    "print(f\"subclass3- Ave-precision in external validation: {np.mean(bootstrap_stats_class3['precision']):.4f}\", f\"subclass3- Std-precision in external validation: {np.std(bootstrap_stats_class3['precision']):.4f}\")\n",
    "print(f\"subclass3- Ave-accyracy in external validation: {np.mean(bootstrap_stats_class3['accuracy']):.4f}\", f\"subclass3- Std-accuracy in external validation: {np.std(bootstrap_stats_class3['accuracy']):.4f}\")\n",
    "print(f\"subclass3- Ave-F1 in external validation: {np.mean(bootstrap_stats_class3['F1']):.4f}\", f\"subclass3- Std-F1 in external validation: {np.std(bootstrap_stats_class3['F1']):.4f}\")\n",
    "print(f\"subclass3- Ave-AUPRC in external validation: {np.mean(strap_stats_class3['prc']):.4f}\", f\"subclass3- Std-AUPRC in external validation: {np.std(strap_stats_class3['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass4- Ave-specificity in external validation: {np.mean(bootstrap_stats_class4['specificity']):.4f}\", f\"subclass4- Std-specificity in external validation: {np.std(bootstrap_stats_class4['specificity']):.4f}\")\n",
    "print(f\"subclass4- Ave-sensitivity in external validation: {np.mean(bootstrap_stats_class4['recall']):.4f}\", f\"subclass4- Std-sensitivity in external validation: {np.std(bootstrap_stats_class4['recall']):.4f}\")\n",
    "print(f\"subclass4- Ave-AUROC in external validation: {np.mean(strap_stats_class4['auc']):.4f}\", f\"subclass4- Std-AUROC in external validation: {np.std(strap_stats_class4['auc']):.4f}\")\n",
    "print(f\"subclass4- Ave-precision in external validation: {np.mean(bootstrap_stats_class4['precision']):.4f}\", f\"subclass4- Std-precision in external validation: {np.std(bootstrap_stats_class4['precision']):.4f}\")\n",
    "print(f\"subclass4- Ave-accyracy in external validation: {np.mean(bootstrap_stats_class4['accuracy']):.4f}\", f\"subclass4- Std-accuracy in external validation: {np.std(bootstrap_stats_class4['accuracy']):.4f}\")\n",
    "print(f\"subclass4- Ave-F1 in external validation: {np.mean(bootstrap_stats_class4['F1']):.4f}\", f\"subclass4- Std-F1 in external validation: {np.std(bootstrap_stats_class4['F1']):.4f}\")\n",
    "print(f\"subclass4- Ave-AUPRC in external validation: {np.mean(strap_stats_class4['prc']):.4f}\", f\"subclass4- Std-AUPRC in external validation: {np.std(strap_stats_class4['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass5- Ave-specificity in external validation:{np.mean(bootstrap_stats_class5['specificity']):.4f}\", f\"subclass5- Std-specificity in external validation: {np.std(bootstrap_stats_class5['specificity']):.4f}\")\n",
    "print(f\"subclass5- Ave-sensitivity in external validation: {np.mean(bootstrap_stats_class5['recall']):.4f}\", f\"subclass5- Std-sensitivity in external validation:{np.std(bootstrap_stats_class5['recall']):.4f}\")\n",
    "print(f\"subclass5- Ave-AUROC in external validation:{np.mean(strap_stats_class5['auc']):.4f}\", f\"subclass5- Std-AUROC in external validation: {np.std(strap_stats_class5['auc']):.4f}\")\n",
    "print(f\"subclass5- Ave-precision in external validation: {np.mean(bootstrap_stats_class5['precision']):.4f}\", f\"subclass5- Std-precision in external validation: {np.std(bootstrap_stats_class5['precision']):.4f}\")\n",
    "print(f\"subclass5- Ave-accyracy in external validation: {np.mean(bootstrap_stats_class5['accuracy']):.4f}\", f\"subclass5- Std-accuracy in external validation: {np.std(bootstrap_stats_class5['accuracy']):.4f}\")\n",
    "print(f\"subclass5- Ave-F1 in external validation: {np.mean(bootstrap_stats_class5['F1']):.4f}\", f\"subclass5- Std-F1 in external validation: {np.std(bootstrap_stats_class5['F1']):.4f}\")\n",
    "print(f\"subclass5- Ave-AUPRC in external validation: {np.mean(strap_stats_class5['prc']):.4f}\", f\"subclass5- Std-AUPRC in external validation: {np.std(strap_stats_class5['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass6- Ave-specificity in external validation: {np.mean(bootstrap_stats_class6['specificity']):.4f}\", f\"subclass6- Std-specificity in external validation: {np.std(bootstrap_stats_class6['specificity']):.4f}\")\n",
    "print(f\"subclass6- Ave-sensitivity in external validation: {np.mean(bootstrap_stats_class6['recall']):.4f}\", f\"subclass6- Std-sensitivity in external validation: {np.std(bootstrap_stats_class6['recall']):.4f}\")\n",
    "print(f\"subclass6- Ave-AUROC in external validation: {np.mean(strap_stats_class6['auc']):.4f}\", f\"subclass6- Std-AUROC in external validation: {np.std(strap_stats_class6['auc']):.4f}\")\n",
    "print(f\"subclass6- Ave-precision in external validation: {np.mean(bootstrap_stats_class6['precision']):.4f}\", f\"subclass6- Std-precision in external validation: {np.std(bootstrap_stats_class6['precision']):.4f}\")\n",
    "print(f\"subclass6- Ave-accyracy in external validation: {np.mean(bootstrap_stats_class6['accuracy']):.4f}\", f\"subclass6- Std-accuracy in external validation: {np.std(bootstrap_stats_class6['accuracy']):.4f}\")\n",
    "print(f\"subclass6- Ave-F1 in external validation: {np.mean(bootstrap_stats_class6['F1']):.4f}\", f\"subclass6- Std-F1 in external validation: {np.std(bootstrap_stats_class6['F1']):.4f}\")\n",
    "print(f\"subclass6- Ave-AUPRC in external validation: {np.mean(strap_stats_class6['prc']):.4f}\", f\"subclass6- Std-AUPRC in external validation: {np.std(strap_stats_class6['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass1- Ave-specificity in internal validation: {np.mean(bootstrap_stat_class1['specificity']):.4f}\", f\"subclass1- Std-specificity in internal validation: {np.std(bootstrap_stat_class1['specificity']):.4f}\")\n",
    "print(f\"subclass1- Ave-sensitivity in internal validation: {np.mean(bootstrap_stat_class1['recall']):.4f}\", f\"subclass1- Std-sensitivity in internal validation: {np.std(bootstrap_stat_class1['recall']):.4f}\")\n",
    "print(f\"subclass1- Ave-AUROC in internal validation: {np.mean(strap_stat_class1['auc']):.4f}\", f\"subclass1- Std-AUROC in internal validation: {np.std(strap_stat_class1['auc']):.4f}\")\n",
    "print(f\"subclass1- Ave-precision in internal validation: {np.mean(bootstrap_stat_class1['precision']):.4f}\", f\"subclass1- Std-precision in internal validation: {np.std(bootstrap_stat_class1['precision']):.4f}\")\n",
    "print(f\"subclass1- Ave-accyracy in internal validation: {np.mean(bootstrap_stat_class1['accuracy']):.4f}\", f\"subclass1- Std-accuracy in internal validation: {np.std(bootstrap_stat_class1['accuracy']):.4f}\")\n",
    "print(f\"subclass1- Ave-F1 in internal validation: {np.mean(bootstrap_stat_class1['F1']):.4f}\", f\"subclass1- Std-F1 in internal validation: {np.std(bootstrap_stat_class1['F1']):.4f}\")\n",
    "print(f\"subclass1- Ave-AUPRC in internal validation: {np.mean(strap_stat_class1['prc']):.4f}\", f\"subclass1- Std-AUPRC in internal validation: {np.std(strap_stat_class1['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass2- Ave-specificity in internal validation: {np.mean(bootstrap_stat_class2['specificity']):.4f}\", f\"subclass2- Std-specificity in internal validation: {np.std(bootstrap_stat_class2['specificity']):.4f}\")\n",
    "print(f\"subclass2- Ave-sensitivity in internal validation: {np.mean(bootstrap_stat_class2['recall']):.4f}\", f\"subclass2- Std-sensitivity in internal validation: {np.std(bootstrap_stat_class2['recall']):.4f}\")\n",
    "print(f\"subclass2- Ave-AUROC in internal validation: {np.mean(strap_stat_class2['auc']):.4f}\", f\"subclass2- Std-AUROC in internal validation: {np.std(strap_stat_class2['auc']):.4f}\")\n",
    "print(f\"subclass2- Ave-precision in internal validation: {np.mean(bootstrap_stat_class2['precision']):.4f}\", f\"subclass2- Std-precision in internal validation: {np.std(bootstrap_stat_class2['precision']):.4f}\")\n",
    "print(f\"subclass2- Ave-accyracy in internal validation: {np.mean(bootstrap_stat_class2['accuracy']):.4f}\", f\"subclass2- Std-accuracy in internal validation: {np.std(bootstrap_stat_class2['accuracy']):.4f}\")\n",
    "print(f\"subclass2- Ave-F1 in internal validation: {np.mean(bootstrap_stat_class2['F1']):.4f}\", f\"subclass2- Std-F1 in internal validation: {np.std(bootstrap_stat_class2['F1']):.4f}\")\n",
    "print(f\"subclass2- Ave-AUPRC in internal cross-validation: {np.mean(strap_stat_class2['prc']):.4f}\", f\"subclass2- Std-AUPRC in internal validation: {np.std(strap_stat_class2['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass3- Ave-specificity in internal validation: {np.mean(bootstrap_stat_class3['specificity']):.4f}\", f\"subclass3- Std-specificity in internal validation: {np.std(bootstrap_stat_class3['specificity']):.4f}\")\n",
    "print(f\"subclass3- Ave-sensitivity in internal validation: {np.mean(bootstrap_stat_class3['recall']):.4f}\", f\"subclass3- Std-sensitivity in internal validation: {np.std(bootstrap_stat_class3['recall']):.4f}\")\n",
    "print(f\"subclass3- Ave-AUROC in internal validation: {np.mean(strap_stat_class3['auc']):.4f}\", f\"subclass3- Std-AUROC in internal validation: {np.std(strap_stat_class3['auc']):.4f}\")\n",
    "print(f\"subclass3- Ave-precision in internal validation: {np.mean(bootstrap_stat_class3['precision']):.4f}\", f\"subclass3- Std-precision in internal validation: {np.std(bootstrap_stat_class3['precision']):.4f}\")\n",
    "print(f\"subclass3- Ave-accyracy in internal validation: {np.mean(bootstrap_stat_class3['accuracy']):.4f}\", f\"subclass3- Std-accuracy in internal validation: {np.std(bootstrap_stat_class3['accuracy']):.4f}\")\n",
    "print(f\"subclass3- Ave-F1 in internal validation: {np.mean(bootstrap_stat_class3['F1']):.4f}\", f\"subclass3- Std-F1 in internal validation: {np.std(bootstrap_stat_class3['F1']):.4f}\")\n",
    "print(f\"subclass3- Ave-AUPRC in internal validation: {np.mean(strap_stat_class3['prc']):.4f}\", f\"subclass3 Std-AUPRC in internal validation: {np.std(strap_stat_class3['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass4- Ave-specificity in internal validation: {np.mean(bootstrap_stat_class4['specificity']):.4f}\", f\"subclass4- Std-specificity in internal validation: {np.std(bootstrap_stat_class4['specificity']):.4f}\")\n",
    "print(f\"subclass4- Ave-sensitivity in internal validation: {np.mean(bootstrap_stat_class4['recall']):.4f}\", f\"subclass4- Std-sensitivity in internal validation: {np.std(bootstrap_stat_class4['recall']):.4f}\")\n",
    "print(f\"subclass4- Ave-AUROC in internal validation:{np.mean(strap_stat_class4['auc']):.4f}\", f\"subclass4- Std-AUROC in internal validation: {np.std(strap_stat_class4['auc']):.4f}\")\n",
    "print(f\"subclass4- Ave-precision in internal validation: {np.mean(bootstrap_stat_class4['precision']):.4f}\", f\"subclass4- Std-precision in internal validation: {np.std(bootstrap_stat_class4['precision']):.4f}\")\n",
    "print(f\"subclass4- Ave-accyracy in internal validation: {np.mean(bootstrap_stat_class4['accuracy']):.4f}\", f\"subclass4- Std-accuracy in internal validation: {np.std(bootstrap_stat_class4['accuracy']):.4f}\")\n",
    "print(f\"subclass4- Ave-F1 in internal validation:{np.mean(bootstrap_stat_class4['F1']):.4f}\", f\"subclass4- Std-F1 in internal validation: {np.std(bootstrap_stat_class4['F1']):.4f}\")\n",
    "print(f\"subclass4- Ave-AUPRC in internal validation: {np.mean(strap_stat_class4['prc']):.4f}\", f\"subclass4- Std-AUPRC in internal validation: {np.std(strap_stat_class4['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass5- Ave-specificity in internal validation: {np.mean(bootstrap_stat_class5['specificity']):.4f}\", f\"subclass5- Std-specificity in internal validation: {np.std(bootstrap_stat_class5['specificity']):.4f}\")\n",
    "print(f\"subclass5- Ave-sensitivity in internal validation: {np.mean(bootstrap_stat_class5['recall']):.4f}\", f\"subclass5- Std-sensitivity in internal validation: {np.std(bootstrap_stat_class5['recall']):.4f}\")\n",
    "print(f\"subclass5- Ave-AUROC in internal validation: {np.mean(strap_stat_class5['auc']):.4f}\", f\"subclass5- Std-AUROC in internal validation: {np.std(strap_stat_class5['auc']):.4f}\")\n",
    "print(f\"subclass5- Ave-precision in internal validation: {np.mean(bootstrap_stat_class5['precision']):.4f}\", f\"subclass5- Std-precision in internal validation: {np.std(bootstrap_stat_class5['precision']):.4f}\")\n",
    "print(f\"subclass5- Ave-accyracy in internal validation: {np.mean(bootstrap_stat_class5['accuracy']):.4f}\", f\"subclass5- Std-accuracy in internal validation: {np.std(bootstrap_stat_class5['accuracy']):.4f}\")\n",
    "print(f\"subclass5- Ave-F1 in internal validation: {np.mean(bootstrap_stat_class5['F1']):.4f}\", f\"subclass5- Std-F1 in internal validation: {np.std(bootstrap_stat_class5['F1']):.4f}\")\n",
    "print(f\"subclass5- Ave-AUPRC in internal alidation: {np.mean(strap_stat_class5['prc']):.4f}\", f\"subclass5- Std-AUPRC in internal validation: {np.std(strap_stat_class5['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass6- Ave-specificity in internal validation: {np.mean(bootstrap_stat_class6['specificity']):.4f}\", f\"subclass6- Std-specificity in internal validation: {np.std(bootstrap_stat_class6['specificity']):.4f}\")\n",
    "print(f\"subclass6- Ave-sensitivity in internal validation: {np.mean(bootstrap_stat_class6['recall']):.4f}\", f\"subclass6- Std-sensitivity in internal validation: {np.std(bootstrap_stat_class6['recall']):.4f}\")\n",
    "print(f\"subclass6- Ave-AUROC in internal validation:{np.mean(strap_stat_class6['auc']):.4f}\", f\"subclass6- Std-AUROC in internal validation: {np.std(strap_stat_class6['auc']):.4f}\")\n",
    "print(f\"subclass6- Ave-precision in internal validation: {np.mean(bootstrap_stat_class6['precision']):.4f}\", f\"subclass6- Std-precision in internal validation: {np.std(bootstrap_stat_class6['precision']):.4f}\")\n",
    "print(f\"subclass6- Ave-accyracy in internal validation:: {np.mean(bootstrap_stat_class6['accuracy']):.4f}\", f\"subclass6- Std-accuracy in internal validation: {np.std(bootstrap_stat_class6['accuracy']):.4f}\")\n",
    "print(f\"subclass6- Ave-F1 in internal validation: {np.mean(bootstrap_stat_class6['F1']):.4f}\", f\"subclass6- Std-F1 in internal validation: {np.std(bootstrap_stat_class6['F1']):.4f}\")\n",
    "print(f\"subclass6- Ave-AUPRC in internal validation:{np.mean(strap_stat_class6['prc']):.4f}\", f\"subclass6- Std-AUPRC in internal validation: {np.std(strap_stat_class6['prc']):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e168540d-fe8c-4682-a8ee-99287d7658f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fce9862-22c6-4542-856c-d8a1381b6b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This section offers an MLP - based feature selection component akin to RFECV, which can replace the aforementioned RFECV - LR functionality.\n",
    "#This is only a component\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_classif, f_classif\n",
    "from sklearn.metrics import RocCurveDisplay, roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#Date load\n",
    "filepath = \"C:\\\\Users\\\\PS\\\\Desktop\\\\Open code\\\\Demo.csv\" #Set the user's own path\n",
    "df = pd.read_csv(filepath, header=0, encoding=\"gbk\")\n",
    "X1 = df.drop([\"Pancreas disease\", \"Biliary tract disease\", \"Gastroduodenal disease\", \"Intestinal tract disease\", \"liver disease\", \"others\"], axis=1)\n",
    "y = df[[\"liver disease\", \"Intestinal tract disease\", \"liver disease\", \"Biliary tract disease\", \"Gastroduodenal disease\", \"others\"]]\n",
    "\n",
    "N=5\n",
    "kf = KFold(n_splits=N, shuffle=True, random_state=3)\n",
    "test_acc = np.zeros(N)\n",
    "train_acc = np.zeros(N)\n",
    "precision = np.zeros(N)\n",
    "F1 = np.zeros(N)\n",
    "recall = np.zeros(N)\n",
    "specificity = np.zeros(N)\n",
    "auc1 = np.zeros(N)\n",
    "list = []\n",
    "accuracy=np.zeros(48) #Ensure the feature selection scope is consistent.\n",
    "#MLP\n",
    "classifier = MLPClassifier(activation='logistic', solver='adam', alpha=1e-2, hidden_layer_sizes=(13), learning_rate='constant', max_iter=20000)\n",
    "\n",
    "for k in range(40,88):\n",
    "    \n",
    "        selector = SelectKBest(score_func=mutual_info_classif,k=k)\n",
    "        X_new = selector.fit_transform(X1, y) # Generate new feature columns.\n",
    "        mask = selector.get_support() # Get the feature mask.\n",
    "        new_features = X1.columns[mask] # Select the important features.\n",
    "        X = df[new_features]\n",
    "\n",
    "        j = 0\n",
    "        for train_index, test_index in kf.split(X):\n",
    "             X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "             y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "             classifier.fit(X_train, y_train)\n",
    "             pred_train = classifier.predict(X_train)\n",
    "             pred_test = classifier.predict(X_test)\n",
    "             cm = confusion_matrix(y_test, pred_test)\n",
    "             #Model Evaluation Metrics.\n",
    "             train_acc[j] = accuracy_score(y_train, pred_train)\n",
    "             test_acc[j] = accuracy_score(y_test, pred_test)\n",
    "             precision[j], recall[j], F1[j], _ = precision_recall_fscore_support(np.array(y_test), np.array(pred_test), average='binary')\n",
    "             specificity[j] = cm1[0, 0] / (cm1[0, 0] + cm1[0, 1])\n",
    "   \n",
    "             score_lr = classifier.predict_proba(X_test)[:, 1]\n",
    "             fpr_lr, tpr_lr, thres_lr = roc_curve(y_test, score_lr, )\n",
    "             auc1[j] = auc(fpr_lr, tpr_lr)\n",
    "             j = j + 1\n",
    "            \n",
    "        accuracy[k-40]=np.mean(test_acc)\n",
    "        list.append(mask)\n",
    "\n",
    "max_index = np.argmax(accuracy)#Select the optimal feature subset based on accuracy.\n",
    "new_features_ = X1.columns[list[max_index]]\n",
    "print(\"Optimal number of features: %d\" % len(new_features_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679dde3f-f1fc-4606-907c-6a22b6351354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d4d306-5fd7-41c7-bb5b-c25d57582e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d89f31-1c60-4e8f-b430-8f4761f878b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the code for diesease pre-diagnosis using the Ensemble learning-DNN approach.\n",
    "#This code is only avaliable for Ensemble learning-C(num_labels,K=num_labels-1)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import itertools\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import warnings\n",
    "matplotlib.rcParams['font.sans-serif']=['SimHei']\n",
    "matplotlib.rcParams['axes.unicode_minus']= False\n",
    "matplotlib.rcParams['font.size']= 11\n",
    "from pandas import DataFrame\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import RocCurveDisplay, roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import hamming_loss, f1_score, precision_score, precision_recall_curve, recall_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# 变量初始化\n",
    "#Ensemble learning-C(num_labels,K=num_labels-1)\n",
    "K = 5 #K=num_labels-1\n",
    "\n",
    "# This section imports the data. \n",
    "filepath = \"C:\\\\Users\\\\PS\\\\Desktop\\\\Open code\\\\Demo.csv\" #Set the user's own path\n",
    "df = pd.read_csv(filepath, header=0, encoding=\"gbk\")\n",
    "X1 = df.drop([\"Pancreas disease\", \"Biliary tract disease\", \"Gastroduodenal disease\", \"Intestinal tract disease\", \"liver disease\", \"others\"], axis=1)\n",
    "y = df[[\"Pancreas disease\", \"Intestinal tract disease\", \"liver disease\", \"Biliary tract disease\", \"Gastroduodenal disease\", \"others\"]]\n",
    "\n",
    "# This section generates all possible C(num_labels,K) combinations. \n",
    "labels = y.columns.tolist()\n",
    "num_labels = y.shape[1]\n",
    "#Use itertools.combinations to generate all possible combinations of K subclasses.\n",
    "combinations = list(itertools.combinations(labels, K))\n",
    "\n",
    "#N-fold cross-validation\n",
    "N = 5\n",
    "kf = KFold(n_splits=N, shuffle=True, random_state=3)\n",
    "\n",
    "#This section selects the fundamental approach for RFECV, which can utilize models like logistic regression, random forests, XGBoost, or a custom neural network.\n",
    "#select LR\n",
    "classifier1= LogisticRegression(solver='lbfgs', penalty='l2', dual=False, tol=1e-3, C=1.0, fit_intercept=True,\n",
    "                                intercept_scaling=1, class_weight='balanced', random_state=None,\n",
    "                                max_iter=100,verbose=0,warm_start=False, n_jobs=-1)\n",
    "\n",
    "#weight_Class reflects the class weights.\n",
    "def weight_Class (y):\n",
    "    # Calculate weight of each subclass.\n",
    "    # Initialize weight dictionary.\n",
    "    class_weights = {}\n",
    "    # Iterate through each column (label)\n",
    "    for i, column in enumerate(y.columns):\n",
    "        # Calculate the frequency of each class\n",
    "        counts = np.bincount(y[column].astype(int), minlength=2)\n",
    "        # Calculate the weights, avoiding division by zero.\n",
    "        total_samples = len(y)\n",
    "        weights = total_samples / counts\n",
    "        weights[counts == 0] = 0  # avoiding division by zero\n",
    "        #Store the weights in a dictionary with class labels as keys and weights as values.\n",
    "        class_weights[column] = dict({0: weights[0], 1: weights[1]})\n",
    "        #Create a weight array for each sample in the training set.\n",
    "    pos_weights = [class_weights[category][1] for category in class_weights]\n",
    "\n",
    "    return pos_weights\n",
    "\n",
    "#Label Co-occurrence Adjustment Layer\n",
    "class FeatureAdjustmentLayer(nn.Module):\n",
    "    def __init__(self, hidden_size, num_labels, co_occurrence_matrix):\n",
    "        super(FeatureAdjustmentLayer, self).__init__()\n",
    "        self.co_occurrence_matrix = nn.Parameter(torch.from_numpy(co_occurrence_matrix).float(), requires_grad=False)\n",
    "        #Define a linear layer to map from hidden_size to num_labels.\n",
    "        self.map_to_labels = nn.Linear(hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Map the hidden layer features to a dimension equal to the number of labels.\n",
    "        mapped_features = self.map_to_labels(x)  # [batch_size, num_labels]\n",
    "        # Adjust the features using the co-occurrence matrix.\n",
    "        # Note: Ensure that the dimensions of mapped_features and co_occurrence_matrix are compatible.\n",
    "        adjusted_with_cooccurrence = torch.matmul(mapped_features, self.co_occurrence_matrix)  # [batch_size, num_labels]\n",
    "        return adjusted_with_cooccurrence\n",
    "\n",
    "#DNN for MultiLabelClassification。\n",
    "class MultiLabelClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_labels, co_occurrence_matrix):\n",
    "        super(MultiLabelClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.adjustment_layer = FeatureAdjustmentLayer(hidden_size, num_labels, co_occurrence_matrix)\n",
    "        self.fc3 = nn.Linear(num_labels, num_labels)  #Ensure the input dimension here is num_labels.\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.adjustment_layer(x)\n",
    "        output = torch.sigmoid(self.fc3(x))  #Ensure that the input dimension of self.fc3 matches the dimension of x.\n",
    "        return output\n",
    "\n",
    "#This function defines the basic method of model training.\n",
    "def Fit_MLP(X, y, pos_weights, co_occurrence_matrix, num_epochs, hidden_size=64, learning_rate=0.01):\n",
    "    #device set\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    pos_weights_tensor = torch.tensor(pos_weights, device=device)\n",
    "    X_Ten = torch.tensor(X.values, dtype=torch.float32).to(device)\n",
    "    y_Ten = torch.tensor(y.values, dtype=torch.float32).to(device)\n",
    "    dataset = TensorDataset(X_Ten, y_Ten)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    #Initialize the model, ensuring that the co_occurrence_matrix has been converted to a format suitable for the model.\n",
    "    model = MultiLabelClassifier(X.shape[1], hidden_size, y.shape[1], co_occurrence_matrix).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights_tensor)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "   \n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "#This is a self-defined GRIDSEARCH function\n",
    "def GRIDSEARCH (X_train, y_train, pos_weights, co_occurrence_matrix):\n",
    "    # Define the parameter grid.\n",
    "    param_grid = {'hidden_size': [8, 16, 32], 'learning_rate': [0.01, 0.05], 'num_epochs': [10, 20, 30]}\n",
    "    best_clf = None\n",
    "    best_score = np.inf\n",
    "    best_params = {}\n",
    "    for hidden_size in param_grid['hidden_size']:\n",
    "        for lr in param_grid['learning_rate']:\n",
    "            for epochs in param_grid['num_epochs']:\n",
    "                model = Fit_MLP(X_train, y_train, pos_weights, co_occurrence_matrix, epochs, hidden_size, lr)\n",
    "                y_pred_proba, y_pred = predict_Multilabel(model, X_train)\n",
    "                y_true = y_train.values\n",
    "                #y_pred = y_pred.numpy()\n",
    "                score = np.sum(y_true != y_pred)\n",
    "                if score < best_score:\n",
    "                    best_score = score\n",
    "                    best_params = {'hidden_size': hidden_size, 'learning_rate': lr, 'num_epochs': epochs}\n",
    "                    best_clf = model\n",
    "                    \n",
    "    return best_clf\n",
    "\n",
    "#This function defines the basic method for multi-label prediction.\n",
    "def predict_Multilabel(classifier, X):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    classifier = classifier.to(device)\n",
    "    X_Ten = torch.tensor(X.values, dtype=torch.float32).to(device)\n",
    "    dataset = TensorDataset(X_Ten)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "    classifier.eval()\n",
    "    y_pred_proba_combined = []\n",
    "    with torch.no_grad():\n",
    "         for batch in dataloader:\n",
    "                inputs = batch[0].to(device)\n",
    "                probabilities = classifier(inputs)\n",
    "                y_pred_proba_combined.append(probabilities.cpu().numpy())\n",
    "    \n",
    "    y_pred_proba_combined = np.concatenate(y_pred_proba_combined)\n",
    "    binary_vector = (y_pred_proba_combined > 0.5).astype(int)\n",
    "    return y_pred_proba_combined, binary_vector\n",
    "\n",
    "#This function defines the basic method for multi-label prediction with voting. \n",
    "#Compared to the approach for C(num_labels,K<num_labels-1), there are slight differences here.\n",
    "def predict_with_rfecv(K, classifiers, df, num_labels):\n",
    "    #C(num_labels,K)\n",
    "    base_labels=K \n",
    "    num_rows = len(df)  \n",
    "    vote_results_list = []  #Store the voting results for each row.\n",
    "    \n",
    "    for index, row in df.iterrows():  #Iterate through each row of df.\n",
    "        predictions = np.zeros((len(classifiers), base_labels), dtype=int)\n",
    "        predictions_R = np.zeros((len(classifiers), num_labels), dtype=int)\n",
    "        # Store the voting results for each label.\n",
    "        vote_results = np.zeros(num_labels, dtype=int)\n",
    "        \n",
    "        for i, (clf, support, remaining_label_index) in enumerate(classifiers):\n",
    "            # Apply the features selected by RFECV.\n",
    "            X_selected = row[support].values.reshape(1, -1)  # Select the features in the row.\n",
    "            X_selected_d = pd.DataFrame (X_selected)\n",
    "            # Use the corresponding binary classifier to make predictions.\n",
    "            clf_predictions_proba, clf_predictions = predict_Multilabel(clf, X_selected_d)\n",
    "            # The predict_Multilabel function returns a one - dimensional array that contains all the label predictions from the current classifier.\n",
    "            predictions[i, :] = clf_predictions\n",
    "            predictions_R[i, :] = np.insert(predictions[i, :], remaining_label_index, 0)   \n",
    "\n",
    "        # Conduct voting to obtain the final results.\n",
    "        for j in range(num_labels):\n",
    "            votes = np.sum(predictions_R[:, j])\n",
    "            vote_results[j] = 1 if votes > (len(classifiers)-2) / 2 else 0 #Slightly lower the voting threshold to suit multi-label classification.\n",
    "        vote_results_list.append(vote_results)  # Add the voting results of the current row to the list.\n",
    "        predictions = []\n",
    "        predictions_R =[]\n",
    "        \n",
    "    return np.array(vote_results_list)  # Return the voting results for all rows.\n",
    "\n",
    "#Validation funciton with bootstrap - for recall, specificity, accuracy, precision, and F1\n",
    "def predict_with_rfecv_bootstrap(K, classifiers, df, y_test, n_bootstrap):\n",
    "    \n",
    "    #Storage space for results\n",
    "    bootstrap_stats= {\n",
    "        'recall': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],  \n",
    "        'F1': [],\n",
    "        'han':[]   \n",
    "    }\n",
    "    bootstrap_stats_class1= {\n",
    "        'recall': [],\n",
    "        'specificity': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],  \n",
    "        'F1': [] \n",
    "    }\n",
    "    bootstrap_stats_class2={\n",
    "        'recall': [],\n",
    "        'specificity': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],  \n",
    "        'F1': [] \n",
    "    }\n",
    "    bootstrap_stats_class3= {\n",
    "        'recall': [],\n",
    "        'specificity': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],  \n",
    "        'F1': [] \n",
    "    }\n",
    "    bootstrap_stats_class4= {\n",
    "        'recall': [],\n",
    "        'specificity': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],  \n",
    "        'F1': [] \n",
    "    }\n",
    "    bootstrap_stats_class5= {\n",
    "        'recall': [],\n",
    "        'specificity': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],  \n",
    "        'F1': [] \n",
    "    }\n",
    "    bootstrap_stats_class6= {\n",
    "        'recall': [],\n",
    "        'specificity': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],  \n",
    "        'F1': [] \n",
    "    }\n",
    "    num_rows = len(df)  \n",
    "    f1_vals = np.zeros(n_bootstrap, dtype=float)\n",
    "    precision_vals = np.zeros(n_bootstrap, dtype=float)\n",
    "    accuracy_vals = np.zeros(n_bootstrap, dtype=float)\n",
    "    recall_vals = np.zeros(n_bootstrap, dtype=float)\n",
    "    n_classes = y_test.shape[1]\n",
    "    \n",
    "    for b in range(n_bootstrap):\n",
    "        indices = resample(df.index, n_samples=num_rows, replace=True, random_state=b)\n",
    "        df_bootstrap = df.loc[indices]\n",
    "        y_test_bootstrap = y_test.loc[indices]\n",
    "        predictions = predict_with_rfecv(K, classifiers, df_bootstrap, n_classes) \n",
    "        warnings.filterwarnings('ignore', category=UserWarning)\n",
    "        #'han' refers to the hamming_loss\n",
    "        hamming_loss_val = hamming_loss(y_test_bootstrap, predictions)\n",
    "        f1_val = f1_score(y_test_bootstrap, predictions, average='micro')\n",
    "        precision_val = precision_score(y_test_bootstrap, predictions, average='micro')\n",
    "        accuracy_val = accuracy_score(y_test_bootstrap, predictions)\n",
    "        recall_val = recall_score(y_test_bootstrap, predictions, average='micro')\n",
    "        bootstrap_stats['recall'].append(recall_val)\n",
    "        bootstrap_stats['precision'].append(precision_val)\n",
    "        bootstrap_stats['accuracy'].append(accuracy_val)\n",
    "        bootstrap_stats['F1'].append(f1_val)\n",
    "        bootstrap_stats['han'].append(hamming_loss_val)\n",
    "        \n",
    "        #Calculate the multi - label confusion matrix.\n",
    "        mcm = multilabel_confusion_matrix(y_test_bootstrap, predictions)\n",
    "        # Compute and store the precision, recall, and F1 score for each subclass.\n",
    "        precision = precision_score(y_test_bootstrap, predictions, average=None)\n",
    "        recall = recall_score(y_test_bootstrap, predictions, average=None)\n",
    "        f1 = f1_score(y_test_bootstrap, predictions, average=None)\n",
    "\n",
    "        bootstrap_stats_class1['precision'].append(precision[0])\n",
    "        bootstrap_stats_class2['precision'].append(precision[1])\n",
    "        bootstrap_stats_class3['precision'].append(precision[2])\n",
    "        bootstrap_stats_class4['precision'].append(precision[3])\n",
    "        bootstrap_stats_class5['precision'].append(precision[4])\n",
    "        bootstrap_stats_class6['precision'].append(precision[5])\n",
    "        bootstrap_stats_class1['recall'].append(recall[0])\n",
    "        bootstrap_stats_class2['recall'].append(recall[1])\n",
    "        bootstrap_stats_class3['recall'].append(recall[2])\n",
    "        bootstrap_stats_class4['recall'].append(recall[3])\n",
    "        bootstrap_stats_class5['recall'].append(recall[4])\n",
    "        bootstrap_stats_class6['recall'].append(recall[5])\n",
    "        bootstrap_stats_class1['F1'].append(f1[0])\n",
    "        bootstrap_stats_class2['F1'].append(f1[1])\n",
    "        bootstrap_stats_class3['F1'].append(f1[2])\n",
    "        bootstrap_stats_class4['F1'].append(f1[3])\n",
    "        bootstrap_stats_class5['F1'].append(f1[4])\n",
    "        bootstrap_stats_class6['F1'].append(f1[5])\n",
    "\n",
    "        #Calculate and store the accuracy for each subclass.\n",
    "        accuracies = []\n",
    "        for i in range(n_classes):\n",
    "            # Extract the true and predicted labels for the i-th class.\n",
    "            y_true_class = y_test_bootstrap.values[:, i]\n",
    "            y_pred_class = predictions[:, i]  # Use binary labels.\n",
    "            # Calculate the accuracy for the i-th class.\n",
    "            accuracy_class = accuracy_score(y_true_class, y_pred_class)\n",
    "            if i==0:\n",
    "                bootstrap_stats_class1['accuracy'].append(accuracy_class)\n",
    "            elif i==1:\n",
    "                bootstrap_stats_class2['accuracy'].append(accuracy_class)\n",
    "            elif i==2:\n",
    "                bootstrap_stats_class3['accuracy'].append(accuracy_class)\n",
    "            elif i==3:\n",
    "                bootstrap_stats_class4['accuracy'].append(accuracy_class)\n",
    "            elif i==4:\n",
    "                bootstrap_stats_class5['accuracy'].append(accuracy_class)\n",
    "            elif i==5:\n",
    "                bootstrap_stats_class6['accuracy'].append(accuracy_class)\n",
    "       \n",
    "        # Calculate and store the specificity for each class\n",
    "        specificities = []\n",
    "        for i in range(n_classes):\n",
    "            #True Negatives = Sum of diagonal elements - True Positives of the current class.\n",
    "            true_negatives = np.sum(mcm[:, 0, 0]) - mcm[i, 0, 0]\n",
    "            # False Positives = Sum of the elements in current row - True Positives.\n",
    "            false_positives = np.sum(mcm[i, 0, 1])\n",
    "            # Calculate specificities\n",
    "            specificity = true_negatives / (true_negatives + false_positives) if (true_negatives + false_positives) > 0 else 0\n",
    "            if i==0:\n",
    "                bootstrap_stats_class1['specificity'].append(specificity)\n",
    "            elif i==1:\n",
    "                bootstrap_stats_class2['specificity'].append(specificity)\n",
    "            elif i==2:\n",
    "                bootstrap_stats_class3['specificity'].append(specificity)\n",
    "            elif i==3:\n",
    "                bootstrap_stats_class4['specificity'].append(specificity)\n",
    "            elif i==4:\n",
    "                bootstrap_stats_class5['specificity'].append(specificity)\n",
    "            elif i==5:\n",
    "                bootstrap_stats_class6['specificity'].append(specificity)\n",
    "    \n",
    "    return bootstrap_stats, bootstrap_stats_class1, bootstrap_stats_class2, bootstrap_stats_class3, bootstrap_stats_class4, bootstrap_stats_class5, bootstrap_stats_class6\n",
    "\n",
    "#Validation funciton with bootstrap - only for AUROC and AUPRC\n",
    "def predict_with_rfecv_bootstrap_RPC(K, classifiers, df, y, n_bootstrap):\n",
    "    \n",
    "    #Storage space for results\n",
    "    bootstrap_stats = {\n",
    "        'auc': [],\n",
    "        'prc': [],\n",
    "    }\n",
    "    bootstrap_stats_class1= {\n",
    "        'auc': [],\n",
    "        'prc': [],\n",
    "    }\n",
    "    bootstrap_stats_class2={\n",
    "        'auc': [],\n",
    "        'prc': [],\n",
    "    }\n",
    "    bootstrap_stats_class3= {\n",
    "        'auc': [],\n",
    "        'prc': [],\n",
    "    }\n",
    "    bootstrap_stats_class4={\n",
    "        'auc': [],\n",
    "        'prc': [],\n",
    "    }\n",
    "    bootstrap_stats_class5= {\n",
    "        'auc': [],\n",
    "        'prc': [],\n",
    "    }\n",
    "    bootstrap_stats_class6= {\n",
    "        'auc': [],\n",
    "        'prc': [],\n",
    "    }\n",
    "\n",
    "    base_labels=K \n",
    "    num_rows = len(df) \n",
    "    num_labels = y.shape[1]\n",
    "    # Store the prediction results for all Bootstrap samples.\n",
    "    all_predictions_proba = np.zeros((num_rows, num_labels))\n",
    "    for b in range(n_bootstrap):\n",
    "        # Bootstrap resampling allows for the selection of samples with replacement.\n",
    "        indices = resample(df.index, n_samples= num_rows, replace=True, random_state = b)\n",
    "        df_bootstrap = df.loc[indices].reset_index(drop=True)\n",
    "        y_test = y.loc[indices].reset_index(drop=True)\n",
    "        sample_labels_V =y_test.values\n",
    "\n",
    "        for index, row in df_bootstrap.iterrows():  # Iterate through each row of df_bootstrap.\n",
    "            predictions_R_prob = np.zeros((len(classifiers), num_labels), dtype=int)\n",
    "        \n",
    "            for i, (clf, support, remaining_label_index) in enumerate(classifiers):\n",
    "                # Apply the features selected by RFECV.\n",
    "                X_selected = row[support].values.reshape(1, -1)  #Select the features in the row.\n",
    "                X_selected_d = pd.DataFrame (X_selected)\n",
    "                #Use the corresponding binary classifier to make predictions.\n",
    "                clf_predictions_proba, clf_predictions = predict_Multilabel(clf, X_selected_d)\n",
    "                #The predict_Multilabel function returns a one - dimensional array that contains all the label predictions from the current classifier.\n",
    "                predictions_R_prob[i, :] = np.insert(clf_predictions_proba, remaining_label_index, 0)\n",
    "                \n",
    "            # The combination number C(5,4) equals 10. In other cases it is the value of the combination numberC(num_labels-1,K-1)    \n",
    "            column_means=np.sum(predictions_R_prob, axis=0)/5\n",
    "            # Store the prediction probabilities for the current dataset.\n",
    "            all_predictions_proba[index, :] = column_means\n",
    "\n",
    "        # Calculate Micro-AUROC\n",
    "        micro_auc = roc_auc_score(sample_labels_V.ravel(), all_predictions_proba.ravel(), average='micro')\n",
    "        precisionq, recallq, _ = precision_recall_curve(sample_labels_V.ravel(), all_predictions_proba.ravel())\n",
    "        # Calculate Micro-AUPRC\n",
    "        micro_prc_auc = auc(recallq, precisionq)\n",
    "        bootstrap_stats['auc'].append(micro_auc)\n",
    "        bootstrap_stats['prc'].append(micro_prc_auc)\n",
    "        \n",
    "        fprs = dict()\n",
    "        tprs = dict()\n",
    "        roc_aucs = dict()\n",
    "        precisions = dict()\n",
    "        recalls = dict()\n",
    "        pr_aucs = dict()\n",
    "\n",
    "        #Calculate the AUROC for each class.\n",
    "        for i in range(num_labels):\n",
    "            fprs[i], tprs[i], _ = roc_curve(sample_labels_V[:, i], all_predictions_proba[:, i])\n",
    "            roc_aucs[i] = auc(fprs[i], tprs[i])\n",
    "            if i==0:\n",
    "                bootstrap_stats_class1['auc'].append(roc_aucs[0])\n",
    "            elif i==1:\n",
    "                bootstrap_stats_class2['auc'].append(roc_aucs[1])\n",
    "            elif i==2:\n",
    "                bootstrap_stats_class3['auc'].append(roc_aucs[2])\n",
    "            elif i==3:\n",
    "                bootstrap_stats_class4['auc'].append(roc_aucs[3])\n",
    "            elif i==4:\n",
    "                bootstrap_stats_class5['auc'].append(roc_aucs[4])\n",
    "            elif i==5:\n",
    "                bootstrap_stats_class6['auc'].append(roc_aucs[5])\n",
    "                \n",
    "        # Calculate the AUPRC for each class.\n",
    "        for i in range(num_labels):\n",
    "            precisions[i], recalls[i], _ = precision_recall_curve(sample_labels_V[:, i], all_predictions_proba[:, i])\n",
    "            pr_aucs[i] = auc(recalls[i], precisions[i])\n",
    "            if i==0:\n",
    "                bootstrap_stats_class1['prc'].append(pr_aucs[i])\n",
    "            elif i==1:\n",
    "                bootstrap_stats_class2['prc'].append(pr_aucs[i])\n",
    "            elif i==2:\n",
    "                bootstrap_stats_class3['prc'].append(pr_aucs[i])\n",
    "            elif i==3:\n",
    "                bootstrap_stats_class4['prc'].append(pr_aucs[i])\n",
    "            elif i==4:\n",
    "                bootstrap_stats_class5['prc'].append(pr_aucs[i])\n",
    "            elif i==5:\n",
    "                bootstrap_stats_class6['prc'].append(pr_aucs[i])\n",
    "    \n",
    "    return bootstrap_stats, bootstrap_stats_class1, bootstrap_stats_class2, bootstrap_stats_class3, bootstrap_stats_class4, bootstrap_stats_class5, bootstrap_stats_class6\n",
    "    \n",
    "#Automatically identify continuous and binary variables.\n",
    "continuous_vars = []\n",
    "binary_vars = []\n",
    "for col in X1.columns:\n",
    "# Automatically identify binary variables by iterating through each column in the dataset. \n",
    "#If a column is numeric, has exactly two unique values, and those values are 0 and 1, it is considered a binary variable.\n",
    "    if X1[col].dtype.kind in 'biufc' and X1[col].nunique() == 2 and set(X1[col].unique()) == {0, 1}:\n",
    "       binary_vars.append(col)\n",
    "    # Otherwise, it is considered a continuous variable.\n",
    "    else:\n",
    "       continuous_vars.append(col)\n",
    "    # Define variable groups.\n",
    "    groups = {\n",
    "        'Continuous': continuous_vars,\n",
    "         'Binary': binary_vars\n",
    "    }\n",
    "\n",
    "# Apply logarithmic transformation and standardization to continuous variables.\n",
    "log_X1 = X1.copy()\n",
    "log_X1[continuous_vars] = np.log1p(X1[continuous_vars])  #Apply logarithmic transformation to continuous variables.\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = log_X1.copy()\n",
    "X_scaled[continuous_vars] = scaler.fit_transform(X_scaled[continuous_vars])  #Apply standardization to continuous variables.\n",
    "\n",
    "# Perform train - test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.20, random_state=5)\n",
    "\n",
    "#Initialize the lists for classifiers and supports for each label.\n",
    "classifiers1 = []\n",
    "label_supports = []\n",
    "\n",
    "#Perform RFECV feature selection separately for each category label.\n",
    "for j in range(y_train.shape[1]):\n",
    "    rfecv = RFECV(estimator=classifier1, step=1, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    rfecv.fit(X_train, y_train.iloc[:, j])\n",
    "    label_supports.append(rfecv.support_)\n",
    "\n",
    "# Iterate through all combinations of C(num_labels,K) categories.\n",
    "for combo in combinations:\n",
    "    remaining_label_index = [i for i, label in enumerate(labels) if label not in combo]\n",
    "    subset = pd.concat([X_train, y_train.loc[:, combo]], axis=1)\n",
    "    filtered_subset = subset[y_train.loc[:, combo].sum(axis=1) > 0]\n",
    "    columns_to_drop = [col for col in combo if col in filtered_subset.columns]\n",
    "    X1_train = filtered_subset.drop(columns_to_drop, axis=1)\n",
    "    y1_train = filtered_subset.loc[:, combo]\n",
    "\n",
    "    #Combine the support features of all labels involved in the current combination.\n",
    "    combo_support = np.logical_or.reduce([label_supports[j] for j in range(y_train.shape[1]) if labels[j] in combo])\n",
    "\n",
    "    best_clf = None\n",
    "    best_accuracy = 1.0\n",
    "    for train_index, test_index in kf.split(filtered_subset):\n",
    "        X_T_train, X_T_test = X1_train.iloc[train_index], X1_train.iloc[test_index]\n",
    "        y_T_train, y_T_test = y1_train.iloc[train_index], y1_train.iloc[test_index]\n",
    "        # Use the combined support vector(Index vector) to select features.\n",
    "        X_T_train_selected = X_T_train.loc[:, X_T_train.columns[combo_support]]\n",
    "        X_T_test_selected = X_T_test.loc[:, X_T_test.columns[combo_support]]\n",
    "        # Train the classifiers.\n",
    "        pos_weights = weight_Class (y_T_train)\n",
    "        co_occurrence_matrix = np.dot(y_T_train.values.T, y_T_train.values) / y_T_train.values.shape[0]\n",
    "        model = GRIDSEARCH (X_T_train_selected, y_T_train, pos_weights, co_occurrence_matrix)\n",
    "        y_pred_proba, y_pred = predict_Multilabel(model, X_T_test_selected)\n",
    "        \n",
    "        hamming_loss_val = hamming_loss(y_T_test, y_pred)\n",
    "        #If the current model's Hamming Loss is smaller, then update the best model.\n",
    "        if hamming_loss_val < best_accuracy:\n",
    "            best_accuracy = hamming_loss_val\n",
    "            best_clf = (model, combo_support, remaining_label_index)\n",
    "    if best_clf:\n",
    "        classifiers1.append(best_clf)\n",
    "\n",
    "# Use the prediction function for validation with bootstrap\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "bootstrap_stats, bootstrap_stats_class1, bootstrap_stats_class2, bootstrap_stats_class3,bootstrap_stats_class4, bootstrap_stats_class5, bootstrap_stats_class6 = predict_with_rfecv_bootstrap(K, classifiers1, X_test, y_test, n_bootstrap=600)\n",
    "bootstrap_stat, bootstrap_stat_class1, bootstrap_stat_class2, bootstrap_stat_class3,bootstrap_stat_class4, bootstrap_stat_class5, bootstrap_stat_class6 = predict_with_rfecv_bootstrap(K, classifiers1, X_train, y_train, n_bootstrap=600)\n",
    "strap_stats, strap_stats_class1, strap_stats_class2, strap_stats_class3, strap_stats_class4, strap_stats_class5, strap_stats_class6 = predict_with_rfecv_bootstrap_RPC(K, classifiers1, X_test.reset_index(drop=True), y_test.reset_index(drop=True), n_bootstrap=600)\n",
    "strap_stat, strap_stat_class1, strap_stat_class2, strap_stat_class3, strap_stat_class4, strap_stat_class5, strap_stat_class6 = predict_with_rfecv_bootstrap_RPC(K, classifiers1, X_train.reset_index(drop=True), y_train.reset_index(drop=True), n_bootstrap=600)\n",
    "\n",
    "# Print the metric results\n",
    "print(f\"micro- Ave-hamming distance in external validation: {np.mean(bootstrap_stats['han']):.4f}\", f\"micro- Std-hamming distance in external validation: {np.std(bootstrap_stats['han']):.4f}\")\n",
    "print(f\"micro- Ave-sensitivity in external validation: {np.mean(bootstrap_stats['recall']):.4f}\", f\"micro- Std-sensitivity in external validation: {np.std(bootstrap_stats['recall']):.4f}\")\n",
    "print(f\"micro- Ave-AUROC in external validation: {np.mean(strap_stats['auc']):.4f}\", f\"micro- Std-AUROC in external validation: {np.std(strap_stats['auc']):.4f}\")\n",
    "print(f\"micro- Ave-precision in external validation: {np.mean(bootstrap_stats['precision']):.4f}\", f\"micro- Std-precision in external validation: {np.std(bootstrap_stats['precision']):.4f}\")\n",
    "print(f\"subset-Ave-accyracy in external validation: {np.mean(bootstrap_stats['accuracy']):.4f}\", f\"subset- Std-accuracy in external validation: {np.std(bootstrap_stats['accuracy']):.4f}\")\n",
    "print(f\"micro- Ave-F1 in external validation: {np.mean(bootstrap_stats['F1']):.4f}\", f\"micro- Std-F1 in external validation: {np.std(bootstrap_stats['F1']):.4f}\")\n",
    "print(f\"micro- Ave-AUPRC in external validation: {np.mean(strap_stats['prc']):.4f}\", f\"micro- Std-F1 in external validation: {np.std(strap_stats['prc']):.4f}\")\n",
    "\n",
    "print(f\"micro- Ave-hamming distance in internal validation: {np.mean(bootstrap_stat['han']):.4f}\", f\"micro- Std-hamming distance in internal validation: {np.std(bootstrap_stat['han']):.4f}\")\n",
    "print(f\"micro- Ave-sensitivity in internal validation: {np.mean(bootstrap_stat['recall']):.4f}\", f\"micro- Std-sensitivity in internal validation: {np.std(bootstrap_stat['recall']):.4f}\")\n",
    "print(f\"micro- Ave-AUROC in internal validation: {np.mean(strap_stat['auc']):.4f}\", f\"micro- Std-AUROC in internal cross-validation: {np.std(strap_stat['auc']):.4f}\")\n",
    "print(f\"micro- Ave-precision in internal validation: {np.mean(bootstrap_stat['precision']):.4f}\", f\"micro- Std-precision in internal validation:  {np.std(bootstrap_stat['precision']):.4f}\")\n",
    "print(f\"subset-Ave-accyracy in internal validation: {np.mean(bootstrap_stat['accuracy']):.4f}\", f\"subset- Std-accuracy in internal validation: {np.std(bootstrap_stat['accuracy']):.4f}\")\n",
    "print(f\"micro- Ave-F1 in internal validation: {np.mean(bootstrap_stat['F1']):.4f}\", f\"micro- Std-F1 in internal validation: {np.std(bootstrap_stat['F1']):.4f}\")\n",
    "print(f\"micro- Ave-AUPRC in internal validation: {np.mean(strap_stat['prc']):.4f}\", f\"micro- Std-F1 in internal validation: {np.std(strap_stat['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass1- Ave-specificity in external validation: {np.mean(bootstrap_stats_class1['specificity']):.4f}\", f\"subclass1- Std-specificity in external validation: {np.std(bootstrap_stats_class1['specificity']):.4f}\")\n",
    "print(f\"subclass1- Ave-sensitivity in external validation: {np.mean(bootstrap_stats_class1['recall']):.4f}\", f\"subclass1- Std-sensitivity in external validation: {np.std(bootstrap_stats_class1['recall']):.4f}\")\n",
    "print(f\"subclass1- Ave-AUROC in external validation: {np.mean(strap_stats_class1['auc']):.4f}\", f\"subclass1- Std-AUROC in external validation: {np.std(strap_stats_class1['auc']):.4f}\")\n",
    "print(f\"subclass1- Ave-precision in external validation: {np.mean(bootstrap_stats_class1['precision']):.4f}\", f\"subclass1- Std-precision in external validation: {np.std(bootstrap_stats_class1['precision']):.4f}\")\n",
    "print(f\"subclass1- Ave-accyracy in external validation: {np.mean(bootstrap_stats_class1['accuracy']):.4f}\", f\"subclass1- Std-accuracy in external validation: {np.std(bootstrap_stats_class1['accuracy']):.4f}\")\n",
    "print(f\"subclass1- Ave-F1 in external validation: {np.mean(bootstrap_stats_class1['F1']):.4f}\", f\"subclass1- Std-F1 in external validation: {np.std(bootstrap_stats_class1['F1']):.4f}\")\n",
    "print(f\"subclass1- Ave-AUPRC in external validation: {np.mean(strap_stats_class1['prc']):.4f}\", f\"subclass1- Std-AUPRC in external validation: {np.std(strap_stats_class1['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass2- Ave-specificity in external validation: {np.mean(bootstrap_stats_class2['specificity']):.4f}\", f\"subclass2- Std-specificity in external validation: {np.std(bootstrap_stats_class2['specificity']):.4f}\")\n",
    "print(f\"subclass2- Ave-sensitivity in external validation: {np.mean(bootstrap_stats_class2['recall']):.4f}\", f\"subclass2- Std-sensitivity in external validation: {np.std(bootstrap_stats_class2['recall']):.4f}\")\n",
    "print(f\"subclass2- Ave-AUROC in external validation: {np.mean(strap_stats_class2['auc']):.4f}\", f\"subclass2- Std-AUROC in external validation: {np.std(strap_stats_class2['auc']):.4f}\")\n",
    "print(f\"subclass2- Ave-precision in external validation: {np.mean(bootstrap_stats_class2['precision']):.4f}\", f\"subclass2- Std-precision in external validation: {np.std(bootstrap_stats_class2['precision']):.4f}\")\n",
    "print(f\"subclass2- Ave-accyracy in external validation: {np.mean(bootstrap_stats_class2['accuracy']):.4f}\", f\"subclass2- Std-accuracy in external validation: {np.std(bootstrap_stats_class2['accuracy']):.4f}\")\n",
    "print(f\"subclass2- Ave-F1 in external validation: {np.mean(bootstrap_stats_class2['F1']):.4f}\", f\"subclass2- Std-F1 in external validation: {np.std(bootstrap_stats_class2['F1']):.4f}\")\n",
    "print(f\"subclass2- Ave-AUPRC in external validation: {np.mean(strap_stats_class2['prc']):.4f}\", f\"subclass2- Std-AUPRC in external validation: {np.std(strap_stats_class2['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass3- Ave-specificity in external validation: {np.mean(bootstrap_stats_class3['specificity']):.4f}\", f\"subclass3- Std-specificity in external validation: {np.std(bootstrap_stats_class3['specificity']):.4f}\")\n",
    "print(f\"subclass3- Ave-sensitivity in external validation: {np.mean(bootstrap_stats_class3['recall']):.4f}\", f\"subclass3- Std-sensitivity in external validation: {np.std(bootstrap_stats_class3['recall']):.4f}\")\n",
    "print(f\"subclass3- Ave-AUROC in external validation: {np.mean(strap_stats_class3['auc']):.4f}\", f\"subclass3- Std-AUROC in external validation: {np.std(strap_stats_class3['auc']):.4f}\")\n",
    "print(f\"subclass3- Ave-precision in external validation: {np.mean(bootstrap_stats_class3['precision']):.4f}\", f\"subclass3- Std-precision in external validation: {np.std(bootstrap_stats_class3['precision']):.4f}\")\n",
    "print(f\"subclass3- Ave-accyracy in external validation: {np.mean(bootstrap_stats_class3['accuracy']):.4f}\", f\"subclass3- Std-accuracy in external validation: {np.std(bootstrap_stats_class3['accuracy']):.4f}\")\n",
    "print(f\"subclass3- Ave-F1 in external validation: {np.mean(bootstrap_stats_class3['F1']):.4f}\", f\"subclass3- Std-F1 in external validation: {np.std(bootstrap_stats_class3['F1']):.4f}\")\n",
    "print(f\"subclass3- Ave-AUPRC in external validation: {np.mean(strap_stats_class3['prc']):.4f}\", f\"subclass3- Std-AUPRC in external validation: {np.std(strap_stats_class3['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass4- Ave-specificity in external validation: {np.mean(bootstrap_stats_class4['specificity']):.4f}\", f\"subclass4- Std-specificity in external validation: {np.std(bootstrap_stats_class4['specificity']):.4f}\")\n",
    "print(f\"subclass4- Ave-sensitivity in external validation: {np.mean(bootstrap_stats_class4['recall']):.4f}\", f\"subclass4- Std-sensitivity in external validation: {np.std(bootstrap_stats_class4['recall']):.4f}\")\n",
    "print(f\"subclass4- Ave-AUROC in external validation: {np.mean(strap_stats_class4['auc']):.4f}\", f\"subclass4- Std-AUROC in external validation: {np.std(strap_stats_class4['auc']):.4f}\")\n",
    "print(f\"subclass4- Ave-precision in external validation: {np.mean(bootstrap_stats_class4['precision']):.4f}\", f\"subclass4- Std-precision in external validation: {np.std(bootstrap_stats_class4['precision']):.4f}\")\n",
    "print(f\"subclass4- Ave-accyracy in external validation: {np.mean(bootstrap_stats_class4['accuracy']):.4f}\", f\"subclass4- Std-accuracy in external validation: {np.std(bootstrap_stats_class4['accuracy']):.4f}\")\n",
    "print(f\"subclass4- Ave-F1 in external validation: {np.mean(bootstrap_stats_class4['F1']):.4f}\", f\"subclass4- Std-F1 in external validation: {np.std(bootstrap_stats_class4['F1']):.4f}\")\n",
    "print(f\"subclass4- Ave-AUPRC in external validation: {np.mean(strap_stats_class4['prc']):.4f}\", f\"subclass4- Std-AUPRC in external validation: {np.std(strap_stats_class4['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass5- Ave-specificity in external validation:{np.mean(bootstrap_stats_class5['specificity']):.4f}\", f\"subclass5- Std-specificity in external validation: {np.std(bootstrap_stats_class5['specificity']):.4f}\")\n",
    "print(f\"subclass5- Ave-sensitivity in external validation: {np.mean(bootstrap_stats_class5['recall']):.4f}\", f\"subclass5- Std-sensitivity in external validation:{np.std(bootstrap_stats_class5['recall']):.4f}\")\n",
    "print(f\"subclass5- Ave-AUROC in external validation:{np.mean(strap_stats_class5['auc']):.4f}\", f\"subclass5- Std-AUROC in external validation: {np.std(strap_stats_class5['auc']):.4f}\")\n",
    "print(f\"subclass5- Ave-precision in external validation: {np.mean(bootstrap_stats_class5['precision']):.4f}\", f\"subclass5- Std-precision in external validation: {np.std(bootstrap_stats_class5['precision']):.4f}\")\n",
    "print(f\"subclass5- Ave-accyracy in external validation: {np.mean(bootstrap_stats_class5['accuracy']):.4f}\", f\"subclass5- Std-accuracy in external validation: {np.std(bootstrap_stats_class5['accuracy']):.4f}\")\n",
    "print(f\"subclass5- Ave-F1 in external validation: {np.mean(bootstrap_stats_class5['F1']):.4f}\", f\"subclass5- Std-F1 in external validation: {np.std(bootstrap_stats_class5['F1']):.4f}\")\n",
    "print(f\"subclass5- Ave-AUPRC in external validation: {np.mean(strap_stats_class5['prc']):.4f}\", f\"subclass5- Std-AUPRC in external validation: {np.std(strap_stats_class5['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass6- Ave-specificity in external validation: {np.mean(bootstrap_stats_class6['specificity']):.4f}\", f\"subclass6- Std-specificity in external validation: {np.std(bootstrap_stats_class6['specificity']):.4f}\")\n",
    "print(f\"subclass6- Ave-sensitivity in external validation: {np.mean(bootstrap_stats_class6['recall']):.4f}\", f\"subclass6- Std-sensitivity in external validation: {np.std(bootstrap_stats_class6['recall']):.4f}\")\n",
    "print(f\"subclass6- Ave-AUROC in external validation: {np.mean(strap_stats_class6['auc']):.4f}\", f\"subclass6- Std-AUROC in external validation: {np.std(strap_stats_class6['auc']):.4f}\")\n",
    "print(f\"subclass6- Ave-precision in external validation: {np.mean(bootstrap_stats_class6['precision']):.4f}\", f\"subclass6- Std-precision in external validation: {np.std(bootstrap_stats_class6['precision']):.4f}\")\n",
    "print(f\"subclass6- Ave-accyracy in external validation: {np.mean(bootstrap_stats_class6['accuracy']):.4f}\", f\"subclass6- Std-accuracy in external validation: {np.std(bootstrap_stats_class6['accuracy']):.4f}\")\n",
    "print(f\"subclass6- Ave-F1 in external validation: {np.mean(bootstrap_stats_class6['F1']):.4f}\", f\"subclass6- Std-F1 in external validation: {np.std(bootstrap_stats_class6['F1']):.4f}\")\n",
    "print(f\"subclass6- Ave-AUPRC in external validation: {np.mean(strap_stats_class6['prc']):.4f}\", f\"subclass6- Std-AUPRC in external validation: {np.std(strap_stats_class6['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass1- Ave-specificity in internal validation: {np.mean(bootstrap_stat_class1['specificity']):.4f}\", f\"subclass1- Std-specificity in internal validation: {np.std(bootstrap_stat_class1['specificity']):.4f}\")\n",
    "print(f\"subclass1- Ave-sensitivity in internal validation: {np.mean(bootstrap_stat_class1['recall']):.4f}\", f\"subclass1- Std-sensitivity in internal validation: {np.std(bootstrap_stat_class1['recall']):.4f}\")\n",
    "print(f\"subclass1- Ave-AUROC in internal validation: {np.mean(strap_stat_class1['auc']):.4f}\", f\"subclass1- Std-AUROC in internal validation: {np.std(strap_stat_class1['auc']):.4f}\")\n",
    "print(f\"subclass1- Ave-precision in internal validation: {np.mean(bootstrap_stat_class1['precision']):.4f}\", f\"subclass1- Std-precision in internal validation: {np.std(bootstrap_stat_class1['precision']):.4f}\")\n",
    "print(f\"subclass1- Ave-accyracy in internal validation: {np.mean(bootstrap_stat_class1['accuracy']):.4f}\", f\"subclass1- Std-accuracy in internal validation: {np.std(bootstrap_stat_class1['accuracy']):.4f}\")\n",
    "print(f\"subclass1- Ave-F1 in internal validation: {np.mean(bootstrap_stat_class1['F1']):.4f}\", f\"subclass1- Std-F1 in internal validation: {np.std(bootstrap_stat_class1['F1']):.4f}\")\n",
    "print(f\"subclass1- Ave-AUPRC in internal validation: {np.mean(strap_stat_class1['prc']):.4f}\", f\"subclass1- Std-AUPRC in internal validation: {np.std(strap_stat_class1['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass2- Ave-specificity in internal validation: {np.mean(bootstrap_stat_class2['specificity']):.4f}\", f\"subclass2- Std-specificity in internal validation: {np.std(bootstrap_stat_class2['specificity']):.4f}\")\n",
    "print(f\"subclass2- Ave-sensitivity in internal validation: {np.mean(bootstrap_stat_class2['recall']):.4f}\", f\"subclass2- Std-sensitivity in internal validation: {np.std(bootstrap_stat_class2['recall']):.4f}\")\n",
    "print(f\"subclass2- Ave-AUROC in internal validation: {np.mean(strap_stat_class2['auc']):.4f}\", f\"subclass2- Std-AUROC in internal validation: {np.std(strap_stat_class2['auc']):.4f}\")\n",
    "print(f\"subclass2- Ave-precision in internal validation: {np.mean(bootstrap_stat_class2['precision']):.4f}\", f\"subclass2- Std-precision in internal validation: {np.std(bootstrap_stat_class2['precision']):.4f}\")\n",
    "print(f\"subclass2- Ave-accyracy in internal validation: {np.mean(bootstrap_stat_class2['accuracy']):.4f}\", f\"subclass2- Std-accuracy in internal validation: {np.std(bootstrap_stat_class2['accuracy']):.4f}\")\n",
    "print(f\"subclass2- Ave-F1 in internal validation: {np.mean(bootstrap_stat_class2['F1']):.4f}\", f\"subclass2- Std-F1 in internal validation: {np.std(bootstrap_stat_class2['F1']):.4f}\")\n",
    "print(f\"subclass2- Ave-AUPRC in internal cross-validation: {np.mean(strap_stat_class2['prc']):.4f}\", f\"subclass2- Std-AUPRC in internal validation: {np.std(strap_stat_class2['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass3- Ave-specificity in internal validation: {np.mean(bootstrap_stat_class3['specificity']):.4f}\", f\"subclass3- Std-specificity in internal validation: {np.std(bootstrap_stat_class3['specificity']):.4f}\")\n",
    "print(f\"subclass3- Ave-sensitivity in internal validation: {np.mean(bootstrap_stat_class3['recall']):.4f}\", f\"subclass3- Std-sensitivity in internal validation: {np.std(bootstrap_stat_class3['recall']):.4f}\")\n",
    "print(f\"subclass3- Ave-AUROC in internal validation: {np.mean(strap_stat_class3['auc']):.4f}\", f\"subclass3- Std-AUROC in internal validation: {np.std(strap_stat_class3['auc']):.4f}\")\n",
    "print(f\"subclass3- Ave-precision in internal validation: {np.mean(bootstrap_stat_class3['precision']):.4f}\", f\"subclass3- Std-precision in internal validation: {np.std(bootstrap_stat_class3['precision']):.4f}\")\n",
    "print(f\"subclass3- Ave-accyracy in internal validation: {np.mean(bootstrap_stat_class3['accuracy']):.4f}\", f\"subclass3- Std-accuracy in internal validation: {np.std(bootstrap_stat_class3['accuracy']):.4f}\")\n",
    "print(f\"subclass3- Ave-F1 in internal validation: {np.mean(bootstrap_stat_class3['F1']):.4f}\", f\"subclass3- Std-F1 in internal validation: {np.std(bootstrap_stat_class3['F1']):.4f}\")\n",
    "print(f\"subclass3- Ave-AUPRC in internal validation: {np.mean(strap_stat_class3['prc']):.4f}\", f\"subclass3 Std-AUPRC in internal validation: {np.std(strap_stat_class3['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass4- Ave-specificity in internal validation: {np.mean(bootstrap_stat_class4['specificity']):.4f}\", f\"subclass4- Std-specificity in internal validation: {np.std(bootstrap_stat_class4['specificity']):.4f}\")\n",
    "print(f\"subclass4- Ave-sensitivity in internal validation: {np.mean(bootstrap_stat_class4['recall']):.4f}\", f\"subclass4- Std-sensitivity in internal validation: {np.std(bootstrap_stat_class4['recall']):.4f}\")\n",
    "print(f\"subclass4- Ave-AUROC in internal validation:{np.mean(strap_stat_class4['auc']):.4f}\", f\"subclass4- Std-AUROC in internal validation: {np.std(strap_stat_class4['auc']):.4f}\")\n",
    "print(f\"subclass4- Ave-precision in internal validation: {np.mean(bootstrap_stat_class4['precision']):.4f}\", f\"subclass4- Std-precision in internal validation: {np.std(bootstrap_stat_class4['precision']):.4f}\")\n",
    "print(f\"subclass4- Ave-accyracy in internal validation: {np.mean(bootstrap_stat_class4['accuracy']):.4f}\", f\"subclass4- Std-accuracy in internal validation: {np.std(bootstrap_stat_class4['accuracy']):.4f}\")\n",
    "print(f\"subclass4- Ave-F1 in internal validation:{np.mean(bootstrap_stat_class4['F1']):.4f}\", f\"subclass4- Std-F1 in internal validation: {np.std(bootstrap_stat_class4['F1']):.4f}\")\n",
    "print(f\"subclass4- Ave-AUPRC in internal validation: {np.mean(strap_stat_class4['prc']):.4f}\", f\"subclass4- Std-AUPRC in internal validation: {np.std(strap_stat_class4['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass5- Ave-specificity in internal validation: {np.mean(bootstrap_stat_class5['specificity']):.4f}\", f\"subclass5- Std-specificity in internal validation: {np.std(bootstrap_stat_class5['specificity']):.4f}\")\n",
    "print(f\"subclass5- Ave-sensitivity in internal validation: {np.mean(bootstrap_stat_class5['recall']):.4f}\", f\"subclass5- Std-sensitivity in internal validation: {np.std(bootstrap_stat_class5['recall']):.4f}\")\n",
    "print(f\"subclass5- Ave-AUROC in internal validation: {np.mean(strap_stat_class5['auc']):.4f}\", f\"subclass5- Std-AUROC in internal validation: {np.std(strap_stat_class5['auc']):.4f}\")\n",
    "print(f\"subclass5- Ave-precision in internal validation: {np.mean(bootstrap_stat_class5['precision']):.4f}\", f\"subclass5- Std-precision in internal validation: {np.std(bootstrap_stat_class5['precision']):.4f}\")\n",
    "print(f\"subclass5- Ave-accyracy in internal validation: {np.mean(bootstrap_stat_class5['accuracy']):.4f}\", f\"subclass5- Std-accuracy in internal validation: {np.std(bootstrap_stat_class5['accuracy']):.4f}\")\n",
    "print(f\"subclass5- Ave-F1 in internal validation: {np.mean(bootstrap_stat_class5['F1']):.4f}\", f\"subclass5- Std-F1 in internal validation: {np.std(bootstrap_stat_class5['F1']):.4f}\")\n",
    "print(f\"subclass5- Ave-AUPRC in internal alidation: {np.mean(strap_stat_class5['prc']):.4f}\", f\"subclass5- Std-AUPRC in internal validation: {np.std(strap_stat_class5['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass6- Ave-specificity in internal validation: {np.mean(bootstrap_stat_class6['specificity']):.4f}\", f\"subclass6- Std-specificity in internal validation: {np.std(bootstrap_stat_class6['specificity']):.4f}\")\n",
    "print(f\"subclass6- Ave-sensitivity in internal validation: {np.mean(bootstrap_stat_class6['recall']):.4f}\", f\"subclass6- Std-sensitivity in internal validation: {np.std(bootstrap_stat_class6['recall']):.4f}\")\n",
    "print(f\"subclass6- Ave-AUROC in internal validation:{np.mean(strap_stat_class6['auc']):.4f}\", f\"subclass6- Std-AUROC in internal validation: {np.std(strap_stat_class6['auc']):.4f}\")\n",
    "print(f\"subclass6- Ave-precision in internal validation: {np.mean(bootstrap_stat_class6['precision']):.4f}\", f\"subclass6- Std-precision in internal validation: {np.std(bootstrap_stat_class6['precision']):.4f}\")\n",
    "print(f\"subclass6- Ave-accyracy in internal validation:: {np.mean(bootstrap_stat_class6['accuracy']):.4f}\", f\"subclass6- Std-accuracy in internal validation: {np.std(bootstrap_stat_class6['accuracy']):.4f}\")\n",
    "print(f\"subclass6- Ave-F1 in internal validation: {np.mean(bootstrap_stat_class6['F1']):.4f}\", f\"subclass6- Std-F1 in internal validation: {np.std(bootstrap_stat_class6['F1']):.4f}\")\n",
    "print(f\"subclass6- Ave-AUPRC in internal validation:{np.mean(strap_stat_class6['prc']):.4f}\", f\"subclass6- Std-AUPRC in internal validation: {np.std(strap_stat_class6['prc']):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c7a09a-97ae-499c-903d-55fd0c230da8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b436a6fb-2239-432a-8306-f8afa4f63953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f031ca16-44f2-4b64-bd40-0b8912bae88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the code for diesease pre-diagnosis using the Ensemble learning-DNN approach.\n",
    "#This code is only avaliable for Ensemble learning-C(num_labels,K=num_labels)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import itertools\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import warnings\n",
    "matplotlib.rcParams['font.sans-serif']=['SimHei']\n",
    "matplotlib.rcParams['axes.unicode_minus']= False\n",
    "matplotlib.rcParams['font.size']= 11\n",
    "from pandas import DataFrame\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import RocCurveDisplay, roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import hamming_loss, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix, f1_score, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# This section imports the data. \n",
    "filepath = \"C:\\\\Users\\\\PS\\\\Desktop\\\\Open code\\\\Demo.csv\" #Set the user's own path.\n",
    "df = pd.read_csv(filepath, header=0, encoding=\"gbk\")\n",
    "X1 = df.drop([\"Pancreas disease\", \"Biliary tract disease\", \"Gastroduodenal disease\", \"Intestinal tract disease\", \"liver disease\", \"others\"], axis=1)\n",
    "y = df[[\"Pancreas disease\", \"Intestinal tract disease\", \"liver disease\", \"Biliary tract disease\", \"Gastroduodenal disease\", \"others\"]]\n",
    "\n",
    "# This section generates all possible C(num_labels,K) combinations. \n",
    "labels = y.columns.tolist()\n",
    "num_labels = y.shape[1]\n",
    "#Use itertools.combinations to generate all possible combinations of K subclasses.\n",
    "combinations = list(itertools.combinations(labels, num_labels))\n",
    "\n",
    "#N-fold cross-validation\n",
    "N = 5\n",
    "kf = KFold(n_splits=N, shuffle=True, random_state=3)\n",
    "\n",
    "#逻辑回归\n",
    "classifier1= LogisticRegression(solver='lbfgs', penalty='l2', dual=False, tol=1e-3, C=1.0, fit_intercept=True,\n",
    "                                intercept_scaling=1, class_weight='balanced', random_state=None,\n",
    "                                max_iter=100,verbose=0,warm_start=False, n_jobs=-1)\n",
    "\n",
    "\n",
    "#weight_Class reflects the class weights.\n",
    "def weight_Class (y):\n",
    "    # Calculate weight of each subclass.\n",
    "    # Initialize weight dictionary.\n",
    "    class_weights = {}\n",
    "    # Iterate through each column (label)\n",
    "    for i, column in enumerate(y.columns):\n",
    "        # Calculate the frequency of each class\n",
    "        counts = np.bincount(y[column].astype(int), minlength=2)\n",
    "        # Calculate the weights, avoiding division by zero.\n",
    "        total_samples = len(y)\n",
    "        weights = total_samples / counts\n",
    "        weights[counts == 0] = 0  # avoiding division by zero\n",
    "        #Store the weights in a dictionary with class labels as keys and weights as values.\n",
    "        class_weights[column] = dict({0: weights[0], 1: weights[1]})\n",
    "        #Create a weight array for each sample in the training set.\n",
    "    pos_weights = [class_weights[category][1] for category in class_weights]\n",
    "\n",
    "    return pos_weights\n",
    "\n",
    "#Label Co-occurrence Adjustment Layer\n",
    "class FeatureAdjustmentLayer(nn.Module):\n",
    "    def __init__(self, hidden_size, num_labels, co_occurrence_matrix):\n",
    "        super(FeatureAdjustmentLayer, self).__init__()\n",
    "        self.co_occurrence_matrix = nn.Parameter(torch.from_numpy(co_occurrence_matrix).float(), requires_grad=False)\n",
    "        #Define a linear layer to map from hidden_size to num_labels.\n",
    "        self.map_to_labels = nn.Linear(hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Map the hidden layer features to a dimension equal to the number of labels.\n",
    "        mapped_features = self.map_to_labels(x)  # [batch_size, num_labels]\n",
    "        # Adjust the features using the co-occurrence matrix.\n",
    "        # Note: Ensure that the dimensions of mapped_features and co_occurrence_matrix are compatible.\n",
    "        adjusted_with_cooccurrence = torch.matmul(mapped_features, self.co_occurrence_matrix)  # [batch_size, num_labels]\n",
    "        return adjusted_with_cooccurrence\n",
    "\n",
    "#DNN for MultiLabelClassification。\n",
    "class MultiLabelClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_labels, co_occurrence_matrix):\n",
    "        super(MultiLabelClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.adjustment_layer = FeatureAdjustmentLayer(hidden_size, num_labels, co_occurrence_matrix)\n",
    "        self.fc3 = nn.Linear(num_labels, num_labels)  #Ensure the input dimension here is num_labels.\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.adjustment_layer(x)\n",
    "        output = torch.sigmoid(self.fc3(x))  #Ensure that the input dimension of self.fc3 matches the dimension of x.\n",
    "        return output\n",
    "\n",
    "#This function defines the basic method of model training.\n",
    "def Fit_MLP(X, y, pos_weights, co_occurrence_matrix, num_epochs, hidden_size=64, learning_rate=0.01):\n",
    "    #device set\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    pos_weights_tensor = torch.tensor(pos_weights, device=device)\n",
    "    X_Ten = torch.tensor(X.values, dtype=torch.float32).to(device)\n",
    "    y_Ten = torch.tensor(y.values, dtype=torch.float32).to(device)\n",
    "    dataset = TensorDataset(X_Ten, y_Ten)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    #Initialize the model, ensuring that the co_occurrence_matrix has been converted to a format suitable for the model.\n",
    "    model = MultiLabelClassifier(X.shape[1], hidden_size, y.shape[1], co_occurrence_matrix).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights_tensor)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "   \n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "#This is a self-defined GRIDSEARCH function\n",
    "def GRIDSEARCH (X_train, y_train, pos_weights, co_occurrence_matrix):\n",
    "    # Define the parameter grid.\n",
    "    param_grid = {'hidden_size': [8, 16, 32], 'learning_rate': [0.01, 0.05], 'num_epochs': [10, 20, 30]}\n",
    "    best_clf = None\n",
    "    best_score = 0\n",
    "    best_params = {}\n",
    "    for hidden_size in param_grid['hidden_size']:\n",
    "        for lr in param_grid['learning_rate']:\n",
    "            for epochs in param_grid['num_epochs']:\n",
    "                model = Fit_MLP(X_train, y_train, pos_weights, co_occurrence_matrix, epochs, hidden_size, lr)\n",
    "                y_pred_proba, y_pred = predict_Multilabel(model, X_train)\n",
    "                y_true = y_train.values\n",
    "                #y_pred = y_pred.numpy()\n",
    "                score = f1_score(y_true, y_pred, average='macro')\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_params = {'hidden_size': hidden_size, 'learning_rate': lr, 'num_epochs': epochs}\n",
    "                    best_clf = model\n",
    "                    \n",
    "    return best_clf\n",
    "\n",
    "#This function defines the basic method for multi-label prediction.\n",
    "def predict_Multilabel(classifier, X):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    classifier = classifier.to(device)\n",
    "    X_Ten = torch.tensor(X.values, dtype=torch.float32).to(device)\n",
    "    dataset = TensorDataset(X_Ten)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "    classifier.eval()\n",
    "    y_pred_proba_combined = []\n",
    "    with torch.no_grad():\n",
    "         for batch in dataloader:\n",
    "                inputs = batch[0].to(device)\n",
    "                probabilities = classifier(inputs)\n",
    "                y_pred_proba_combined.append(probabilities.cpu().numpy())\n",
    "    \n",
    "    y_pred_proba_combined = np.concatenate(y_pred_proba_combined)\n",
    "    binary_vector = (y_pred_proba_combined > 0.5).astype(int)\n",
    "    return y_pred_proba_combined, binary_vector\n",
    "\n",
    "#This function defines the basic method for multi-label prediction with voting. \n",
    "#Compared to the approach for C(num_labels,K<num_labels-1) and C(num_labels,K=num_labels-1) , there are slight differences here.        \n",
    "def predict_with_rfecv(classifiers, df, num_labels):\n",
    "\n",
    "    num_rows = len(df) \n",
    "    vote_results_list = []  #Store the prediction results for each row.\n",
    "    prob_results_list = []  #Store the prediction probabilities for each row.\n",
    "    \n",
    "    for index, row in df.iterrows():  #Iterate through each row of df.\n",
    "        predictions = np.zeros((len(classifiers), num_labels), dtype=int)\n",
    "        predictions_R = np.zeros((len(classifiers), num_labels), dtype=float)\n",
    "        # Store the prediction results for each label.\n",
    "        vote_results = np.zeros((num_labels), dtype=int)\n",
    "        \n",
    "        for i, (clf, support) in enumerate(classifiers):\n",
    "            # Apply the features selected by RFECV.\n",
    "            X_selected = row[support].values.reshape(1, -1)  # 选择行中的特征\n",
    "            X_selected_d = pd.DataFrame (X_selected)\n",
    "            # Use the corresponding binary classifier to make predictions.\n",
    "            clf_predictions_proba, clf_predictions = predict_Multilabel(clf, X_selected_d)\n",
    "            # The predict_Multilabel function returns a one - dimensional array that contains all the label predictions from the current classifier.\n",
    "            predictions[i, :] = clf_predictions\n",
    "            predictions_R[i, :] = clf_predictions_proba\n",
    "            \n",
    "        # Conduct voting to obtain the final results.\n",
    "        for j in range(num_labels):\n",
    "            votes = np.sum(predictions[:, j])\n",
    "            vote_results[j] = 1 if votes == np.max(np.sum(predictions, axis=0)) else 0\n",
    "        vote_results_list.append(vote_results)  # Add the prediction results of the current row to the list.\n",
    "        prob_results_list.append(np.sum(predictions_R, axis=0))  # Add the prediction probabilities of the current row to the list.\n",
    "        \n",
    "    return np.array(prob_results_list), np.array(vote_results_list) \n",
    "\n",
    "\n",
    "def predict_with_rfecv_bootstrap(classifiers, df, y_test, n_bootstrap):\n",
    "    \n",
    "    #Storage space for results\n",
    "    bootstrap_stats= {\n",
    "        'recall': [],\n",
    "        'auc': [],\n",
    "        'prc': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],  \n",
    "        'F1': [],\n",
    "        'han':[]\n",
    "    }\n",
    "    bootstrap_stats_class1= {\n",
    "        'recall': [],\n",
    "        'specificity': [],\n",
    "        'auc': [],\n",
    "        'prc': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],  \n",
    "        'F1': [] \n",
    "    }\n",
    "    bootstrap_stats_class2={\n",
    "        'recall': [],\n",
    "        'specificity': [],\n",
    "        'auc': [],\n",
    "        'prc': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],  \n",
    "        'F1': [] \n",
    "    }\n",
    "    bootstrap_stats_class3= {\n",
    "        'recall': [],\n",
    "        'specificity': [],\n",
    "        'auc': [],\n",
    "        'prc': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],  \n",
    "        'F1': [] \n",
    "    }\n",
    "    bootstrap_stats_class4= {\n",
    "        'recall': [],\n",
    "        'specificity': [],\n",
    "        'auc': [],\n",
    "        'prc': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],  \n",
    "        'F1': [] \n",
    "    }\n",
    "    bootstrap_stats_class5= {\n",
    "        'recall': [],\n",
    "        'specificity': [],\n",
    "        'auc': [],\n",
    "        'prc': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],  \n",
    "        'F1': [] \n",
    "    }\n",
    "    bootstrap_stats_class6= {\n",
    "        'recall': [],\n",
    "        'specificity': [],\n",
    "        'auc': [],\n",
    "        'prc': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],  \n",
    "        'F1': [] \n",
    "    }\n",
    "    \n",
    "    num_rows = len(df) \n",
    "    f1_vals = np.zeros(n_bootstrap, dtype=float)\n",
    "    precision_vals = np.zeros(n_bootstrap, dtype=float)\n",
    "    accuracy_vals = np.zeros(n_bootstrap, dtype=float)\n",
    "    recall_vals = np.zeros(n_bootstrap, dtype=float)\n",
    "    \n",
    "    for b in range(n_bootstrap):\n",
    "        indices = resample(df.index, n_samples=num_rows, replace=True, random_state=b)\n",
    "        df_bootstrap = df.loc[indices]\n",
    "        y_test_bootstrap = y_test.loc[indices]\n",
    "        predictions_R, predictions = predict_with_rfecv(classifiers, df_bootstrap, num_labels)  # 确保这个函数返回预测结果\n",
    "        warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "        hamming_loss_val = hamming_loss(y_test_bootstrap, predictions)\n",
    "        f1_val = f1_score(y_test_bootstrap, predictions, average='micro')\n",
    "        precision_val = precision_score(y_test_bootstrap, predictions, average='micro')\n",
    "        accuracy_val = accuracy_score(y_test_bootstrap, predictions)\n",
    "        recall_val = recall_score(y_test_bootstrap, predictions, average='micro')\n",
    "        # Calculate Micro-AUROC\n",
    "        micro_auc = roc_auc_score(y_test_bootstrap.values.ravel(), predictions_R.ravel(), average='micro')\n",
    "        precisionq, recallq, _ = precision_recall_curve(y_test_bootstrap.values.ravel(), predictions_R.ravel())\n",
    "        # Calculate Micro-AUPRC\n",
    "        micro_prc_auc = auc(recallq, precisionq)\n",
    "        bootstrap_stats['recall'].append(recall_val)\n",
    "        bootstrap_stats['precision'].append(precision_val)\n",
    "        bootstrap_stats['accuracy'].append(accuracy_val)\n",
    "        bootstrap_stats['F1'].append(f1_val)\n",
    "        bootstrap_stats['auc'].append(micro_auc)\n",
    "        bootstrap_stats['prc'].append(micro_prc_auc)\n",
    "        bootstrap_stats['han'].append(hamming_loss_val)\n",
    "\n",
    "        # Calculate the multi-label confusion matrix.\n",
    "        mcm = multilabel_confusion_matrix(y_test_bootstrap, predictions)\n",
    "        #Compute and store the precision, recall, and F1 score for each subclass.\n",
    "        n_classes = y_test.shape[1]\n",
    "        precision = precision_score(y_test_bootstrap, predictions, average=None)\n",
    "        recall = recall_score(y_test_bootstrap, predictions, average=None)\n",
    "        f1 = f1_score(y_test_bootstrap, predictions, average=None)\n",
    "\n",
    "        bootstrap_stats_class1['precision'].append(precision[0])\n",
    "        bootstrap_stats_class2['precision'].append(precision[1])\n",
    "        bootstrap_stats_class3['precision'].append(precision[2])\n",
    "        bootstrap_stats_class4['precision'].append(precision[3])\n",
    "        bootstrap_stats_class5['precision'].append(precision[4])\n",
    "        bootstrap_stats_class6['precision'].append(precision[5])\n",
    "        \n",
    "        bootstrap_stats_class1['recall'].append(recall[0])\n",
    "        bootstrap_stats_class2['recall'].append(recall[1])\n",
    "        bootstrap_stats_class3['recall'].append(recall[2])\n",
    "        bootstrap_stats_class4['recall'].append(recall[3])\n",
    "        bootstrap_stats_class5['recall'].append(recall[4])\n",
    "        bootstrap_stats_class6['recall'].append(recall[5])\n",
    "        \n",
    "        bootstrap_stats_class1['F1'].append(f1[0])\n",
    "        bootstrap_stats_class2['F1'].append(f1[1])\n",
    "        bootstrap_stats_class3['F1'].append(f1[2])\n",
    "        bootstrap_stats_class4['F1'].append(f1[3])\n",
    "        bootstrap_stats_class5['F1'].append(f1[4])\n",
    "        bootstrap_stats_class6['F1'].append(f1[5])\n",
    "\n",
    "        #Calculate and store the accuracy for each subclass.\n",
    "        accuracies = []\n",
    "        for i in range(n_classes):\n",
    "            # Extract the true and predicted labels for the i-th class.\n",
    "            y_true_class = y_test_bootstrap.values\n",
    "            # Calculate the accuracy for the i-th class.\n",
    "            accuracy_class = accuracy_score(y_true_class[:, i], predictions[:, i])\n",
    "            if i==0:\n",
    "                bootstrap_stats_class1['accuracy'].append(accuracy_class)\n",
    "            elif i==1:\n",
    "                bootstrap_stats_class2['accuracy'].append(accuracy_class)\n",
    "            elif i==2:\n",
    "                bootstrap_stats_class3['accuracy'].append(accuracy_class)\n",
    "            elif i==3:\n",
    "                bootstrap_stats_class4['accuracy'].append(accuracy_class)\n",
    "            elif i==4:\n",
    "                bootstrap_stats_class5['accuracy'].append(accuracy_class)\n",
    "            elif i==5:\n",
    "                bootstrap_stats_class6['accuracy'].append(accuracy_class)\n",
    "       \n",
    "        # Calculate and store the specificity for each class\n",
    "        specificities = []\n",
    "        for i in range(n_classes):\n",
    "            #True Negatives = Sum of diagonal elements - True Positives of the current class.\n",
    "            true_negatives = np.sum(mcm[:, 0, 0]) - mcm[i, 0, 0]\n",
    "            # False Positives = Sum of the elements in current row - True Positives.\n",
    "            false_positives = np.sum(mcm[i, 0, 1])\n",
    "            # Calculate specificities\n",
    "            specificity = true_negatives / (true_negatives + false_positives) if (true_negatives + false_positives) > 0 else 0\n",
    "            if i==0:\n",
    "                bootstrap_stats_class1['specificity'].append(specificity)\n",
    "            elif i==1:\n",
    "                bootstrap_stats_class2['specificity'].append(specificity)\n",
    "            elif i==2:\n",
    "                bootstrap_stats_class3['specificity'].append(specificity)\n",
    "            elif i==3:\n",
    "                bootstrap_stats_class4['specificity'].append(specificity)\n",
    "            elif i==4:\n",
    "                bootstrap_stats_class5['specificity'].append(specificity)\n",
    "            elif i==5:\n",
    "                bootstrap_stats_class6['specificity'].append(specificity)\n",
    "\n",
    "        fprs = dict()\n",
    "        tprs = dict()\n",
    "        roc_aucs = dict()\n",
    "        #Calculate the AUROC for each class.\n",
    "        for i in range(n_classes):\n",
    "            fprs[i], tprs[i], _ = roc_curve(y_true_class[:, i], predictions_R[:, i])\n",
    "            roc_aucs[i] = auc(fprs[i], tprs[i])\n",
    "            if i==0:\n",
    "               bootstrap_stats_class1['auc'].append(roc_aucs[0])\n",
    "            elif i==1:\n",
    "               bootstrap_stats_class2['auc'].append(roc_aucs[1])\n",
    "            elif i==2:\n",
    "               bootstrap_stats_class3['auc'].append(roc_aucs[2])\n",
    "            elif i==3:\n",
    "               bootstrap_stats_class4['auc'].append(roc_aucs[3])\n",
    "            elif i==4:\n",
    "               bootstrap_stats_class5['auc'].append(roc_aucs[4])\n",
    "            elif i==5:\n",
    "               bootstrap_stats_class6['auc'].append(roc_aucs[5])\n",
    "\n",
    "\n",
    "        # Calculate the AUPRC for each class.\n",
    "        precisions = dict()\n",
    "        recalls = dict()\n",
    "        pr_aucs = dict()\n",
    "        for i in range(n_classes):\n",
    "            precisions[i], recalls[i], _ = precision_recall_curve(y_true_class[:, i], predictions_R[:, i])\n",
    "            pr_aucs[i] = auc(recalls[i], precisions[i])\n",
    "            if i==0:\n",
    "               bootstrap_stats_class1['prc'].append(pr_aucs[0])\n",
    "            elif i==1:\n",
    "               bootstrap_stats_class2['prc'].append(pr_aucs[1])\n",
    "            elif i==2:\n",
    "               bootstrap_stats_class3['prc'].append(pr_aucs[2])\n",
    "            elif i==3:\n",
    "               bootstrap_stats_class4['prc'].append(pr_aucs[3])\n",
    "            elif i==4:\n",
    "               bootstrap_stats_class5['prc'].append(pr_aucs[4])\n",
    "            elif i==5:\n",
    "               bootstrap_stats_class6['prc'].append(pr_aucs[5])\n",
    "    \n",
    "    return bootstrap_stats, bootstrap_stats_class1, bootstrap_stats_class2, bootstrap_stats_class3, bootstrap_stats_class4, bootstrap_stats_class5, bootstrap_stats_class6\n",
    "    \n",
    "#Automatically identify continuous and binary variables.\n",
    "continuous_vars = []\n",
    "binary_vars = []\n",
    "for col in X1.columns:\n",
    "# Automatically identify binary variables by iterating through each column in the dataset. \n",
    "#If a column is numeric, has exactly two unique values, and those values are 0 and 1, it is considered a binary variable.\n",
    "    if X1[col].dtype.kind in 'biufc' and X1[col].nunique() == 2 and set(X1[col].unique()) == {0, 1}:\n",
    "       binary_vars.append(col)\n",
    "    # Otherwise, it is considered a continuous variable.\n",
    "    else:\n",
    "       continuous_vars.append(col)\n",
    "    # Define variable groups.\n",
    "    groups = {\n",
    "        'Continuous': continuous_vars,\n",
    "         'Binary': binary_vars\n",
    "    }\n",
    "\n",
    "# Apply logarithmic transformation and standardization to continuous variables.\n",
    "log_X1 = X1.copy()\n",
    "log_X1[continuous_vars] = np.log1p(X1[continuous_vars])  #Apply logarithmic transformation to continuous variables.\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = log_X1.copy()\n",
    "X_scaled[continuous_vars] = scaler.fit_transform(X_scaled[continuous_vars])  #Apply standardization to continuous variables.\n",
    "\n",
    "# Perform train - test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.20, random_state=5)\n",
    "\n",
    "#Initialize the lists for classifiers and supports for each label.\n",
    "classifiers1 = []\n",
    "label_supports = []\n",
    "\n",
    "#Perform RFECV feature selection separately for each category label.\n",
    "for j in range(y_train.shape[1]):\n",
    "    rfecv = RFECV(estimator=classifier1, step=1, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    rfecv.fit(X_train, y_train.iloc[:, j])\n",
    "    label_supports.append(rfecv.support_)\n",
    "\n",
    "# Iterate through all combinations of C(num_labels,num_labels) categories.\n",
    "for combo in combinations:\n",
    "    subset = pd.concat([X_train, y_train.loc[:, combo]], axis=1)\n",
    "    filtered_subset = subset[subset.sum(axis=1) > 0]\n",
    "    #filtered_subset = subset[y_train[combo_list].sum(axis=1) > 0]\n",
    "    columns_to_drop = [col for col in combo if col in filtered_subset.columns]\n",
    "    X1_train = filtered_subset.drop(columns_to_drop, axis=1)\n",
    "    y1_train = filtered_subset.loc[:, combo]\n",
    "\n",
    "    #Combine the support features of all labels involved in the current combination.\n",
    "    combo_support = np.logical_or.reduce([label_supports[j] for j in range(y_train.shape[1]) if labels[j] in combo])\n",
    "    \n",
    "    best_clf = None\n",
    "    best_accuracy = 1.0\n",
    "    for train_index, test_index in kf.split(filtered_subset):\n",
    "        X_T_train, X_T_test = X1_train.iloc[train_index], X1_train.iloc[test_index]\n",
    "        y_T_train, y_T_test = y1_train.iloc[train_index], y1_train.iloc[test_index]\n",
    "        #Use the combined support vector(Index vector) to select features.\n",
    "        X_T_train_selected = X_T_train.loc[:, X_T_train.columns[combo_support]]\n",
    "        X_T_test_selected = X_T_test.loc[:, X_T_test.columns[combo_support]]\n",
    "        # Train the classifiers.\n",
    "        co_occurrence_matrix = np.dot(y_T_train.values.T, y_T_train.values) / y_T_train.values.shape[0]\n",
    "        pos_weights = weight_Class (y_T_train)\n",
    "        model = GRIDSEARCH (X_T_train_selected, y_T_train, pos_weights, co_occurrence_matrix)\n",
    "        y_pred_proba, y_pred = predict_Multilabel(model, X_T_test_selected)\n",
    "        hamming_loss_val = hamming_loss(y_T_test, y_pred)\n",
    "        #If the current model's Hamming Loss is smaller, then update the best model.\n",
    "        if hamming_loss_val < best_accuracy:\n",
    "            best_accuracy = hamming_loss_val\n",
    "            best_clf = (model, combo_support)\n",
    "    if best_clf:\n",
    "        classifiers1.append(best_clf)\n",
    "\n",
    "# Use the prediction function for validation with bootstrap\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "bootstrap_stats, bootstrap_stats_class1, bootstrap_stats_class2, bootstrap_stats_class3, bootstrap_stats_class4, bootstrap_stats_class5, bootstrap_stats_class6 = predict_with_rfecv_bootstrap(classifiers1, X_test, y_test, n_bootstrap=500)\n",
    "bootstrap_stat, bootstrap_stat_class1, bootstrap_stat_class2, bootstrap_stat_class3, bootstrap_stat_class4, bootstrap_stat_class5, bootstrap_stat_class6 = predict_with_rfecv_bootstrap(classifiers1, X_train, y_train, n_bootstrap=500)\n",
    "\n",
    "# Print the metric results\n",
    "print(f\"micro- Ave-hamming distance in external validation: {np.mean(bootstrap_stats['han']):.4f}\", f\"micro- Std-hamming distance in external validation: {np.std(bootstrap_stats['han']):.4f}\")\n",
    "print(f\"micro- Ave-sensitivity in external validation: {np.mean(bootstrap_stats['recall']):.4f}\", f\"micro- Std-sensitivity in external validation: {np.std(bootstrap_stats['recall']):.4f}\")\n",
    "print(f\"micro- Ave-AUROC in external validation: {np.mean(bootstrap_stats['auc']):.4f}\", f\"micro- Std-AUROC in external validation: {np.std(bootstrap_stats['auc']):.4f}\")\n",
    "print(f\"micro- Ave-precision in external validation: {np.mean(bootstrap_stats['precision']):.4f}\", f\"micro- Std-precision in external validation: {np.std(bootstrap_stats['precision']):.4f}\")\n",
    "print(f\"subset-Ave-accyracy in external validation: {np.mean(bootstrap_stats['accuracy']):.4f}\", f\"subset- Std-accuracy in external validation: {np.std(bootstrap_stats['accuracy']):.4f}\")\n",
    "print(f\"micro- Ave-F1 in external validation: {np.mean(bootstrap_stats['F1']):.4f}\", f\"micro- Std-F1 in external validation: {np.std(bootstrap_stats['F1']):.4f}\")\n",
    "print(f\"micro- Ave-AUPRC in external validation: {np.mean(bootstrap_stats['prc']):.4f}\", f\"micro- Std-F1 in external validation: {np.std(bootstrap_stats['prc']):.4f}\")\n",
    "\n",
    "print(f\"micro- Ave-hamming distance in internal validation: {np.mean(bootstrap_stat['han']):.4f}\", f\"micro- Std-hamming distance in internal validation: {np.std(bootstrap_stat['han']):.4f}\")\n",
    "print(f\"micro- Ave-sensitivity in internal validation: {np.mean(bootstrap_stat['recall']):.4f}\", f\"micro- Std-sensitivity in internal validation: {np.std(bootstrap_stat['recall']):.4f}\")\n",
    "print(f\"micro- Ave-AUROC in internal validation: {np.mean(bootstrap_stat['auc']):.4f}\", f\"micro- Std-AUROC in internal cross-validation: {np.std(bootstrap_stat['auc']):.4f}\")\n",
    "print(f\"micro- Ave-precision in internal validation: {np.mean(bootstrap_stat['precision']):.4f}\", f\"micro- Std-precision in internal validation:  {np.std(bootstrap_stat['precision']):.4f}\")\n",
    "print(f\"subset-Ave-accyracy in internal validation: {np.mean(bootstrap_stat['accuracy']):.4f}\", f\"subset- Std-accuracy in internal validation: {np.std(bootstrap_stat['accuracy']):.4f}\")\n",
    "print(f\"micro- Ave-F1 in internal validation: {np.mean(bootstrap_stat['F1']):.4f}\", f\"micro- Std-F1 in internal validation: {np.std(bootstrap_stat['F1']):.4f}\")\n",
    "print(f\"micro- Ave-AUPRC in internal validation: {np.mean(bootstrap_stat['prc']):.4f}\", f\"micro- Std-F1 in internal validation: {np.std(bootstrap_stat['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass1- Ave-specificity in external validation: {np.mean(bootstrap_stats_class1['specificity']):.4f}\", f\"subclass1- Std-specificity in external validation: {np.std(bootstrap_stats_class1['specificity']):.4f}\")\n",
    "print(f\"subclass1- Ave-sensitivity in external validation: {np.mean(bootstrap_stats_class1['recall']):.4f}\", f\"subclass1- Std-sensitivity in external validation: {np.std(bootstrap_stats_class1['recall']):.4f}\")\n",
    "print(f\"subclass1- Ave-AUROC in external validation: {np.mean(bootstrap_stats_class1['auc']):.4f}\", f\"subclass1- Std-AUROC in external validation: {np.std(bootstrap_stats_class1['auc']):.4f}\")\n",
    "print(f\"subclass1- Ave-precision in external validation: {np.mean(bootstrap_stats_class1['precision']):.4f}\", f\"subclass1- Std-precision in external validation: {np.std(bootstrap_stats_class1['precision']):.4f}\")\n",
    "print(f\"subclass1- Ave-accyracy in external validation: {np.mean(bootstrap_stats_class1['accuracy']):.4f}\", f\"subclass1- Std-accuracy in external validation: {np.std(bootstrap_stats_class1['accuracy']):.4f}\")\n",
    "print(f\"subclass1- Ave-F1 in external validation: {np.mean(bootstrap_stats_class1['F1']):.4f}\", f\"subclass1- Std-F1 in external validation: {np.std(bootstrap_stats_class1['F1']):.4f}\")\n",
    "print(f\"subclass1- Ave-AUPRC in external validation: {np.mean(bootstrap_stats_class1['prc']):.4f}\", f\"subclass1- Std-AUPRC in external validation: {np.std(bootstrap_stats_class1['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass2- Ave-specificity in external validation: {np.mean(bootstrap_stats_class2['specificity']):.4f}\", f\"subclass2- Std-specificity in external validation: {np.std(bootstrap_stats_class2['specificity']):.4f}\")\n",
    "print(f\"subclass2- Ave-sensitivity in external validation: {np.mean(bootstrap_stats_class2['recall']):.4f}\", f\"subclass2- Std-sensitivity in external validation: {np.std(bootstrap_stats_class2['recall']):.4f}\")\n",
    "print(f\"subclass2- Ave-AUROC in external validation: {np.mean(bootstrap_stats_class2['auc']):.4f}\", f\"subclass2- Std-AUROC in external validation: {np.std(bootstrap_stats_class2['auc']):.4f}\")\n",
    "print(f\"subclass2- Ave-precision in external validation: {np.mean(bootstrap_stats_class2['precision']):.4f}\", f\"subclass2- Std-precision in external validation: {np.std(bootstrap_stats_class2['precision']):.4f}\")\n",
    "print(f\"subclass2- Ave-accyracy in external validation: {np.mean(bootstrap_stats_class2['accuracy']):.4f}\", f\"subclass2- Std-accuracy in external validation: {np.std(bootstrap_stats_class2['accuracy']):.4f}\")\n",
    "print(f\"subclass2- Ave-F1 in external validation: {np.mean(bootstrap_stats_class2['F1']):.4f}\", f\"subclass2- Std-F1 in external validation: {np.std(bootstrap_stats_class2['F1']):.4f}\")\n",
    "print(f\"subclass2- Ave-AUPRC in external validation: {np.mean(bootstrap_stats_class2['prc']):.4f}\", f\"subclass2- Std-AUPRC in external validation: {np.std(bootstrap_stats_class2['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass3- Ave-specificity in external validation: {np.mean(bootstrap_stats_class3['specificity']):.4f}\", f\"subclass3- Std-specificity in external validation: {np.std(bootstrap_stats_class3['specificity']):.4f}\")\n",
    "print(f\"subclass3- Ave-sensitivity in external validation: {np.mean(bootstrap_stats_class3['recall']):.4f}\", f\"subclass3- Std-sensitivity in external validation: {np.std(bootstrap_stats_class3['recall']):.4f}\")\n",
    "print(f\"subclass3- Ave-AUROC in external validation: {np.mean(bootstrap_stats_class3['auc']):.4f}\", f\"subclass3- Std-AUROC in external validation: {np.std(bootstrap_stats_class3['auc']):.4f}\")\n",
    "print(f\"subclass3- Ave-precision in external validation: {np.mean(bootstrap_stats_class3['precision']):.4f}\", f\"subclass3- Std-precision in external validation: {np.std(bootstrap_stats_class3['precision']):.4f}\")\n",
    "print(f\"subclass3- Ave-accyracy in external validation: {np.mean(bootstrap_stats_class3['accuracy']):.4f}\", f\"subclass3- Std-accuracy in external validation: {np.std(bootstrap_stats_class3['accuracy']):.4f}\")\n",
    "print(f\"subclass3- Ave-F1 in external validation: {np.mean(bootstrap_stats_class3['F1']):.4f}\", f\"subclass3- Std-F1 in external validation: {np.std(bootstrap_stats_class3['F1']):.4f}\")\n",
    "print(f\"subclass3- Ave-AUPRC in external validation: {np.mean(bootstrap_stats_class3['prc']):.4f}\", f\"subclass3- Std-AUPRC in external validation: {np.std(bootstrap_stats_class3['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass4- Ave-specificity in external validation: {np.mean(bootstrap_stats_class4['specificity']):.4f}\", f\"subclass4- Std-specificity in external validation: {np.std(bootstrap_stats_class4['specificity']):.4f}\")\n",
    "print(f\"subclass4- Ave-sensitivity in external validation: {np.mean(bootstrap_stats_class4['recall']):.4f}\", f\"subclass4- Std-sensitivity in external validation: {np.std(bootstrap_stats_class4['recall']):.4f}\")\n",
    "print(f\"subclass4- Ave-AUROC in external validation: {np.mean(bootstrap_stats_class4['auc']):.4f}\", f\"subclass4- Std-AUROC in external validation: {np.std(bootstrap_stats_class4['auc']):.4f}\")\n",
    "print(f\"subclass4- Ave-precision in external validation: {np.mean(bootstrap_stats_class4['precision']):.4f}\", f\"subclass4- Std-precision in external validation: {np.std(bootstrap_stats_class4['precision']):.4f}\")\n",
    "print(f\"subclass4- Ave-accyracy in external validation: {np.mean(bootstrap_stats_class4['accuracy']):.4f}\", f\"subclass4- Std-accuracy in external validation: {np.std(bootstrap_stats_class4['accuracy']):.4f}\")\n",
    "print(f\"subclass4- Ave-F1 in external validation: {np.mean(bootstrap_stats_class4['F1']):.4f}\", f\"subclass4- Std-F1 in external validation: {np.std(bootstrap_stats_class4['F1']):.4f}\")\n",
    "print(f\"subclass4- Ave-AUPRC in external validation: {np.mean(bootstrap_stats_class4['prc']):.4f}\", f\"subclass4- Std-AUPRC in external validation: {np.std(bootstrap_stats_class4['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass5- Ave-specificity in external validation:{np.mean(bootstrap_stats_class5['specificity']):.4f}\", f\"subclass5- Std-specificity in external validation: {np.std(bootstrap_stats_class5['specificity']):.4f}\")\n",
    "print(f\"subclass5- Ave-sensitivity in external validation: {np.mean(bootstrap_stats_class5['recall']):.4f}\", f\"subclass5- Std-sensitivity in external validation:{np.std(bootstrap_stats_class5['recall']):.4f}\")\n",
    "print(f\"subclass5- Ave-AUROC in external validation:{np.mean(bootstrap_stats_class5['auc']):.4f}\", f\"subclass5- Std-AUROC in external validation: {np.std(bootstrap_stats_class5['auc']):.4f}\")\n",
    "print(f\"subclass5- Ave-precision in external validation: {np.mean(bootstrap_stats_class5['precision']):.4f}\", f\"subclass5- Std-precision in external validation: {np.std(bootstrap_stats_class5['precision']):.4f}\")\n",
    "print(f\"subclass5- Ave-accyracy in external validation: {np.mean(bootstrap_stats_class5['accuracy']):.4f}\", f\"subclass5- Std-accuracy in external validation: {np.std(bootstrap_stats_class5['accuracy']):.4f}\")\n",
    "print(f\"subclass5- Ave-F1 in external validation: {np.mean(bootstrap_stats_class5['F1']):.4f}\", f\"subclass5- Std-F1 in external validation: {np.std(bootstrap_stats_class5['F1']):.4f}\")\n",
    "print(f\"subclass5- Ave-AUPRC in external validation: {np.mean(bootstrap_stats_class5['prc']):.4f}\", f\"subclass5- Std-AUPRC in external validation: {np.std(bootstrap_stats_class5['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass6- Ave-specificity in external validation: {np.mean(bootstrap_stats_class6['specificity']):.4f}\", f\"subclass6- Std-specificity in external validation: {np.std(bootstrap_stats_class6['specificity']):.4f}\")\n",
    "print(f\"subclass6- Ave-sensitivity in external validation: {np.mean(bootstrap_stats_class6['recall']):.4f}\", f\"subclass6- Std-sensitivity in external validation: {np.std(bootstrap_stats_class6['recall']):.4f}\")\n",
    "print(f\"subclass6- Ave-AUROC in external validation: {np.mean(bootstrap_stats_class6['auc']):.4f}\", f\"subclass6- Std-AUROC in external validation: {np.std(bootstrap_stats_class6['auc']):.4f}\")\n",
    "print(f\"subclass6- Ave-precision in external validation: {np.mean(bootstrap_stats_class6['precision']):.4f}\", f\"subclass6- Std-precision in external validation: {np.std(bootstrap_stats_class6['precision']):.4f}\")\n",
    "print(f\"subclass6- Ave-accyracy in external validation: {np.mean(bootstrap_stats_class6['accuracy']):.4f}\", f\"subclass6- Std-accuracy in external validation: {np.std(bootstrap_stats_class6['accuracy']):.4f}\")\n",
    "print(f\"subclass6- Ave-F1 in external validation: {np.mean(bootstrap_stats_class6['F1']):.4f}\", f\"subclass6- Std-F1 in external validation: {np.std(bootstrap_stats_class6['F1']):.4f}\")\n",
    "print(f\"subclass6- Ave-AUPRC in external validation: {np.mean(bootstrap_stats_class6['prc']):.4f}\", f\"subclass6- Std-AUPRC in external validation: {np.std(bootstrap_stats_class6['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass1- Ave-specificity in internal validation: {np.mean(bootstrap_stat_class1['specificity']):.4f}\", f\"subclass1- Std-specificity in internal validation: {np.std(bootstrap_stat_class1['specificity']):.4f}\")\n",
    "print(f\"subclass1- Ave-sensitivity in internal validation: {np.mean(bootstrap_stat_class1['recall']):.4f}\", f\"subclass1- Std-sensitivity in internal validation: {np.std(bootstrap_stat_class1['recall']):.4f}\")\n",
    "print(f\"subclass1- Ave-AUROC in internal validation: {np.mean(bootstrap_stat_class1['auc']):.4f}\", f\"subclass1- Std-AUROC in internal validation: {np.std(bootstrap_stat_class1['auc']):.4f}\")\n",
    "print(f\"subclass1- Ave-precision in internal validation: {np.mean(bootstrap_stat_class1['precision']):.4f}\", f\"subclass1- Std-precision in internal validation: {np.std(bootstrap_stat_class1['precision']):.4f}\")\n",
    "print(f\"subclass1- Ave-accyracy in internal validation: {np.mean(bootstrap_stat_class1['accuracy']):.4f}\", f\"subclass1- Std-accuracy in internal validation: {np.std(bootstrap_stat_class1['accuracy']):.4f}\")\n",
    "print(f\"subclass1- Ave-F1 in internal validation: {np.mean(bootstrap_stat_class1['F1']):.4f}\", f\"subclass1- Std-F1 in internal validation: {np.std(bootstrap_stat_class1['F1']):.4f}\")\n",
    "print(f\"subclass1- Ave-AUPRC in internal validation: {np.mean(bootstrap_stat_class1['prc']):.4f}\", f\"subclass1- Std-AUPRC in internal validation: {np.std(bootstrap_stat_class1['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass2- Ave-specificity in internal validation: {np.mean(bootstrap_stat_class2['specificity']):.4f}\", f\"subclass2- Std-specificity in internal validation: {np.std(bootstrap_stat_class2['specificity']):.4f}\")\n",
    "print(f\"subclass2- Ave-sensitivity in internal validation: {np.mean(bootstrap_stat_class2['recall']):.4f}\", f\"subclass2- Std-sensitivity in internal validation: {np.std(bootstrap_stat_class2['recall']):.4f}\")\n",
    "print(f\"subclass2- Ave-AUROC in internal validation: {np.mean(bootstrap_stat_class2['auc']):.4f}\", f\"subclass2- Std-AUROC in internal validation: {np.std(bootstrap_stat_class2['auc']):.4f}\")\n",
    "print(f\"subclass2- Ave-precision in internal validation: {np.mean(bootstrap_stat_class2['precision']):.4f}\", f\"subclass2- Std-precision in internal validation: {np.std(bootstrap_stat_class2['precision']):.4f}\")\n",
    "print(f\"subclass2- Ave-accyracy in internal validation: {np.mean(bootstrap_stat_class2['accuracy']):.4f}\", f\"subclass2- Std-accuracy in internal validation: {np.std(bootstrap_stat_class2['accuracy']):.4f}\")\n",
    "print(f\"subclass2- Ave-F1 in internal validation: {np.mean(bootstrap_stat_class2['F1']):.4f}\", f\"subclass2- Std-F1 in internal validation: {np.std(bootstrap_stat_class2['F1']):.4f}\")\n",
    "print(f\"subclass2- Ave-AUPRC in internal cross-validation: {np.mean(bootstrap_stat_class2['prc']):.4f}\", f\"subclass2- Std-AUPRC in internal validation: {np.std(bootstrap_stat_class2['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass3- Ave-specificity in internal validation: {np.mean(bootstrap_stat_class3['specificity']):.4f}\", f\"subclass3- Std-specificity in internal validation: {np.std(bootstrap_stat_class3['specificity']):.4f}\")\n",
    "print(f\"subclass3- Ave-sensitivity in internal validation: {np.mean(bootstrap_stat_class3['recall']):.4f}\", f\"subclass3- Std-sensitivity in internal validation: {np.std(bootstrap_stat_class3['recall']):.4f}\")\n",
    "print(f\"subclass3- Ave-AUROC in internal validation: {np.mean(bootstrap_stat_class3['auc']):.4f}\", f\"subclass3- Std-AUROC in internal validation: {np.std(bootstrap_stat_class3['auc']):.4f}\")\n",
    "print(f\"subclass3- Ave-precision in internal validation: {np.mean(bootstrap_stat_class3['precision']):.4f}\", f\"subclass3- Std-precision in internal validation: {np.std(bootstrap_stat_class3['precision']):.4f}\")\n",
    "print(f\"subclass3- Ave-accyracy in internal validation: {np.mean(bootstrap_stat_class3['accuracy']):.4f}\", f\"subclass3- Std-accuracy in internal validation: {np.std(bootstrap_stat_class3['accuracy']):.4f}\")\n",
    "print(f\"subclass3- Ave-F1 in internal validation: {np.mean(bootstrap_stat_class3['F1']):.4f}\", f\"subclass3- Std-F1 in internal validation: {np.std(bootstrap_stat_class3['F1']):.4f}\")\n",
    "print(f\"subclass3- Ave-AUPRC in internal validation: {np.mean(bootstrap_stat_class3['prc']):.4f}\", f\"subclass3 Std-AUPRC in internal validation: {np.std(bootstrap_stat_class3['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass4- Ave-specificity in internal validation: {np.mean(bootstrap_stat_class4['specificity']):.4f}\", f\"subclass4- Std-specificity in internal validation: {np.std(bootstrap_stat_class4['specificity']):.4f}\")\n",
    "print(f\"subclass4- Ave-sensitivity in internal validation: {np.mean(bootstrap_stat_class4['recall']):.4f}\", f\"subclass4- Std-sensitivity in internal validation: {np.std(bootstrap_stat_class4['recall']):.4f}\")\n",
    "print(f\"subclass4- Ave-AUROC in internal validation:{np.mean(bootstrap_stat_class4['auc']):.4f}\", f\"subclass4- Std-AUROC in internal validation: {np.std(bootstrap_stat_class4['auc']):.4f}\")\n",
    "print(f\"subclass4- Ave-precision in internal validation: {np.mean(bootstrap_stat_class4['precision']):.4f}\", f\"subclass4- Std-precision in internal validation: {np.std(bootstrap_stat_class4['precision']):.4f}\")\n",
    "print(f\"subclass4- Ave-accyracy in internal validation: {np.mean(bootstrap_stat_class4['accuracy']):.4f}\", f\"subclass4- Std-accuracy in internal validation: {np.std(bootstrap_stat_class4['accuracy']):.4f}\")\n",
    "print(f\"subclass4- Ave-F1 in internal validation:{np.mean(bootstrap_stat_class4['F1']):.4f}\", f\"subclass4- Std-F1 in internal validation: {np.std(bootstrap_stat_class4['F1']):.4f}\")\n",
    "print(f\"subclass4- Ave-AUPRC in internal validation: {np.mean(bootstrap_stat_class4['prc']):.4f}\", f\"subclass4- Std-AUPRC in internal validation: {np.std(bootstrap_stat_class4['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass5- Ave-specificity in internal validation: {np.mean(bootstrap_stat_class5['specificity']):.4f}\", f\"subclass5- Std-specificity in internal validation: {np.std(bootstrap_stat_class5['specificity']):.4f}\")\n",
    "print(f\"subclass5- Ave-sensitivity in internal validation: {np.mean(bootstrap_stat_class5['recall']):.4f}\", f\"subclass5- Std-sensitivity in internal validation: {np.std(bootstrap_stat_class5['recall']):.4f}\")\n",
    "print(f\"subclass5- Ave-AUROC in internal validation: {np.mean(bootstrap_stat_class5['auc']):.4f}\", f\"subclass5- Std-AUROC in internal validation: {np.std(bootstrap_stat_class5['auc']):.4f}\")\n",
    "print(f\"subclass5- Ave-precision in internal validation: {np.mean(bootstrap_stat_class5['precision']):.4f}\", f\"subclass5- Std-precision in internal validation: {np.std(bootstrap_stat_class5['precision']):.4f}\")\n",
    "print(f\"subclass5- Ave-accyracy in internal validation: {np.mean(bootstrap_stat_class5['accuracy']):.4f}\", f\"subclass5- Std-accuracy in internal validation: {np.std(bootstrap_stat_class5['accuracy']):.4f}\")\n",
    "print(f\"subclass5- Ave-F1 in internal validation: {np.mean(bootstrap_stat_class5['F1']):.4f}\", f\"subclass5- Std-F1 in internal validation: {np.std(bootstrap_stat_class5['F1']):.4f}\")\n",
    "print(f\"subclass5- Ave-AUPRC in internal alidation: {np.mean(bootstrap_stat_class5['prc']):.4f}\", f\"subclass5- Std-AUPRC in internal validation: {np.std(bootstrap_stat_class5['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass6- Ave-specificity in internal validation: {np.mean(bootstrap_stat_class6['specificity']):.4f}\", f\"subclass6- Std-specificity in internal validation: {np.std(bootstrap_stat_class6['specificity']):.4f}\")\n",
    "print(f\"subclass6- Ave-sensitivity in internal validation: {np.mean(bootstrap_stat_class6['recall']):.4f}\", f\"subclass6- Std-sensitivity in internal validation: {np.std(bootstrap_stat_class6['recall']):.4f}\")\n",
    "print(f\"subclass6- Ave-AUROC in internal validation:{np.mean(bootstrap_stat_class6['auc']):.4f}\", f\"subclass6- Std-AUROC in internal validation: {np.std(bootstrap_stat_class6['auc']):.4f}\")\n",
    "print(f\"subclass6- Ave-precision in internal validation: {np.mean(bootstrap_stat_class6['precision']):.4f}\", f\"subclass6- Std-precision in internal validation: {np.std(bootstrap_stat_class6['precision']):.4f}\")\n",
    "print(f\"subclass6- Ave-accyracy in internal validation:: {np.mean(bootstrap_stat_class6['accuracy']):.4f}\", f\"subclass6- Std-accuracy in internal validation: {np.std(bootstrap_stat_class6['accuracy']):.4f}\")\n",
    "print(f\"subclass6- Ave-F1 in internal validation: {np.mean(bootstrap_stat_class6['F1']):.4f}\", f\"subclass6- Std-F1 in internal validation: {np.std(bootstrap_stat_class6['F1']):.4f}\")\n",
    "print(f\"subclass6- Ave-AUPRC in internal validation:{np.mean(bootstrap_stat_class6['prc']):.4f}\", f\"subclass6- Std-AUPRC in internal validation: {np.std(bootstrap_stat_class6['prc']):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23172b5b-16c3-453b-8d9b-6486774fee99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
