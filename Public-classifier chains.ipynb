{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35322b4-814c-4189-9da2-6c5777327aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the code for diesease pre-diagnosis using the Classifier—chain approach.\n",
    "#SVM, Logistic Regression, XGBoost and Random forest were avaliable using this code\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "matplotlib.rcParams['font.sans-serif']=['SimHei']\n",
    "matplotlib.rcParams['axes.unicode_minus']= False\n",
    "matplotlib.rcParams['font.size']= 11\n",
    "from pandas import DataFrame\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import RocCurveDisplay, roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import hamming_loss, f1_score, precision_score, recall_score, precision_recall_curve\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_classif,f_classif\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, StandardScaler\n",
    "from sklearn.utils import resample\n",
    "import warnings\n",
    "\n",
    "list = []\n",
    "# This section imports the data. We provide demo data “Demo.csv” for code implementation.\n",
    "filepath = \"C:\\\\Users\\\\PS\\\\Desktop\\\\Open code\\\\Demo.csv\" #Set the user's own path.\n",
    "df1=[]\n",
    "df1 = pd.read_csv(filepath, header=0, encoding=\"gbk\")\n",
    "X1 = df1.drop([\"Pancreas disease\", \"Biliary tract disease\", \"Gastroduodenal disease\", \"Intestinal tract disease\", \"liver disease\", \"others\"], axis=1)\n",
    "y1 = df1[[\"Pancreas disease\", \"Intestinal tract disease\", \"liver disease\", \"Biliary tract disease\", \"Gastroduodenal disease\", \"others\"]]\n",
    "y= y1.values\n",
    "\n",
    "#This section initializes the model. Choose one of the four models(SVM, LR, XGBoost, RF) and ensure consistent model selection throughout.\n",
    "#SVM\n",
    "classifier5 = SVC(C=1.0, gamma='auto', kernel='linear', class_weight='balanced', tol=1e-2, probability=True)\n",
    "\n",
    "#Logistic Regression\n",
    "#classifier1 = LogisticRegression(penalty='l2', dual=False, tol=1e-3, C=1.0, fit_intercept=True,\n",
    "                                #intercept_scaling=1, class_weight='balanced', random_state=None,\n",
    "                                #max_iter=100,verbose=0,warm_start=False, n_jobs=-1)\n",
    "#XGBoost\n",
    "#classifier4= XGBClassifier(base_score=0.5,booster='gbtree',colsample_bylevel=1,\n",
    "                            #colsample_bynode=1,colsample_bytree=1,gamma=0.1,\n",
    "                            #learning_rate=0.3,max_delta_step=0, max_depth=9,\n",
    "                            #min_child_weight=1,n_estimators=200,n_jobs=-1,\n",
    "                            #nthread=None,objective='binary:logistic', reg_alpha=0,\n",
    "                            #reg_lambda=1,scale_pos_weight=1,silent=None,\n",
    "                            #subsample=1,verbosity=1)\n",
    "\n",
    "#Random forest\n",
    "#classifier2 = RandomForestClassifier(n_estimators=100, class_weight='balanced', n_jobs=-1)\n",
    "\n",
    "\n",
    "#This function calculates class weights. This function matches the XGBoost model.\n",
    "def weight_Class (y):\n",
    "    # Calculate weight of each subclass.\n",
    "    counts = sum(y)\n",
    "    total_samples = len(y)\n",
    "    weights = total_samples / counts\n",
    "    \n",
    "    return weights\n",
    "\n",
    "#This function performs model training and outputs the optimal model, incorporating 5-fold cross-validation.\n",
    "def CV_train(classifier, param_grid, X, y):\n",
    "    #N-fold internal cross-validation\n",
    "    N = 5\n",
    "    kf = KFold(n_splits=N, shuffle=True, random_state=3)\n",
    "    grid_search = GridSearchCV(estimator = classifier, param_grid=param_grid, scoring='roc_auc', cv=kf, n_jobs=-1)\n",
    "    best_accuracy = 0\n",
    "    best_clf = None\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]       \n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        #Prediction\n",
    "        pred_train = best_model.predict(X_train)\n",
    "        pred_test = best_model.predict_proba(X_test)\n",
    "        #Here the model evaluation criterion is selected. In this example, ROC-AUC is chosen.\n",
    "        accuracy_val = roc_auc_score(y_test, pred_test[:, 1])\n",
    "        if accuracy_val > best_accuracy:\n",
    "           best_accuracy = accuracy_val\n",
    "           best_clf = best_model\n",
    "    return best_clf  \n",
    "\n",
    "# External validation funciton with bootstrap \n",
    "def bootstrap_with_roc(classifiers, X, y, n_iterations):\n",
    "\n",
    "    #Storage space for results\n",
    "    bootstrap_stats= {\n",
    "        'recall': [],\n",
    "        'auc': [],\n",
    "        'prc': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],  \n",
    "        'F1': [],\n",
    "        'han':[]\n",
    "    }\n",
    "    bootstrap_stats_class1= {\n",
    "        'recall': [],\n",
    "        'specificity': [],\n",
    "        'auc': [],\n",
    "        'prc': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],  \n",
    "        'F1': [] \n",
    "    }\n",
    "    bootstrap_stats_class2={\n",
    "        'recall': [],\n",
    "        'specificity': [],\n",
    "        'auc': [],\n",
    "        'prc': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],  \n",
    "        'F1': [] \n",
    "    }\n",
    "    bootstrap_stats_class3= {\n",
    "        'recall': [],\n",
    "        'specificity': [],\n",
    "        'auc': [],\n",
    "        'prc': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],  \n",
    "        'F1': [] \n",
    "    }\n",
    "    bootstrap_stats_class4= {\n",
    "        'recall': [],\n",
    "        'specificity': [],\n",
    "        'auc': [],\n",
    "        'prc': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],  \n",
    "        'F1': [] \n",
    "    }\n",
    "    bootstrap_stats_class5= {\n",
    "        'recall': [],\n",
    "        'specificity': [],\n",
    "        'auc': [],\n",
    "        'prc': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],  \n",
    "        'F1': [] \n",
    "    }\n",
    "    bootstrap_stats_class6= {\n",
    "        'recall': [],\n",
    "        'specificity': [],\n",
    "        'auc': [],\n",
    "        'prc': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],  \n",
    "        'F1': [] \n",
    "    }\n",
    "    \n",
    "    #Transform y into a multi-label dataFrame\n",
    "    num_samples = X.shape[0]\n",
    "    y = pd.DataFrame(y, columns=[f'pred_{j}' for j in range(6)])\n",
    "    num_classifiers = len(classifiers)\n",
    "\n",
    "    for b in range(n_iterations):\n",
    "        #resample in bootstrap\n",
    "        indices_resampled = resample(X.index, n_samples=num_samples, replace=True, random_state=b)\n",
    "        X_resampled = X.loc[indices_resampled].reset_index(drop=True)\n",
    "        y_test = y.loc[indices_resampled].reset_index(drop=True)\n",
    "        y_test_labels= y_test.values\n",
    "        predictions = np.zeros((num_samples, num_classifiers), dtype=float)  # Floating - point numbers are adopted to maintain precision\n",
    "        predictions_p = np.zeros((num_samples, num_classifiers), dtype=float)  # Floating - point numbers are adopted to maintain precision  \n",
    "        for i, (clf, support) in enumerate(classifiers):\n",
    "            X_selected = X_resampled.iloc[:, support]  # Select the features supported by the current classifier\n",
    "            if i > 0:\n",
    "               prev_predictions = predictions[:, :i]  # Retrieve the previous diesease predictions of the previous classifier\n",
    "               prev_predictions_df = pd.DataFrame(prev_predictions, columns=[f'pred_{j}' for j in range(i)])\n",
    "               X_selected_T = pd.concat([X_selected, prev_predictions_df], axis=1)\n",
    "               predictions_b = clf.predict(X_selected_T.values)\n",
    "               predictions_b_prob = clf.predict_proba(X_selected_T.values) \n",
    "            else: \n",
    "               predictions_b = clf.predict(X_selected)\n",
    "               predictions_b_prob = clf.predict_proba(X_selected) \n",
    "            # Store the predictions of the current classifier.\n",
    "            predictions[:, i] += predictions_b\n",
    "            # Store the prediction probabilities of the current classifier for future use.\n",
    "            predictions_p[:, i] += predictions_b_prob[:, 1]\n",
    "\n",
    "        #This section calculates and stores the micro - metrics.\n",
    "        hamming_loss_val = hamming_loss(y_test_labels, predictions) #hamming_loss\n",
    "        f1_val = f1_score(y_test_labels, predictions, average='micro') #micro-F1\n",
    "        precision_val = precision_score(y_test_labels, predictions, average='micro') #Micro-precision\n",
    "        accuracy_val = accuracy_score(y_test_labels, predictions) # Micro-accuracy\n",
    "        recall_val = recall_score(y_test_labels, predictions, average='micro') #Mirco-recall\n",
    "        micro_auc = roc_auc_score(y_test_labels.ravel(), predictions_p.ravel(), average='micro') #Mirco-AUROC\n",
    "        precisionq, recallq, _ = precision_recall_curve(y_test_labels.ravel(), predictions_p.ravel())\n",
    "        micro_prc_auc = auc(recallq, precisionq) # 计算 Micro-AUPRC\n",
    "        bootstrap_stats['recall'].append(recall_val)\n",
    "        bootstrap_stats['precision'].append(precision_val)\n",
    "        bootstrap_stats['accuracy'].append(accuracy_val)\n",
    "        bootstrap_stats['F1'].append(f1_val)\n",
    "        bootstrap_stats['auc'].append(micro_auc)\n",
    "        bootstrap_stats['prc'].append(micro_prc_auc)\n",
    "        bootstrap_stats['han'].append(hamming_loss_val)\n",
    "        \n",
    "        # Calculate the multi-label confusion matrix.\n",
    "        mcm = multilabel_confusion_matrix(y_test_labels, predictions)\n",
    "        # Compute and store the precision, recall, and F1 score for each subclass.\n",
    "        n_classes = y.shape[1]\n",
    "        precision = precision_score(y_test_labels, predictions, average=None)\n",
    "        recall = recall_score(y_test_labels, predictions, average=None)\n",
    "        f1 = f1_score(y_test_labels, predictions, average=None)\n",
    "        bootstrap_stats_class1['precision'].append(precision[0])\n",
    "        bootstrap_stats_class2['precision'].append(precision[1])\n",
    "        bootstrap_stats_class3['precision'].append(precision[2])\n",
    "        bootstrap_stats_class4['precision'].append(precision[3])\n",
    "        bootstrap_stats_class5['precision'].append(precision[4])\n",
    "        bootstrap_stats_class6['precision'].append(precision[5])\n",
    "        bootstrap_stats_class1['recall'].append(recall[0])\n",
    "        bootstrap_stats_class2['recall'].append(recall[1])\n",
    "        bootstrap_stats_class3['recall'].append(recall[2])\n",
    "        bootstrap_stats_class4['recall'].append(recall[3])\n",
    "        bootstrap_stats_class5['recall'].append(recall[4])\n",
    "        bootstrap_stats_class6['recall'].append(recall[5])\n",
    "        bootstrap_stats_class1['F1'].append(f1[0])\n",
    "        bootstrap_stats_class2['F1'].append(f1[1])\n",
    "        bootstrap_stats_class3['F1'].append(f1[2])\n",
    "        bootstrap_stats_class4['F1'].append(f1[3])\n",
    "        bootstrap_stats_class5['F1'].append(f1[4])\n",
    "        bootstrap_stats_class6['F1'].append(f1[5])\n",
    "\n",
    "        #Calculate and store the accuracy for each subclass.\n",
    "        accuracies = []\n",
    "        for i in range(n_classes):\n",
    "            # Extract the true and predicted labels for the i-th class.\n",
    "            y_true_class = y_test_labels[:, i]\n",
    "            y_pred_class = predictions[:, i]  # Use binary labels for the i-th class.\n",
    "            # Calculate the accuracy for the i-th class.\n",
    "            accuracy_class = accuracy_score(y_test_labels[:, i], y_pred_class)\n",
    "            if i==0:\n",
    "               bootstrap_stats_class1['accuracy'].append(accuracy_class)\n",
    "            elif i==1:\n",
    "               bootstrap_stats_class2['accuracy'].append(accuracy_class)\n",
    "            elif i==2:\n",
    "               bootstrap_stats_class3['accuracy'].append(accuracy_class)\n",
    "            elif i==3:\n",
    "               bootstrap_stats_class4['accuracy'].append(accuracy_class)\n",
    "            elif i==4:\n",
    "               bootstrap_stats_class5['accuracy'].append(accuracy_class)\n",
    "            elif i==5:\n",
    "               bootstrap_stats_class6['accuracy'].append(accuracy_class)\n",
    "\n",
    "        # Calculate and store the specificity for each class\n",
    "        specificities = []\n",
    "        for i in range(n_classes):\n",
    "            #True Negatives = Sum of diagonal elements - True Positives of the current class.\n",
    "            true_negatives = np.sum(mcm[:, 0, 0]) - mcm[i, 0, 0]\n",
    "            # False Positives = Sum of the elements in current row - True Positives.\n",
    "            false_positives = np.sum(mcm[i, 0, 1])\n",
    "            # Calculate specificities\n",
    "            specificity = true_negatives / (true_negatives + false_positives) if (true_negatives + false_positives) > 0 else 0\n",
    "            if i==0:\n",
    "               bootstrap_stats_class1['specificity'].append(specificity)\n",
    "            elif i==1:\n",
    "               bootstrap_stats_class2['specificity'].append(specificity)\n",
    "            elif i==2:\n",
    "               bootstrap_stats_class3['specificity'].append(specificity)\n",
    "            elif i==3:\n",
    "               bootstrap_stats_class4['specificity'].append(specificity)\n",
    "            elif i==4:\n",
    "               bootstrap_stats_class5['specificity'].append(specificity)\n",
    "            elif i==5:\n",
    "               bootstrap_stats_class6['specificity'].append(specificity)\n",
    "\n",
    "        #Calculate and store AUROC for each class\n",
    "        fprs = dict()\n",
    "        tprs = dict()\n",
    "        roc_aucs = dict()\n",
    "        for i in range(n_classes):\n",
    "            fprs[i], tprs[i], _ = roc_curve(y_test_labels[:, i], predictions_p[:, i])\n",
    "            roc_aucs[i] = auc(fprs[i], tprs[i])\n",
    "            if i==0:\n",
    "               bootstrap_stats_class1['auc'].append(roc_aucs[0])\n",
    "            elif i==1:\n",
    "               bootstrap_stats_class2['auc'].append(roc_aucs[1])\n",
    "            elif i==2:\n",
    "               bootstrap_stats_class3['auc'].append(roc_aucs[2])\n",
    "            elif i==3:\n",
    "               bootstrap_stats_class4['auc'].append(roc_aucs[3])\n",
    "            elif i==4:\n",
    "               bootstrap_stats_class5['auc'].append(roc_aucs[4])\n",
    "            elif i==5:\n",
    "               bootstrap_stats_class6['auc'].append(roc_aucs[5])\n",
    "\n",
    "        #Calculate and store AUPRC for each class\n",
    "        precisions = dict()\n",
    "        recalls = dict()\n",
    "        pr_aucs = dict()\n",
    "        for i in range(n_classes):\n",
    "            precisions[i], recalls[i], _ = precision_recall_curve(y_test_labels[:, i], predictions_p[:, i])\n",
    "            pr_aucs[i] = auc(recalls[i], precisions[i])\n",
    "            if i==0:\n",
    "               bootstrap_stats_class1['prc'].append(pr_aucs[0])\n",
    "            elif i==1:\n",
    "               bootstrap_stats_class2['prc'].append(pr_aucs[1])\n",
    "            elif i==2:\n",
    "               bootstrap_stats_class3['prc'].append(pr_aucs[2])\n",
    "            elif i==3:\n",
    "               bootstrap_stats_class4['prc'].append(pr_aucs[3])\n",
    "            elif i==4:\n",
    "               bootstrap_stats_class5['prc'].append(pr_aucs[4])\n",
    "            elif i==5:\n",
    "               bootstrap_stats_class6['prc'].append(pr_aucs[5])\n",
    "\n",
    "    return bootstrap_stats, bootstrap_stats_class1, bootstrap_stats_class2, bootstrap_stats_class3, bootstrap_stats_class4, bootstrap_stats_class5, bootstrap_stats_class6\n",
    "\n",
    "\n",
    "#Automatically identify continuous and binary variables.\n",
    "continuous_vars = []\n",
    "binary_vars = []\n",
    "for col in X1.columns:\n",
    "# Automatically identify binary variables by iterating through each column in the dataset. \n",
    "#If a column is numeric, has exactly two unique values, and those values are 0 and 1, it is considered a binary variable.\n",
    "    if X1[col].dtype.kind in 'biufc' and X1[col].nunique() == 2 and set(X1[col].unique()) == {0, 1}:\n",
    "       binary_vars.append(col)\n",
    "    # Otherwise, it is considered a continuous variable.\n",
    "    else:\n",
    "       continuous_vars.append(col)\n",
    "    # Define variable groups.\n",
    "    groups = {\n",
    "        'Continuous': continuous_vars,\n",
    "         'Binary': binary_vars\n",
    "    }\n",
    "\n",
    "# Apply logarithmic transformation and standardization to continuous variables.\n",
    "log_X1 = X1.copy()\n",
    "log_X1[continuous_vars] = np.log1p(X1[continuous_vars])  #Apply logarithmic transformation to continuous variables.\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = log_X1.copy()\n",
    "X_scaled[continuous_vars] = scaler.fit_transform(X_scaled[continuous_vars])  #Apply standardization to continuous variables.\n",
    "\n",
    "# Perform train - test split\n",
    "X_scaled = X_scaled.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.20, random_state=5)\n",
    "\n",
    "# Initialize a list of classifier chains\n",
    "classifiers = []\n",
    "# Create a binary classifier for each label\n",
    "n_classes = y.shape[1]\n",
    "for i in range(n_classes):\n",
    "    best_clf = None\n",
    "    best_accuracy = 0\n",
    "    #Create a boolean mask to select samples where the current class is active.\n",
    "    y_train_i = np.where(y_train[:, i] == 1, 1, 0)  #Create a boolean mask where samples are labeled 1 if they belong to class i, and 0 otherwise.\n",
    "    if np.sum(y_train_i == 1) > 1:  #Ensure there are sufficient positive samples for the model\n",
    "        #Use RFECV for feature selection\n",
    "        rfecv = RFECV(estimator=classifier5, step=1, cv=5, scoring='accuracy')\n",
    "        X_train_1 = pd.DataFrame(X_train, columns=X1.columns)\n",
    "        rfecv.fit(X_train_1, y_train_i.ravel())\n",
    "        support = rfecv.support_\n",
    "        #The parameter scale_weight is tailored for use with XGBoost.\n",
    "        scale_weight= weight_Class (y_train_i)\n",
    "\n",
    "        #Reinitialize the classifier here and set up the parameter groups for Gridsearch, ensuring consistency in selection across the four classifiers.\n",
    "        #SVM\n",
    "        classifier5 =SVC(C=1.0, gamma='auto', class_weight='balanced', kernel='linear', tol=1e-2, probability=True)\n",
    "        param_grid1 = {'C': [0.1, 1, 10], 'gamma': ['scale', 'auto', 0.1, 1, 10], 'kernel': ['linear', 'rbf', 'poly'],  \n",
    "                       'tol': [1e-3, 1e-2, 1e-1] }\n",
    "\n",
    "        #LR\n",
    "        #lassifier1= LogisticRegression(dual=False, fit_intercept=True, intercept_scaling=1, class_weight='balanced', random_state=None,\n",
    "                                        #verbose=0, warm_start=False, n_jobs=-1)\n",
    "        #param_grid1 = {'penalty': ['l2'],  'C': [0.5, 1, 1.5, 2],   \n",
    "                       #'solver': ['newton-cg', 'lbfgs', 'liblinear'],  'max_iter': [1000, 5000],  'tol': [1e-3, 1e-2]}\n",
    "\n",
    "        #RF\n",
    "        #classifier2 = RandomForestClassifier(n_estimators=100, class_weight='balanced', n_jobs=-1)\n",
    "        #param_grid1 = {'n_estimators': [100, 200, 300],  'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 5, 10], \n",
    "                      #'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n",
    "\n",
    "        #XGBoost\n",
    "        #classifier4 = XGBClassifier(objective='binary:logistic', scale_pos_weight = scale_weight, n_estimators=100, n_jobs=-1, verbosity=1)\n",
    "        #param_grid1 = {'max_depth': [6, 9], 'min_child_weight': [3, 5], 'learning_rate': [0.01, 0.1], 'subsample': [0.8, 1.0],\n",
    "                       #'colsample_bytree': [0.6, 0.8, 1.0], 'gamma': [0, 0.1, 0.2], 'reg_alpha': [0, 0.1, 1.0], 'reg_lambda': [1, 1.1, 10.0]}\n",
    "        \n",
    "        y_train_1 = pd.DataFrame(y_train, columns = y1.columns)\n",
    "        if i > 0:\n",
    "            X_train_2 = pd.concat([X_train_1.iloc[:, support], y_train_1.iloc[:, :i]], axis=1)\n",
    "            best_clf = CV_train(classifier5, param_grid1, X_train_2, y_train_i.ravel())\n",
    "        else:\n",
    "            best_clf = CV_train(classifier5, param_grid1, X_train_1.iloc[:, support], y_train_i.ravel())\n",
    "\n",
    "    classifiers.append((best_clf, support))\n",
    "    \n",
    "# Use the prediction function for validation with bootstrap\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "n_iterations=600\n",
    "bootstrap_stats, bootstrap_stats_class1, bootstrap_stats_class2, bootstrap_stats_class3, bootstrap_stats_class4, bootstrap_stats_class5, bootstrap_stats_class6 = bootstrap_with_roc(classifiers, pd.DataFrame(X_test, columns=X1.columns), y_test, n_iterations)\n",
    "bootstrap_stat, bootstrap_stat_class1, bootstrap_stat_class2, bootstrap_stat_class3, bootstrap_stat_class4, bootstrap_stat_class5, bootstrap_stat_class6 = bootstrap_with_roc(classifiers, pd.DataFrame(X_train, columns=X1.columns), y_train, n_iterations)\n",
    "\n",
    "# Print the metric results\n",
    "print(f\"micro- Ave-hamming distance in external validation: {np.mean(bootstrap_stats['han']):.4f}\", f\"micro- Std-hamming distance in external validation: {np.std(bootstrap_stats['han']):.4f}\")\n",
    "print(f\"micro- Ave-sensitivity in external validation: {np.mean(bootstrap_stats['recall']):.4f}\", f\"micro- Std-sensitivity in external validation: {np.std(bootstrap_stats['recall']):.4f}\")\n",
    "print(f\"micro- Ave-AUROC in external validation: {np.mean(bootstrap_stats['auc']):.4f}\", f\"micro- Std-AUROC in external validation: {np.std(bootstrap_stats['auc']):.4f}\")\n",
    "print(f\"micro- Ave-precision in external validation: {np.mean(bootstrap_stats['precision']):.4f}\", f\"micro- Std-precision in external validation: {np.std(bootstrap_stats['precision']):.4f}\")\n",
    "print(f\"subset-Ave-accyracy in external validation: {np.mean(bootstrap_stats['accuracy']):.4f}\", f\"subset- Std-accuracy in external validation: {np.std(bootstrap_stats['accuracy']):.4f}\")\n",
    "print(f\"micro- Ave-F1 in external validation: {np.mean(bootstrap_stats['F1']):.4f}\", f\"micro- Std-F1 in external validation: {np.std(bootstrap_stats['F1']):.4f}\")\n",
    "print(f\"micro- Ave-AUPRC in external validation: {np.mean(bootstrap_stats['prc']):.4f}\", f\"micro- Std-F1 in external validation: {np.std(bootstrap_stats['prc']):.4f}\")\n",
    "\n",
    "print(f\"micro- Ave-hamming distance in internal validation: {np.mean(bootstrap_stat['han']):.4f}\", f\"micro- Std-hamming distance in internal validation: {np.std(bootstrap_stat['han']):.4f}\")\n",
    "print(f\"micro- Ave-sensitivity in internal validation: {np.mean(bootstrap_stat['recall']):.4f}\", f\"micro- Std-sensitivity in internal validation: {np.std(bootstrap_stat['recall']):.4f}\")\n",
    "print(f\"micro- Ave-AUROC in internal validation: {np.mean(bootstrap_stat['auc']):.4f}\", f\"micro- Std-AUROC in internal cross-validation: {np.std(bootstrap_stat['auc']):.4f}\")\n",
    "print(f\"micro- Ave-precision in internal validation: {np.mean(bootstrap_stat['precision']):.4f}\", f\"micro- Std-precision in internal validation:  {np.std(bootstrap_stat['precision']):.4f}\")\n",
    "print(f\"subset-Ave-accyracy in internal validation: {np.mean(bootstrap_stat['accuracy']):.4f}\", f\"subset- Std-accuracy in internal validation: {np.std(bootstrap_stat['accuracy']):.4f}\")\n",
    "print(f\"micro- Ave-F1 in internal validation: {np.mean(bootstrap_stat['F1']):.4f}\", f\"micro- Std-F1 in internal validation: {np.std(bootstrap_stat['F1']):.4f}\")\n",
    "print(f\"micro- Ave-AUPRC in internal validation: {np.mean(bootstrap_stat['prc']):.4f}\", f\"micro- Std-F1 in internal validation: {np.std(bootstrap_stat['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass1- Ave-specificity in external validation: {np.mean(bootstrap_stats_class1['specificity']):.4f}\", f\"subclass1- Std-specificity in external validation: {np.std(bootstrap_stats_class1['specificity']):.4f}\")\n",
    "print(f\"subclass1- Ave-sensitivity in external validation: {np.mean(bootstrap_stats_class1['recall']):.4f}\", f\"subclass1- Std-sensitivity in external validation: {np.std(bootstrap_stats_class1['recall']):.4f}\")\n",
    "print(f\"subclass1- Ave-AUROC in external validation: {np.mean(bootstrap_stats_class1['auc']):.4f}\", f\"subclass1- Std-AUROC in external validation: {np.std(bootstrap_stats_class1['auc']):.4f}\")\n",
    "print(f\"subclass1- Ave-precision in external validation: {np.mean(bootstrap_stats_class1['precision']):.4f}\", f\"subclass1- Std-precision in external validation: {np.std(bootstrap_stats_class1['precision']):.4f}\")\n",
    "print(f\"subclass1- Ave-accyracy in external validation: {np.mean(bootstrap_stats_class1['accuracy']):.4f}\", f\"subclass1- Std-accuracy in external validation: {np.std(bootstrap_stats_class1['accuracy']):.4f}\")\n",
    "print(f\"subclass1- Ave-F1 in external validation: {np.mean(bootstrap_stats_class1['F1']):.4f}\", f\"subclass1- Std-F1 in external validation: {np.std(bootstrap_stats_class1['F1']):.4f}\")\n",
    "print(f\"subclass1- Ave-AUPRC in external validation: {np.mean(bootstrap_stats_class1['prc']):.4f}\", f\"subclass1- Std-AUPRC in external validation: {np.std(bootstrap_stats_class1['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass2- Ave-specificity in external validation: {np.mean(bootstrap_stats_class2['specificity']):.4f}\", f\"subclass2- Std-specificity in external validation: {np.std(bootstrap_stats_class2['specificity']):.4f}\")\n",
    "print(f\"subclass2- Ave-sensitivity in external validation: {np.mean(bootstrap_stats_class2['recall']):.4f}\", f\"subclass2- Std-sensitivity in external validation: {np.std(bootstrap_stats_class2['recall']):.4f}\")\n",
    "print(f\"subclass2- Ave-AUROC in external validation: {np.mean(bootstrap_stats_class2['auc']):.4f}\", f\"subclass2- Std-AUROC in external validation: {np.std(bootstrap_stats_class2['auc']):.4f}\")\n",
    "print(f\"subclass2- Ave-precision in external validation: {np.mean(bootstrap_stats_class2['precision']):.4f}\", f\"subclass2- Std-precision in external validation: {np.std(bootstrap_stats_class2['precision']):.4f}\")\n",
    "print(f\"subclass2- Ave-accyracy in external validation: {np.mean(bootstrap_stats_class2['accuracy']):.4f}\", f\"subclass2- Std-accuracy in external validation: {np.std(bootstrap_stats_class2['accuracy']):.4f}\")\n",
    "print(f\"subclass2- Ave-F1 in external validation: {np.mean(bootstrap_stats_class2['F1']):.4f}\", f\"subclass2- Std-F1 in external validation: {np.std(bootstrap_stats_class2['F1']):.4f}\")\n",
    "print(f\"subclass2- Ave-AUPRC in external validation: {np.mean(bootstrap_stats_class2['prc']):.4f}\", f\"subclass2- Std-AUPRC in external validation: {np.std(bootstrap_stats_class2['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass3- Ave-specificity in external validation: {np.mean(bootstrap_stats_class3['specificity']):.4f}\", f\"subclass3- Std-specificity in external validation: {np.std(bootstrap_stats_class3['specificity']):.4f}\")\n",
    "print(f\"subclass3- Ave-sensitivity in external validation: {np.mean(bootstrap_stats_class3['recall']):.4f}\", f\"subclass3- Std-sensitivity in external validation: {np.std(bootstrap_stats_class3['recall']):.4f}\")\n",
    "print(f\"subclass3- Ave-AUROC in external validation: {np.mean(bootstrap_stats_class3['auc']):.4f}\", f\"subclass3- Std-AUROC in external validation: {np.std(bootstrap_stats_class3['auc']):.4f}\")\n",
    "print(f\"subclass3- Ave-precision in external validation: {np.mean(bootstrap_stats_class3['precision']):.4f}\", f\"subclass3- Std-precision in external validation: {np.std(bootstrap_stats_class3['precision']):.4f}\")\n",
    "print(f\"subclass3- Ave-accyracy in external validation: {np.mean(bootstrap_stats_class3['accuracy']):.4f}\", f\"subclass3- Std-accuracy in external validation: {np.std(bootstrap_stats_class3['accuracy']):.4f}\")\n",
    "print(f\"subclass3- Ave-F1 in external validation: {np.mean(bootstrap_stats_class3['F1']):.4f}\", f\"subclass3- Std-F1 in external validation: {np.std(bootstrap_stats_class3['F1']):.4f}\")\n",
    "print(f\"subclass3- Ave-AUPRC in external validation: {np.mean(bootstrap_stats_class3['prc']):.4f}\", f\"subclass3- Std-AUPRC in external validation: {np.std(bootstrap_stats_class3['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass4- Ave-specificity in external validation: {np.mean(bootstrap_stats_class4['specificity']):.4f}\", f\"subclass4- Std-specificity in external validation: {np.std(bootstrap_stats_class4['specificity']):.4f}\")\n",
    "print(f\"subclass4- Ave-sensitivity in external validation: {np.mean(bootstrap_stats_class4['recall']):.4f}\", f\"subclass4- Std-sensitivity in external validation: {np.std(bootstrap_stats_class4['recall']):.4f}\")\n",
    "print(f\"subclass4- Ave-AUROC in external validation: {np.mean(bootstrap_stats_class4['auc']):.4f}\", f\"subclass4- Std-AUROC in external validation: {np.std(bootstrap_stats_class4['auc']):.4f}\")\n",
    "print(f\"subclass4- Ave-precision in external validation: {np.mean(bootstrap_stats_class4['precision']):.4f}\", f\"subclass4- Std-precision in external validation: {np.std(bootstrap_stats_class4['precision']):.4f}\")\n",
    "print(f\"subclass4- Ave-accyracy in external validation: {np.mean(bootstrap_stats_class4['accuracy']):.4f}\", f\"subclass4- Std-accuracy in external validation: {np.std(bootstrap_stats_class4['accuracy']):.4f}\")\n",
    "print(f\"subclass4- Ave-F1 in external validation: {np.mean(bootstrap_stats_class4['F1']):.4f}\", f\"subclass4- Std-F1 in external validation: {np.std(bootstrap_stats_class4['F1']):.4f}\")\n",
    "print(f\"subclass4- Ave-AUPRC in external validation: {np.mean(bootstrap_stats_class4['prc']):.4f}\", f\"subclass4- Std-AUPRC in external validation: {np.std(bootstrap_stats_class4['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass5- Ave-specificity in external validation:{np.mean(bootstrap_stats_class5['specificity']):.4f}\", f\"subclass5- Std-specificity in external validation: {np.std(bootstrap_stats_class5['specificity']):.4f}\")\n",
    "print(f\"subclass5- Ave-sensitivity in external validation: {np.mean(bootstrap_stats_class5['recall']):.4f}\", f\"subclass5- Std-sensitivity in external validation:{np.std(bootstrap_stats_class5['recall']):.4f}\")\n",
    "print(f\"subclass5- Ave-AUROC in external validation:{np.mean(bootstrap_stats_class5['auc']):.4f}\", f\"subclass5- Std-AUROC in external validation: {np.std(bootstrap_stats_class5['auc']):.4f}\")\n",
    "print(f\"subclass5- Ave-precision in external validation: {np.mean(bootstrap_stats_class5['precision']):.4f}\", f\"subclass5- Std-precision in external validation: {np.std(bootstrap_stats_class5['precision']):.4f}\")\n",
    "print(f\"subclass5- Ave-accyracy in external validation: {np.mean(bootstrap_stats_class5['accuracy']):.4f}\", f\"subclass5- Std-accuracy in external validation: {np.std(bootstrap_stats_class5['accuracy']):.4f}\")\n",
    "print(f\"subclass5- Ave-F1 in external validation: {np.mean(bootstrap_stats_class5['F1']):.4f}\", f\"subclass5- Std-F1 in external validation: {np.std(bootstrap_stats_class5['F1']):.4f}\")\n",
    "print(f\"subclass5- Ave-AUPRC in external validation: {np.mean(bootstrap_stats_class5['prc']):.4f}\", f\"subclass5- Std-AUPRC in external validation: {np.std(bootstrap_stats_class5['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass6- Ave-specificity in external validation: {np.mean(bootstrap_stats_class6['specificity']):.4f}\", f\"subclass6- Std-specificity in external validation: {np.std(bootstrap_stats_class6['specificity']):.4f}\")\n",
    "print(f\"subclass6- Ave-sensitivity in external validation: {np.mean(bootstrap_stats_class6['recall']):.4f}\", f\"subclass6- Std-sensitivity in external validation: {np.std(bootstrap_stats_class6['recall']):.4f}\")\n",
    "print(f\"subclass6- Ave-AUROC in external validation: {np.mean(bootstrap_stats_class6['auc']):.4f}\", f\"subclass6- Std-AUROC in external validation: {np.std(bootstrap_stats_class6['auc']):.4f}\")\n",
    "print(f\"subclass6- Ave-precision in external validation: {np.mean(bootstrap_stats_class6['precision']):.4f}\", f\"subclass6- Std-precision in external validation: {np.std(bootstrap_stats_class6['precision']):.4f}\")\n",
    "print(f\"subclass6- Ave-accyracy in external validation: {np.mean(bootstrap_stats_class6['accuracy']):.4f}\", f\"subclass6- Std-accuracy in external validation: {np.std(bootstrap_stats_class6['accuracy']):.4f}\")\n",
    "print(f\"subclass6- Ave-F1 in external validation: {np.mean(bootstrap_stats_class6['F1']):.4f}\", f\"subclass6- Std-F1 in external validation: {np.std(bootstrap_stats_class6['F1']):.4f}\")\n",
    "print(f\"subclass6- Ave-AUPRC in external validation: {np.mean(bootstrap_stats_class6['prc']):.4f}\", f\"subclass6- Std-AUPRC in external validation: {np.std(bootstrap_stats_class6['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass1- Ave-specificity in internal validation: {np.mean(bootstrap_stat_class1['specificity']):.4f}\", f\"subclass1- Std-specificity in internal validation: {np.std(bootstrap_stat_class1['specificity']):.4f}\")\n",
    "print(f\"subclass1- Ave-sensitivity in internal validation: {np.mean(bootstrap_stat_class1['recall']):.4f}\", f\"subclass1- Std-sensitivity in internal validation: {np.std(bootstrap_stat_class1['recall']):.4f}\")\n",
    "print(f\"subclass1- Ave-AUROC in internal validation: {np.mean(bootstrap_stat_class1['auc']):.4f}\", f\"subclass1- Std-AUROC in internal validation: {np.std(bootstrap_stat_class1['auc']):.4f}\")\n",
    "print(f\"subclass1- Ave-precision in internal validation: {np.mean(bootstrap_stat_class1['precision']):.4f}\", f\"subclass1- Std-precision in internal validation: {np.std(bootstrap_stat_class1['precision']):.4f}\")\n",
    "print(f\"subclass1- Ave-accyracy in internal validation: {np.mean(bootstrap_stat_class1['accuracy']):.4f}\", f\"subclass1- Std-accuracy in internal validation: {np.std(bootstrap_stat_class1['accuracy']):.4f}\")\n",
    "print(f\"subclass1- Ave-F1 in internal validation: {np.mean(bootstrap_stat_class1['F1']):.4f}\", f\"subclass1- Std-F1 in internal validation: {np.std(bootstrap_stat_class1['F1']):.4f}\")\n",
    "print(f\"subclass1- Ave-AUPRC in internal validation: {np.mean(bootstrap_stat_class1['prc']):.4f}\", f\"subclass1- Std-AUPRC in internal validation: {np.std(bootstrap_stat_class1['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass2- Ave-specificity in internal validation: {np.mean(bootstrap_stat_class2['specificity']):.4f}\", f\"subclass2- Std-specificity in internal validation: {np.std(bootstrap_stat_class2['specificity']):.4f}\")\n",
    "print(f\"subclass2- Ave-sensitivity in internal validation: {np.mean(bootstrap_stat_class2['recall']):.4f}\", f\"subclass2- Std-sensitivity in internal validation: {np.std(bootstrap_stat_class2['recall']):.4f}\")\n",
    "print(f\"subclass2- Ave-AUROC in internal validation: {np.mean(bootstrap_stat_class2['auc']):.4f}\", f\"subclass2- Std-AUROC in internal validation: {np.std(bootstrap_stat_class2['auc']):.4f}\")\n",
    "print(f\"subclass2- Ave-precision in internal validation: {np.mean(bootstrap_stat_class2['precision']):.4f}\", f\"subclass2- Std-precision in internal validation: {np.std(bootstrap_stat_class2['precision']):.4f}\")\n",
    "print(f\"subclass2- Ave-accyracy in internal validation: {np.mean(bootstrap_stat_class2['accuracy']):.4f}\", f\"subclass2- Std-accuracy in internal validation: {np.std(bootstrap_stat_class2['accuracy']):.4f}\")\n",
    "print(f\"subclass2- Ave-F1 in internal validation: {np.mean(bootstrap_stat_class2['F1']):.4f}\", f\"subclass2- Std-F1 in internal validation: {np.std(bootstrap_stat_class2['F1']):.4f}\")\n",
    "print(f\"subclass2- Ave-AUPRC in internal cross-validation: {np.mean(bootstrap_stat_class2['prc']):.4f}\", f\"subclass2- Std-AUPRC in internal validation: {np.std(bootstrap_stat_class2['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass3- Ave-specificity in internal validation: {np.mean(bootstrap_stat_class3['specificity']):.4f}\", f\"subclass3- Std-specificity in internal validation: {np.std(bootstrap_stat_class3['specificity']):.4f}\")\n",
    "print(f\"subclass3- Ave-sensitivity in internal validation: {np.mean(bootstrap_stat_class3['recall']):.4f}\", f\"subclass3- Std-sensitivity in internal validation: {np.std(bootstrap_stat_class3['recall']):.4f}\")\n",
    "print(f\"subclass3- Ave-AUROC in internal validation: {np.mean(bootstrap_stat_class3['auc']):.4f}\", f\"subclass3- Std-AUROC in internal validation: {np.std(bootstrap_stat_class3['auc']):.4f}\")\n",
    "print(f\"subclass3- Ave-precision in internal validation: {np.mean(bootstrap_stat_class3['precision']):.4f}\", f\"subclass3- Std-precision in internal validation: {np.std(bootstrap_stat_class3['precision']):.4f}\")\n",
    "print(f\"subclass3- Ave-accyracy in internal validation: {np.mean(bootstrap_stat_class3['accuracy']):.4f}\", f\"subclass3- Std-accuracy in internal validation: {np.std(bootstrap_stat_class3['accuracy']):.4f}\")\n",
    "print(f\"subclass3- Ave-F1 in internal validation: {np.mean(bootstrap_stat_class3['F1']):.4f}\", f\"subclass3- Std-F1 in internal validation: {np.std(bootstrap_stat_class3['F1']):.4f}\")\n",
    "print(f\"subclass3- Ave-AUPRC in internal validation: {np.mean(bootstrap_stat_class3['prc']):.4f}\", f\"subclass3 Std-AUPRC in internal validation: {np.std(bootstrap_stat_class3['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass4- Ave-specificity in internal validation: {np.mean(bootstrap_stat_class4['specificity']):.4f}\", f\"subclass4- Std-specificity in internal validation: {np.std(bootstrap_stat_class4['specificity']):.4f}\")\n",
    "print(f\"subclass4- Ave-sensitivity in internal validation: {np.mean(bootstrap_stat_class4['recall']):.4f}\", f\"subclass4- Std-sensitivity in internal validation: {np.std(bootstrap_stat_class4['recall']):.4f}\")\n",
    "print(f\"subclass4- Ave-AUROC in internal validation:{np.mean(bootstrap_stat_class4['auc']):.4f}\", f\"subclass4- Std-AUROC in internal validation: {np.std(bootstrap_stat_class4['auc']):.4f}\")\n",
    "print(f\"subclass4- Ave-precision in internal validation: {np.mean(bootstrap_stat_class4['precision']):.4f}\", f\"subclass4- Std-precision in internal validation: {np.std(bootstrap_stat_class4['precision']):.4f}\")\n",
    "print(f\"subclass4- Ave-accyracy in internal validation: {np.mean(bootstrap_stat_class4['accuracy']):.4f}\", f\"subclass4- Std-accuracy in internal validation: {np.std(bootstrap_stat_class4['accuracy']):.4f}\")\n",
    "print(f\"subclass4- Ave-F1 in internal validation:{np.mean(bootstrap_stat_class4['F1']):.4f}\", f\"subclass4- Std-F1 in internal validation: {np.std(bootstrap_stat_class4['F1']):.4f}\")\n",
    "print(f\"subclass4- Ave-AUPRC in internal validation: {np.mean(bootstrap_stat_class4['prc']):.4f}\", f\"subclass4- Std-AUPRC in internal validation: {np.std(bootstrap_stat_class4['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass5- Ave-specificity in internal validation: {np.mean(bootstrap_stat_class5['specificity']):.4f}\", f\"subclass5- Std-specificity in internal validation: {np.std(bootstrap_stat_class5['specificity']):.4f}\")\n",
    "print(f\"subclass5- Ave-sensitivity in internal validation: {np.mean(bootstrap_stat_class5['recall']):.4f}\", f\"subclass5- Std-sensitivity in internal validation: {np.std(bootstrap_stat_class5['recall']):.4f}\")\n",
    "print(f\"subclass5- Ave-AUROC in internal validation: {np.mean(bootstrap_stat_class5['auc']):.4f}\", f\"subclass5- Std-AUROC in internal validation: {np.std(bootstrap_stat_class5['auc']):.4f}\")\n",
    "print(f\"subclass5- Ave-precision in internal validation: {np.mean(bootstrap_stat_class5['precision']):.4f}\", f\"subclass5- Std-precision in internal validation: {np.std(bootstrap_stat_class5['precision']):.4f}\")\n",
    "print(f\"subclass5- Ave-accyracy in internal validation: {np.mean(bootstrap_stat_class5['accuracy']):.4f}\", f\"subclass5- Std-accuracy in internal validation: {np.std(bootstrap_stat_class5['accuracy']):.4f}\")\n",
    "print(f\"subclass5- Ave-F1 in internal validation: {np.mean(bootstrap_stat_class5['F1']):.4f}\", f\"subclass5- Std-F1 in internal validation: {np.std(bootstrap_stat_class5['F1']):.4f}\")\n",
    "print(f\"subclass5- Ave-AUPRC in internal alidation: {np.mean(bootstrap_stat_class5['prc']):.4f}\", f\"subclass5- Std-AUPRC in internal validation: {np.std(bootstrap_stat_class5['prc']):.4f}\")\n",
    "\n",
    "print(f\"subclass6- Ave-specificity in internal validation: {np.mean(bootstrap_stat_class6['specificity']):.4f}\", f\"subclass6- Std-specificity in internal validation: {np.std(bootstrap_stat_class6['specificity']):.4f}\")\n",
    "print(f\"subclass6- Ave-sensitivity in internal validation: {np.mean(bootstrap_stat_class6['recall']):.4f}\", f\"subclass6- Std-sensitivity in internal validation: {np.std(bootstrap_stat_class6['recall']):.4f}\")\n",
    "print(f\"subclass6- Ave-AUROC in internal validation:{np.mean(bootstrap_stat_class6['auc']):.4f}\", f\"subclass6- Std-AUROC in internal validation: {np.std(bootstrap_stat_class6['auc']):.4f}\")\n",
    "print(f\"subclass6- Ave-precision in internal validation: {np.mean(bootstrap_stat_class6['precision']):.4f}\", f\"subclass6- Std-precision in internal validation: {np.std(bootstrap_stat_class6['precision']):.4f}\")\n",
    "print(f\"subclass6- Ave-accyracy in internal validation:: {np.mean(bootstrap_stat_class6['accuracy']):.4f}\", f\"subclass6- Std-accuracy in internal validation: {np.std(bootstrap_stat_class6['accuracy']):.4f}\")\n",
    "print(f\"subclass6- Ave-F1 in internal validation: {np.mean(bootstrap_stat_class6['F1']):.4f}\", f\"subclass6- Std-F1 in internal validation: {np.std(bootstrap_stat_class6['F1']):.4f}\")\n",
    "print(f\"subclass6- Ave-AUPRC in internal validation:{np.mean(bootstrap_stat_class6['prc']):.4f}\", f\"subclass6- Std-AUPRC in internal validation: {np.std(bootstrap_stat_class6['prc']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27179e69-9c80-49d6-968d-908f38ffbd13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233888a7-d970-4420-8458-29e6ef2ed810",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
